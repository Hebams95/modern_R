[
["index.html", "Modern R with the tidyverse Preface Note to the reader What is R? Who is this book for? Why this book? Why modern R? What is RStudio? What to expect from this book? Prerequisites What are packages? The author", " Modern R with the tidyverse Bruno Rodrigues 2018-11-27 Preface Note to the reader This book is still being written. Chapters 1 to 6 are almost ready. Chapter 7 is outdated, but the key messages are still useful. Chapters 8 and 9 are quite complete too. 10 and 11 are empty for now. Some exercises might be at the wrong place too. If you already like what you read, you can support me by buying me a coffee or paypal.me. What is R? Read R’s official answer to this question here. To make it short: R is a multi-paradigm (procedural, imperative, object-oriented and functional)1 programming language that focuses on applications in statistics. By statistics I mean any field that uses statistics such as official statistics, economics, finance, data science, machine learning, etc. For the sake of simplicity, I will use the word “statistics” as a general term that encompasses all these fields and disciplines for the remaineder of this book. Who is this book for? This book can be useful to different audiences. If you have never used R in your life, and what to start, start with Chapter 1 of this book. Chapter 1 to 3 are the very basics, and should be easy to follow up to Chapter 9. Starting with Chapter 9, it gets more technical, and will be harder to follow. But if I suggest you keep on going, and do not hesitate to contact me for help if you struggle! Chapter 9 is also where you can start if you are already familiar with R and the {tidyverse}, but not functional programming. If you are familiar with R but not the {tidyverse} (or have no clue what the {tidyverse} is), then you can start with Chapter 4. If you are familiar with R, the {tidyverse} and functional programming, you might still be interested in this book, especially Chapter 10 and 11, which deal with package development and further advanced topics respectively. Why this book? This book is first and foremost for myself. This book is the result of years of using and teaching R at university and then at my jobs. During my university time, I wrote some notes to help me teach R and which I distributed to my students. These are still the basis of chapter 3. Then, once I had left university, and continued using R at my first “real” job, I wrote another book that dealt mostly with package development and functional programming. This book is now merged to this one and is the basis of Chapters 9 and 11. During these years at my first job, I was also tasked with teaching R. By that time, I was already quite familiar with the {tidyverse} so I wrote a lot of notes that were internal and adapted for the audience of my first job. These are now the basis of Chapters 4 to 8. Then, during all these years, I kept blogging about R, and reading blogs and further books. All this knowledge is condensed here, so if you are familiar with my blog, you’ll definitely recognize a lot of my blog posts in here. So this book is first and foremost for me, because I need to write all of this down in a central place. So because my target audience is myself, this book is free. If you find it useful, and are in the mood of buying me a coffee you can, but if this book is not useful to you, no harm done (unless you paid for it before reading it, in which case, I am sorry to have wasted your time). But I am quite sure you’ll find some of the things written here useful, regardless of your current experience level with R. Why modern R? Modern R instead of “just” R because we are going to learn how to use modern packages (mostly those from the tidyverse) and concepts, such as functional programming (which is quite an old concept actually, but one that came into fashion recently). R is derived from S, which is a programming language that has roots in FORTRAN and other languages too. If you learned R at university, you’ve probably learned to use it as you would have used FORTRAN; very long scripts where data are represented as matrices and where row-wise (or column-wise) operations are implemented with for loops. There’s nothing wrong with that, mind you, but R was also influenced by Scheme and Common Lisp, which are functional programming languages. In my opinion, functional programming is a programming paradigm that works really well when dealing with statistical problems. This is because programming in a functional style is just like writing math. For instance, suppose you want to sum all the elements of a vector. In mathematical notation, you would write something like: \\[ \\sum_{i = 1}^{100} x_{i} \\] where \\(x\\) is a vector of length \\(i\\). Solving this using a loop would look something like this: res &lt;- 0 for(i in 1:length(x)){ res &lt;- x[i] + res } This does not look like the math notation at all! You have to define a variable that will hold the result outside of the loop, and then you have to define res as something plus res inside the body of the loop. This is really unnatural. The functional programming approach is much easier: Reduce(`+`, x) We will learn about Reduce() later (to be more precise, we will learn about purrr::reduce(), the “tidy” version of Reduce()), but already you see that the notation looks a lot more like the mathematical notation. At its core, functional programming uses functions, and functions are so-called first class objects in R, which means that there is nothing special about them… you can pass them to other functions, create functions that return functions and do any kind of operation on them just as with any other object. This means that functions in R are extremely powerful and flexible tools. In the first part of the book, we are going to use functions that are already available in R, and then use those available in packages, mostly those from the tidyverse. The tidyverse is a collection of packages developed by Hadley Wickham, and several of his colleagues at RStudio, Inc. By using the packages from the tidyverse and R’s built-in functional programming capabilities, we can write code that is faster and easier to explain to colleagues, and also easier to maintain. This also means that you might have to change your expectations and what you know already from R, if you learned it at University but haven’t touched it in a long time. For example for and while loops, are relegated to chapter 8. This does not mean that you will have to wait for 8 chapter to know how to repeat instructions N times, but that for and while loops are tools that are very useful for very specific kinds of situations that will be discussed at that point. In the second part of the book, we are going to move from using R to solve statistical problems to develop with R. We are going to learn about creating one’s own package. If you do not know what packages R, don’t worry, this will be discussed just below. What is RStudio? RStudio is a modern IDE that makes writing R code easier. The first thing we are going to learn is how to use it. R and RStudio are both open source: this means that the source code is freely available on the internet and contributions by anyone are welcome and integrated; provided they are meaningful and useful. What to expect from this book? The idea of Chapters 1 to 7 is to make you efficient with R as quickly as possible, especially if you already have prior programming knowledge. Starting with Chapter 8 you will learn more advanced topics, especially programming with R. R is a programming language, and you can’t write “programming language” without “language”. And just as you wouldn’t expect to learn French, Portuguese or Icelandic by reading a single book, you shouldn’t expect to become fluent in R by reading a single book, not even by reading 10 books. Programming is an art which requires a lot of practice. Teach yourself programming in 10 years is a blog post written by Peter Norvig which explains that just as with any craft, mastering programming takes time. And even if you don’t need or want to become an expert in R, if you wish to use R effectively and in a way that ultimately saves you time, you need to have some fluency in it, and this only comes by continuing to learn about the language, and most importantly practicing. If you keep using R every day, you’ll definitely become very fluent. To stay informed about developments of the language, and the latest news, I advise you read blogs, especially R-bloggers which aggregates blog posts by more than 750 blogs discussing R. So what you can expect from this book is that this book is not the only one you should read (it’s definitely not the only one you should read, more talented people than me have written much better books. Why are you reading this one, by the way?) Prerequisites R and RStudio are the two main pieces of software that we are going to use. R is the programming language and RStudio is a modern IDE for it. You can use R without RStudio; but you cannot use RStudio without R. If you wish to install R and RStudio at home to follow the examples in this book you can do it as both pieces of software are available free of charge (paid options for RStudio exist, for companies that need technical support). Installation is simple, but operating system dependent. To download and install R for Windows, follow this link. For macOS, follow this one. If you run a GNU+Linux distribution, you can install R using the system’s package manager. On Ubuntu, install r-base. For RStudio, look for your operating system here. What are packages? There is one more step; we are going to install some packages. Packages are additional pieces of code that can be installed from within R with the following function: install.packages(). These packages extend R’s capabilities significantly, and are probably one of the main reasons R is so popular. As of November 2018, R has over 13000 packages. To install the packages we need, first open RStudio and then copy and paste this line in the console: install.packages(c(&quot;tidyverse&quot;, &quot;plm&quot;, &quot;pwt9&quot;, &quot;checkpoint&quot;, &quot;Ecdat&quot;, &quot;ggthemes&quot;, &quot;janitor&quot;, &quot;rio&quot;, &quot;colourpicker&quot;)) or go to the Packages pane and then click on Install: The author My name is Bruno Rodrigues and I program almost exclusively in R and have been teaching some R courses for a few years now (first started teaching for students at the Université of Strasbourg). These notes are an update of those I used at the time, plus a lot of things I’ve learned about R In my free time I like cooking, working out and blogging, while listening to Fip. I also like to get my butt handed to me by playing roguelikes such as NetHack, for which I wrote a package that contains functions to analyze the data that is saved on your computer after you win or lose (it will be lose 99% of the time) the game. You can follow me on twitter, I tweet mostly about R or what’s happening in Luxembourg. If you find this book useful, you can buy me an espresso. In this book we are going to focus on R’s functional programming capabilities↩ "],
["getting-to-know-rstudio.html", "Chapter 1 Getting to know RStudio 1.1 Panes 1.2 Console 1.3 Scripts 1.4 Options 1.5 Keyboard shortcuts 1.6 Projects 1.7 History 1.8 Plots 1.9 Addins 1.10 Exercises", " Chapter 1 Getting to know RStudio 1.1 Panes RStudio is divided into different panes. Each pane has a specific function. The gif below shows some of these panes: Take some time to look around what each pane shows you. Some panes are empty; for example the Plots pane or the Viewer pane. Plots shows you the plots you make. You can browse the plots and save them. We will see this in more detail in a later chapter. Viewer shows you previews of documents that you generate with R. More on this later. 1.2 Console The Console pane is where you can execute R code. Write the following in the console: 2 + 3 and you’ll get the answer, 5. However, do not write a lot of lines in the console. It is better write your code inside a script. 1.3 Scripts Look at the gif below: In this gif, we see the user creating a new R script. R scripts are simple text files that hold R code. Think of .do files in STATA or .c files for C. R scripts have the extension .r or .R. It is possible to create a lot of other files. We’ll take a look at R Markdown files later. 1.3.1 The help pane The Help pane allows you to consult documentation for functions or packages. The gif below shows how it works: you can also access help using the following syntax: ?lm. This will bring up the documentation for the function lm(). You can also type ??lm which will look for the string lm in every package. 1.3.2 The Environment pane The Environment pane shows every object created in the current section. It is especially useful if you have defined lists or have loaded data into R as it makes it easy to explore these more complex objects. 1.4 Options It is also possible to customize RStudio’s look and feel: Take some time to go through the options. 1.5 Keyboard shortcuts It is a good idea to familiarize yourself with at least some keyboard shortcuts. This is more convenient than having to move the mouse around: If there is only one keyboard shortcut you need to know, it’s Ctrl-Enter that executes a line of code from your script. However, these other shortcuts are also worth knowing: CTRL-ALT-R: run entire script CTRL-ALT-UP or DOWN: make cursor taller or shorter, allowing you to edit multiple lines at the same time CTRL-F: Search and replace ALT-UP or DOWN: Move line up or down CTRL-SHIFT-C: Comment/uncomment line ALT-SHIFT-K: Bring up the list of keyboard shortcuts CTRL-SHIFT-M: Insert the pipe operator (%&gt;%, more on this later) CTRL-S: Save script This is just a few keyboard shortcuts that I personally find useful. However, I strongly advise you to learn and use whatever shortcuts are useful to you! 1.6 Projects One of the best features of RStudio are projects. Creating a project is simple; the gif below shows how you can create a project and how you can switch between projects. Projects make a lot of things easier, such as managing paths. More on this in the chapter about reading data. Another useful feature of projects is that the scripts you open in project A will stay open even if you switch to another project B, and then switch back to the project A again. You can also use version control (with git) inside a project. Version control is very useful, but I won’t discuss it here. You can find a lot of resources online to get you started with git. 1.7 History The History pane saves all the previous lines you executed. You can then select these lines and send them back to the console or the script. 1.8 Plots All the plots you make during a session are visible in the Plots pane. From there, you can export them in different formats. The plots shown in the gif are made using basic R functions. Later, we will learn how to make nicer looking plots using the package ggplot2. 1.9 Addins Some packages install addins, which are accessible through the addins button: This addins make it easier to use some functions and you can read more about them here. My favorite addins are the ones you get when installing the {datapasta} package. Read more about it here. 1.10 Exercises Exercise 1 Change the look and feel of RStudio to suit your tastes! I personally like to move the console to the right and use a dark theme. Take some 5 minutes to customize it and browse through all the options. "],
["packages.html", "Chapter 2 Packages", " Chapter 2 Packages You can think of packages as addons that extend R’s core functionality. You can browse all available packages on CRAN. To make it easier to find what you might be interested in, you can also browse the CRAN Task Views. Each package has a landing page that summarises its dependencies, version number etc. For example, for the dplyr package: https://cran.r-project.org/web/packages/dplyr/index.html. Take a look at the Downloads section, and especially at the Reference Manual and Vignettes: Vignettes are valuable documents; inside vignettes, the purpose of the package is explained in plain English, usually with accompanying examples. The reference manuals list the available functions inside the packages. You can also find vignettes from within Rstudio: Go to the Packages pane and click on the package you’re interested in. Then you can consult the help for the functions that come with the package as well as the package’s vignettes. Once you installed a package, you have to load it before you can use it. To load packages you use the library() function: library(dplyr) library(janitor) # and so on... If you only need to use one single function once, you don’t need to load an entire package. You can write the following: dplyr::full_join(A, B) using the :: operator, you can access functions from packages without having to load the whole package beforehand. It is possible and easy to create your own packages. This is useful if you have to write a lot of functions that you use daily. We will lean about that, in Chapter 11. "],
["data-types-and-objects.html", "Chapter 3 Data types and objects 3.1 The numeric class 3.2 The character class 3.3 The factor class 3.4 The Date class 3.5 Vectors and matrices 3.6 The logical class 3.7 The list class 3.8 The data.frame and tibble classes 3.9 Formulas 3.10 Models 3.11 The is.*() and as.*() functions 3.12 Exercises", " Chapter 3 Data types and objects All objects in R have a given type. You already know most of them, as these types are also used in mathematics. Integers, floating point numbers, or floats, matrices, etc, are all objects you are already familiar with. But R has other, maybe lesser known data types (that you can find in a lot of other programming languages) that you need to become familiar with. But first, we need to learn how to assign a value to a variable. This can be done in two ways: a &lt;- 3 or a &lt;- 3 there is almost no difference between these two approaches. You would need to pay attention to this, and use &lt;- in very specific situations to which you will very likely never be confronted to. Another thing you must know before going further is that you can convert from one type to another using functions that start with as.(), such as as.character(), as.numeric(), as.logical(), etc… For example, as.character(1) converts the number 1 to the character (or string) “1”. There are also is.character(), is.numeric() and so on that test if the object is of the required class. These functions exist for each object type, and are very useful. Make sure you remember them! 3.1 The numeric class To define single numbers, you can do the following: a &lt;- 3 The class() function allows you to check the class of an object: class(a) ## [1] &quot;numeric&quot; Decimals are defined with the character .: a &lt;- 3.14 3.2 The character class Use &quot; &quot; to define characters (called strings in other programming languages): a &lt;- &quot;this is a string&quot; class(a) ## [1] &quot;character&quot; A very nice package to work with characters is {stringr}, which is also part of the {tidyverse}. 3.3 The factor class Factors look like characters, but are very different. They are the representation of categorical variables. A {tidyverse} package to work with factors is {forcats}. You would rarely use factor variables outside of datasets, so for now, it is enough to know that this class exists. We are going to manipulate factor variables in the next chatper 5. 3.4 The Date class Dates also look like characters, but are very different too: as.Date(&quot;2019/03/19&quot;) ## [1] &quot;2019-03-19&quot; class(as.Date(&quot;2019/03/19&quot;)) ## [1] &quot;Date&quot; Manipulating dates and time can be tricky, but thankfully there’s a {tidyverse} package for that, called {lubridate}. We are going to go over this package in Chapter 5. 3.5 Vectors and matrices You can create a vector in different ways. But first of all, it is important to understand that a vector in most programming languages is nothing more than a list of things. These things can be numbers (either integers or floats), strings, or even other vectors. 3.5.1 The c() function A very important function that allows you to build a vector is c(): a &lt;- c(1,2,3,4,5) This creates a vector with elements 1, 2, 3, 4, 5. If you check its class: class(a) ## [1] &quot;numeric&quot; This can be confusing: you where probably expecting a to be of class vector or something similar. This is not the case if you use c() to create the vector, because c() doesn’t build a vector in the mathematical sense, but rather a list with numbers. Checking its dimension: dim(a) ## NULL returns NULL because a list doesn’t have a dimension, that’s why the dim() function returns NULL. If you want to create a true vector, you need to use cbind() or rbind(). 3.5.2 cbind() and rbind() You can create a true vector with cbind(): a &lt;- cbind(1,2,3,4,5) Check its class now: class(a) ## [1] &quot;matrix&quot; This is exactly what we expected. Let’s check its dimension: dim(a) ## [1] 1 5 This returns the dimension of a using the LICO notation (number of LInes first, the number of COlumns). It is also possible to bind vectors together to create a matrix. b &lt;- cbind(6,7,8,9,10) Now let’s put vector a and b into a matrix called matrix_c using rbind(). rbind() functions the same way as cbind() but glues the vectors together by rows and not by columns. matrix_c &lt;- rbind(a,b) print(matrix_c) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 3 4 5 ## [2,] 6 7 8 9 10 3.5.3 The matrix class R also has support for matrices. For example, you can create a matrix of dimension (5,5) filled with 0’s with the matrix() function: matrix_a &lt;- matrix(0, nrow &lt;- 5, ncol &lt;- 5) If you want to create the following matrix: \\[ B &lt;- \\left( \\begin{array}{ccc} 2 &amp; 4 &amp; 3 \\\\ 1 &amp; 5 &amp; 7 \\end{array} \\right) \\] you would do it like this: B &lt;- matrix(c(2, 4, 3, 1, 5, 7), nrow &lt;- 2, byrow &lt;- TRUE) The option byrow &lt;- TRUE means that the rows of the matrix will be filled first. You can access individual elements of matrix_a like so: matrix_a[2, 3] ## [1] 0 and R returns its value, 0. We can assign a new value to this element if we want. Try: matrix_a[2, 3] &lt;- 7 and now take a look at matrix_a again. print(matrix_a) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 7 0 0 ## [3,] 0 0 0 0 0 ## [4,] 0 0 0 0 0 ## [5,] 0 0 0 0 0 Recall our vector b: b &lt;- cbind(6,7,8,9,10) To access its third element, you can simply write: b[3] ## [1] 8 3.6 The logical class This class is the result of logical comparisons, for example, if you type: 4 &gt; 3 ## [1] TRUE R returns true. If we save this in a variable k: k &lt;- 4 &gt; 3 and check k’s class: class(k) ## [1] &quot;logical&quot; R returns logical. In other programming languages, logicals are often called bools. A logical variable can only have two values, either TRUE or FALSE. 3.7 The list class The list class is a very flexible class, and thus, very useful. You can put anything inside a list, such as numbers: list1 &lt;- list(3, 2) or other lists constructed with c(): list2 &lt;- list(c(1, 2), c(3, 4)) you can also put objects of different classes in the same list: list3 &lt;- list(3, c(1, 2), &quot;lists are amazing!&quot;) and of course create list of lists: my_lists &lt;- list(list1, list2, list3) To check the contents of a list, you can use the structure function str(): str(my_lists) ## List of 3 ## $ :List of 2 ## ..$ : num 3 ## ..$ : num 2 ## $ :List of 2 ## ..$ : num [1:2] 1 2 ## ..$ : num [1:2] 3 4 ## $ :List of 3 ## ..$ : num 3 ## ..$ : num [1:2] 1 2 ## ..$ : chr &quot;lists are amazing!&quot; or you can use RStudio’s Environment pane: You can also create named lists: list4 &lt;- list(&quot;a&quot; &lt;- 2, &quot;b&quot; &lt;- 8, &quot;c&quot; &lt;- &quot;this is a named list&quot;) and you can access the elements in two ways: list4[[1]] ## [1] 2 or, for named lists: list4$c ## NULL Lists are used extensively because they are so flexible. You can build lists of datasets and apply functions to all the datasets at once, build lists of models, lists of plots, etc… In the later chapters we are going to learn all about them. Actually, I use lists very often, but never vectors or matrices. Lists are much more flexible and in R, datasets behave like lists. 3.8 The data.frame and tibble classes In the next chapter we are going to learn how to import datasets into R. Once you import data, the resulting object is either a data.frame or a tibble depending on which package you used to import the data. tibbles extend data.frames so if you know about data.frame objects already, working with tibbles will be very easy. tibbles have a better print() method, and some other niceties. If you want to know more, I go into more detail in my other book but for our purposes, there’s not much you need to know about data.frame and tibble objects, apart that this is the representation of a dataset when loaded into R. However, I want to stress that these objects are central to R and are thus very important. There are different ways to print a data.frame or a tibble if you wish to inspect it. You can use View(my_data) to show the my_data data.frame in the View pane of RStudio: You can also use the str() function: str(my_data) And if you need to access an individual column, you can use the $ sign, same as for a list: my_data$col1 3.9 Formulas We will learn more about formulas later, but because it is an important object, it is useful if you already know about them early on. A formula is defined in the following way: my_formula &lt;- ~x class(my_formula) ## [1] &quot;formula&quot; Formula objects are defined using the ~ symbol. Formulas are useful to define statistical models, for example for a linear regression: lm(y ~ x) or also to define anonymous functions, but more on this later. 3.10 Models A statistical model is an object like any other in R: data(mtcars) my_model &lt;- lm(mpg ~ hp, mtcars) class(my_model) ## [1] &quot;lm&quot; my_model is an object of class lm. You can apply different functions to a model object: summary(my_model) ## ## Call: ## lm(formula = mpg ~ hp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.7121 -2.1122 -0.8854 1.5819 8.2360 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 30.09886 1.63392 18.421 &lt; 2e-16 *** ## hp -0.06823 0.01012 -6.742 1.79e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.863 on 30 degrees of freedom ## Multiple R-squared: 0.6024, Adjusted R-squared: 0.5892 ## F-statistic: 45.46 on 1 and 30 DF, p-value: 1.788e-07 This class will be explored in later chapters. 3.11 The is.*() and as.*() functions is.*() and as.*() are very powerful, and this is the right moment to introduce them. is.*() test the class of an object: is.integer(5) ## [1] FALSE is.character(198) ## [1] FALSE as.*() functions convert from one type to another: as.character(7) ## [1] &quot;7&quot; as.numeric(&quot;23.12&quot;) ## [1] 23.12 but only if it makes sense: as.numeric(&quot;This will return NA&quot;) ## Warning: NAs introduced by coercion ## [1] NA Keep these in mind, because they are going to be very useful. The {purrr} package introduces similar functions, is_*() and as_*(). We will explore them in Chapter 9. 3.12 Exercises Exercise 1 Try to create the following vector: \\[a = (6,3,8,9)\\] and add it this other vector: \\[b = (9,1,3,5)\\] and save the result to a new variable called result. Exercise 2 Using a and b from before, try to get their dot product. Try with a * b in the R console. What happened? Try to find the right function to get the dot product. Don’t hesitate to google the answer! Exercise 3 How can you create a matrix of dimension (30,30) filled with 2’s by only using the function matrix()? Exercise 4 Save your first name in a variable a and your surname in a variable b. What does the function: paste(a, b) do? Look at the help for paste() with ?paste or using the Help pane in RStudio. What does the optional argument sep do? Exercise 5 Define the following variables: a &lt;- 8, b &lt;- 3, c &lt;- 19. What do the following lines check? What do they return? a &gt; b a == b a != b a &lt; b (a &gt; b) &amp;&amp; (a &lt; c) (a &gt; b) &amp;&amp; (a &gt; c) (a &gt; b) || (a &lt; b) Exercise 6 Define the following matrix: \\[ \\text{matrix_a} = \\left( \\begin{array}{ccc} 9 &amp; 4 &amp; 12 \\\\ 5 &amp; 0 &amp; 7 \\\\ 2 &amp; 6 &amp; 8 \\\\ 9 &amp; 2 &amp; 9 \\end{array} \\right) \\] What does matrix_a &gt;= 5 do? What does matrix_a[ , 2] do? Can you find which function gives you the transpose of this matrix? Exercise 7 Solve the following system of equations using the solve() function: \\[ \\left( \\begin{array}{cccc} 9 &amp; 4 &amp; 12 &amp; 2 \\\\ 5 &amp; 0 &amp; 7 &amp; 9\\\\ 2 &amp; 6 &amp; 8 &amp; 0\\\\ 9 &amp; 2 &amp; 9 &amp; 11 \\end{array} \\right) \\times \\left( \\begin{array}{ccc} x \\\\ y \\\\ z \\\\ t \\\\ \\end{array}\\right) = \\left( \\begin{array}{ccc} 7\\\\ 18\\\\ 1\\\\ 0 \\end{array} \\right) \\] Exercise 8 Load the mtcars data (mtcars is include in R, so you only need to use the data() function to load the data): data(mtcars) if you run class(mtcars), you get “data.frame”. Try now with typeof(mtcars). The answer is now “list”! This is because the class of an object is an attribute of that object, which can even be assigned by the user: class(mtcars) &lt;- &quot;don&#39;t do this&quot; class(mtcars) ## [1] &quot;don&#39;t do this&quot; The type of an object is R’s internal type of that object, which cannot be manipulated by the user. It is always useful to know the type of an object (not just its class). For example, in the particular case of data frames, because the type of a data frame is a list, you can use all that you learned about lists to manipulate data frames! Recall that $ allowed you to select the element of a list for instance: my_list &lt;- list(&quot;one&quot; = 1, &quot;two&quot; = 2, &quot;three&quot; = 3) my_list$one ## [1] 1 Because data frames are nothing but fancy lists, this is why you can access columns the same way: mtcars$mpg ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 ## [15] 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 ## [29] 15.8 19.7 15.0 21.4 "],
["reading-and-writing-data.html", "Chapter 4 Reading and writing data 4.1 The swiss army knife of data import and export: {rio} 4.2 Writing any object to disk 4.3 Using RStudio projects to manage paths", " Chapter 4 Reading and writing data In this chapter, we are going to import example datasets that are available in R, mtcars and iris. I have converted these datasets into several formats. Download those datasets here if you want to follow the examples below. R can import some formats without the need of external packages, such as the .csv format. However, for other formats, you will need to use different packages. Because there are a lot of different formats available I suggest you use the {rio} package. {rio} is a wrapper around different packages that import/export data in different formats. This package is nice because you don’t need to remember which package to use to import, say, STATA datasets and then you need to remember which one for SAS datasets, and so on. Read {rio}’s vignette for more details. Below I show some of {rio}’s functions presented in the vignette. It is also possible to import data from other, less “traditional” sources, such as your clipboard. Also note that it is possible to import more than one dataset at once. There are two ways of doing that, either by importing all the datasets, binding their rows together and add a new variable with the name of the data, or import all the datasets into a list, where each element of that list is a data frame. We are going to explore this second option later. 4.1 The swiss army knife of data import and export: {rio} To import data with {rio}, import() is all you need: library(rio) mtcars &lt;- import(&quot;datasets/mtcars.csv&quot;) head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 import() needs the path to the data, and you can specify additional options if needed. On a Windows computer, you have to pay attention to the path; you cannot simply copy and paste it, because paths in Windows use the \\ symbol whereas R uses / (just like on Linux or macOS). Importing a STATA or a SAS file is done just the same: mtcars_stata &lt;- import(&quot;datasets/mtcars.dta&quot;) head(mtcars_stata) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 mtcars_sas &lt;- import(&quot;datasets/mtcars.sas7bdat&quot;) head(mtcars_sas) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 It is also possible to import Excel files where each sheet is a single table, but you will need import_list() for that. The file multi.xlsx has two sheets, each with a table in it: multi &lt;- import_list(&quot;datasets/multi.xlsx&quot;) str(multi) ## List of 2 ## $ mtcars:&#39;data.frame&#39;: 32 obs. of 11 variables: ## ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ... ## ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ... ## ..$ disp: num [1:32] 160 160 108 258 360 ... ## ..$ hp : num [1:32] 110 110 93 110 175 105 245 62 95 123 ... ## ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ... ## ..$ wt : num [1:32] 2.62 2.88 2.32 3.21 3.44 ... ## ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ... ## ..$ vs : num [1:32] 0 0 1 1 0 1 0 1 1 1 ... ## ..$ am : num [1:32] 1 1 1 0 0 0 0 0 0 0 ... ## ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ... ## ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ... ## $ iris :&#39;data.frame&#39;: 150 obs. of 5 variables: ## ..$ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## ..$ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## ..$ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## ..$ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## ..$ Species : chr [1:150] &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; &quot;setosa&quot; ... As you can see multi is a list of datasets. Told you lists were very flexible! It is also possible to import all the datasets in a single directory at once. For this, you first need a vector of paths: paths &lt;- Sys.glob(&quot;datasets/unemployment/*.csv&quot;) Sys.glob() allows you to find files using a regular expression. &quot;datasets/unemployment/*.csv&quot; matches all the .csv files inside the “datasets/unemployment/” folder. all_data &lt;- import_list(paths) str(all_data) ## List of 4 ## $ unemp_2013:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of which: Wage-earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of which: Non-wage-earners: int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ Unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ Active population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ Year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ unemp_2014:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of which: Wage-earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of which: Non-wage-earners: int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ Unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ Active population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ Year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ unemp_2015:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of which: Wage-earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of which: Non-wage-earners: int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ Active population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ Year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ unemp_2016:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of which: Wage-earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of which: Non-wage-earners: int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ Active population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ Year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... in a subsequent chapter we will learn how to actually use these lists of datasets. If you know that each dataset in each file has the same colmuns, you can also import them directly into a single dataset by binding each dataset together using rbind = TRUE: bind_data &lt;- import_list(paths, rbind = TRUE) str(bind_data) ## &#39;data.frame&#39;: 472 obs. of 9 variables: ## $ Commune : chr &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## $ Total employed population : int 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## $ of which: Wage-earners : int 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## $ of which: Non-wage-earners: int 19872 1809 168 94 116 294 272 113 189 338 ... ## $ Unemployed : int 19287 1071 114 25 74 261 98 45 66 207 ... ## $ Active population : int 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## $ Unemployment rate (in %) : num 7.95 5.67 6.27 2.88 4.92 ... ## $ Year : int 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ _file : chr &quot;datasets/unemployment/unemp_2013.csv&quot; &quot;datasets/unemployment/unemp_2013.csv&quot; &quot;datasets/unemployment/unemp_2013.csv&quot; &quot;datasets/unemployment/unemp_2013.csv&quot; ... ## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; This also add a further column called _file indicating the name of the file that contained the original data. If something goes wrong, you might need to take a look at the underlying function {rio} is actually using to import the file. Let’s look at the following example: testdata &lt;- import(&quot;datasets/problems/mtcars.csv&quot;) head(testdata) ## mpg&amp;cyl&amp;disp&amp;hp&amp;drat&amp;wt&amp;qsec&amp;vs&amp;am&amp;gear&amp;carb ## 1 21&amp;6&amp;160&amp;110&amp;3.9&amp;2.62&amp;16.46&amp;0&amp;1&amp;4&amp;4 ## 2 21&amp;6&amp;160&amp;110&amp;3.9&amp;2.875&amp;17.02&amp;0&amp;1&amp;4&amp;4 ## 3 22.8&amp;4&amp;108&amp;93&amp;3.85&amp;2.32&amp;18.61&amp;1&amp;1&amp;4&amp;1 ## 4 21.4&amp;6&amp;258&amp;110&amp;3.08&amp;3.215&amp;19.44&amp;1&amp;0&amp;3&amp;1 ## 5 18.7&amp;8&amp;360&amp;175&amp;3.15&amp;3.44&amp;17.02&amp;0&amp;0&amp;3&amp;2 ## 6 18.1&amp;6&amp;225&amp;105&amp;2.76&amp;3.46&amp;20.22&amp;1&amp;0&amp;3&amp;1 as you can see, the import didn’t work quite well! This is because the separator is the &amp; for some reason. Because we are trying to read a .csv file, rio::import() is using data.table::fread() under the hood (you can read this in import()’s help). If you then read data.table::fread()’s help, you see that the fread() function has an optional sep = argument that you can use to specify the separator. You can use this argument in import() too, and it will be passed down to data.table::fread(): testdata &lt;- import(&quot;datasets/problems/mtcars.csv&quot;, sep = &quot;&amp;&quot;) head(testdata) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 export() allows you to write data to disk, by simply providing the path and name of the file you wish to save. export(testdata, &quot;path/where/to/save/testdata.csv&quot;) If you end the name with .csv the file is exported to the csv format, if instead you write .dta the data will be exported to the STATA format, and so on. If you wish to export to Excel, this is possible, but it may require that you change a file on your computer (you only have to do this once). Try running: export(testdata, &quot;path/where/to/save/testdata.xlsx&quot;) if this results in an error, try the following: Run the following lines in Rstudio: if(!file.exists(&quot;~/.Rprofile&quot;)) # only create if not already there file.create(&quot;~/.Rprofile&quot;) # (don&#39;t overwrite it) file.edit(&quot;~/.Rprofile&quot;) These lines, taken shamelessly from Efficient R programming (go read it, it’s a very great resource) look for and open the .Rprofile file which is a file that is run every time you open Rstudio. This means that you can put any line of code there that will always be executed whenever you launch Rstudio. Add this line to the file: Sys.setenv(&quot;R_ZIPCMD&quot; = &quot;C:/Program Files (x86)/Rtools/zip.exe&quot;) This tells Rstudio to use zip.exe as the default zip tool, which is needed to export files to the Excel format. Try it out by restarting Rstudio, and then running the following lines: library(rio) data(mtcars) export(mtcars, &quot;mtcars.xlsx&quot;) You should find the mtcars.xlsx inside your working directory. You can check what is your working directory with getwd(). {rio} should cover all your needs, but if not, there is very likely a package out there that will import the data you need. 4.2 Writing any object to disk {rio} is an amazing package, but is only able to write tabular representations of data. What if you would like to save, say, a list containing any arbitrary object? This is possible with the saveRDS() function. Literally anything can be saved with saveRDS(): my_list &lt;- list(&quot;this is a list&quot;, list(&quot;which contains a list&quot;, 12), c(1, 2, 3, 4), matrix(c(2, 4, 3, 1, 5, 7), nrow = 2)) str(my_list) ## List of 4 ## $ : chr &quot;this is a list&quot; ## $ :List of 2 ## ..$ : chr &quot;which contains a list&quot; ## ..$ : num 12 ## $ : num [1:4] 1 2 3 4 ## $ : num [1:2, 1:3] 2 4 3 1 5 7 my_list is a list containing a string, a list which contains a string and a number, a vector and a matrix… Now suppose that computing this list takes a very long time. For example, imagine that each element of the list is the result of estimating a very complex model on a simulated dataset, which takes hours to simulate. Because this takes so long to compute, you’d want to save it to disk. This is possible with saveRDS(): saveRDS(my_list, &quot;my_list.RDS&quot;) The next day, after having freshly started your computer and launched RStudio, it is possible to retrieve the object exactly like it was using readRDS(): my_list &lt;- readRDS(&quot;my_list.RDS&quot;) str(my_list) ## List of 4 ## $ : chr &quot;this is a list&quot; ## $ :List of 2 ## ..$ : chr &quot;which contains a list&quot; ## ..$ : num 12 ## $ : num [1:4] 1 2 3 4 ## $ : num [1:2, 1:3] 2 4 3 1 5 7 Even if you want to save a regular dataset, using saveRDS() might be a good idea because the data gets compressed if you add the option compress = TRUE to saveRDS(). However keep in mind that this will only be readable by R, so if you need to share this data with colleagues that use another tool, save it in another format. 4.3 Using RStudio projects to manage paths Managing paths can be painful, especially if you’re collaborating with a colleague and both of you saved the data in paths that are different. Whenever one of you wants to work on the script, the path will need to be adapted first. The best way to avoid that is to use projects with RStudio. Imagine that you are working on a project entitled “housing”. You will create a folder called “housing” somewhere on your computer and inside this folder have another folder called “data”, then a bunch of other folders containing different files or the outputs of your analysis. What matters here is that you have a folder called “data” which contains the datasets you will ananlyze. When you are inside an RStudio project, granted that you chose your “housing” folder as the folder to host the project, you can read the data by simply specifying the path like so: my_data &lt;- import(&quot;/data/data.csv&quot;) Constrast this to what you would need to write if you were not using a project: my_data &lt;- import(&quot;C:/My Documents/Castor/Work/Projects/Housing/data/data.csv&quot;) Not only is that longer, but if Castor is working on this project with Pollux, Pollux would need to change the above line to this: my_data &lt;- import(&quot;C:/My Documents/Pollux/Work/Projects/Housing/data/data.csv&quot;) whenever Pollux needs to work on it. Another, similar issue, is that if you need to write something to disk, such as a dataset or a plot, you would also need to specify the whole path: export(my_data, &quot;C:/My Documents/Pollux/Work/Projects/Housing/data/data.csv&quot;) If you forget to write the whole path, then the dataset will be saved in the standard working directory, which is your “My Documents” folder on Windows, and “Home” on GNU+Linux or macOS. You can check what is the working directory with the getwd() function: getwd() On a fresh session on my computer this returns: &quot;/home/bruno&quot; or, on Windows: &quot;C:/Users/Bruno/Documents&quot; but if you call this function inside a project, it will return the path to your project. It is also possible to set the working directory with setwd(), so you don’t need to always write the full path, meaning that you can this: setwd(&quot;the/path/I/want/&quot;) import(&quot;data/my_data.csv&quot;) export(processed_data, &quot;processed_data.xlsx&quot;) instead of: import(&quot;the/path/I/want/data/my_data.csv&quot;) export(processed_data, &quot;the/path/I/want/processed_data.xlsx&quot;) However, I really, really, really urge you never to use setwd(). Use projects instead! Using projects saves a lot of pain in the long run. "],
["descriptive-statistics-and-data-manipulation.html", "Chapter 5 Descriptive statistics and data manipulation 5.1 An data exploration exercice using base R 5.2 Smoking is bad for you, but pipes are your friend 5.3 The {tidyverse}’s enfant prodige: {dplyr} 5.4 Reshaping data with tidyr 5.5 Scoped {tidyverse} verbs 5.6 Other useful {tidyverse} functions 5.7 Special packages for special kinds of data: {forcats}, {lubridate}, and {stringr} 5.8 List-columns 5.9 Exercises", " Chapter 5 Descriptive statistics and data manipulation Now that we are familiar with some R objects and know how to import data, it is time to write some code. In this chapter, we are going to compute descriptive statistics for a single dataset, but also for a list of datasets. However, I will not give a list of functions to compute descriptive statistics; if you need a specific function you can find easily in the Help pane in Rstudio or using any modern internet search engine. What I will do is show you a workflow that allows you to compute the descripitive statisics you need fast. R has a lot of built-in functions for descriptive statistics; however, if you want to compute statistics by, say, gender, some more complex manipulations are needed. At least this was true in the past. Nowadays, thanks to the packages from the tidyverse, it is very easy and fast to compute descriptive statistics by any stratifying variable(s). The package we are going to use for this is called dplyr. dplyr contains a lot of functions that make manipulating data and computing descriptive statistics very easy. To make things easier for now, we are going to use example data included with dplyr. So no need to import an external dataset; this does not change anything to the example that we are going to study here; the source of the data does not matter for this. Using dplyr is possible only if the data you are working with is already in a useful shape. When data is more messy, you will need to first manipulate it to bring it a tidy format. For this, we will use tidyr, which is very useful package to reshape data and to do advanced cleaning of your data. All these tidyverse functions are also called verbs. However, before getting to know these verbs, let’s do an analysis using standard, or base R functions. This will be the benchmark against which we are going to measure a {tidyverse} workflow. 5.1 An data exploration exercice using base R Let’s first load the starwars data set, included in the {dplyr} package: library(dplyr) data(starwars) Let’s first take a look at the data: head(starwars) ## # A tibble: 6 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke… 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; ## 4 Dart… 202 136 none white yellow 41.9 male ## 5 Leia… 150 49 brown light brown 19 female ## 6 Owen… 178 120 brown, gr… light blue 52 male ## # ... with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; This data contains information on Star Wars characters. The first question you have to answer is to find the average height of the characters: mean(starwars$height) ## [1] NA Let’s also take a look at the standard deviation: sd(starwars$height) ## [1] NA It might be more informative to compute these two statistics by species, so for this, we are going to use aggregate(): aggregate(starwars$height, by = list(Species = starwars$species), mean) ## Species x ## 1 Aleena 79.0000 ## 2 Besalisk 198.0000 ## 3 Cerean 198.0000 ## 4 Chagrian 196.0000 ## 5 Clawdite 168.0000 ## 6 Droid NA ## 7 Dug 112.0000 ## 8 Ewok 88.0000 ## 9 Geonosian 183.0000 ## 10 Gungan 208.6667 ## 11 Human NA ## 12 Hutt 175.0000 ## 13 Iktotchi 188.0000 ## 14 Kaleesh 216.0000 ## 15 Kaminoan 221.0000 ## 16 Kel Dor 188.0000 ## 17 Mirialan 168.0000 ## 18 Mon Calamari 180.0000 ## 19 Muun 191.0000 ## 20 Nautolan 196.0000 ## 21 Neimodian 191.0000 ## 22 Pau&#39;an 206.0000 ## 23 Quermian 264.0000 ## 24 Rodian 173.0000 ## 25 Skakoan 193.0000 ## 26 Sullustan 160.0000 ## 27 Tholothian 184.0000 ## 28 Togruta 178.0000 ## 29 Toong 163.0000 ## 30 Toydarian 137.0000 ## 31 Trandoshan 190.0000 ## 32 Twi&#39;lek 179.0000 ## 33 Vulptereen 94.0000 ## 34 Wookiee 231.0000 ## 35 Xexto 122.0000 ## 36 Yoda&#39;s species 66.0000 ## 37 Zabrak 173.0000 Even if you are not familiar with aggregate(), I believe the above lines are quite self-explanatory. You need to provide aggregate() with 3 things; the variable you want to summarize (or only the data frame, if you want to summarize all variables), a list of grouping variables and then the function that will be applied to each subset. You can easily add another grouping variable: aggregate(starwars$height, by = list(Species = starwars$species, Homeworld = starwars$homeworld), mean) ## Species Homeworld x ## 1 Human Alderaan 176.3333 ## 2 Aleena Aleen Minor 79.0000 ## 3 Human Bespin 175.0000 ## 4 Human Bestine IV 180.0000 ## 5 Neimodian Cato Neimoidia 191.0000 ## 6 Cerean Cerea 198.0000 ## 7 Chagrian Champala 196.0000 ## 8 Human Chandrila 150.0000 ## 9 Human Concord Dawn 183.0000 ## 10 Human Corellia 175.0000 ## 11 Human Coruscant 168.5000 ## 12 Tholothian Coruscant 184.0000 ## 13 Zabrak Dathomir 175.0000 ## 14 Kel Dor Dorin 188.0000 ## 15 Ewok Endor 88.0000 ## 16 Human Eriadu 180.0000 ## 17 Geonosian Geonosis 183.0000 ## 18 Nautolan Glee Anselm 196.0000 ## 19 Human Haruun Kal 188.0000 ## 20 Iktotchi Iktotch 188.0000 ## 21 Zabrak Iridonia 171.0000 ## 22 Kaleesh Kalee 216.0000 ## 23 Human Kamino 183.0000 ## 24 Kaminoan Kamino 221.0000 ## 25 Wookiee Kashyyyk 231.0000 ## 26 Dug Malastare 112.0000 ## 27 Mirialan Mirial 168.0000 ## 28 Mon Calamari Mon Cala 180.0000 ## 29 Muun Muunilinst 191.0000 ## 30 Droid Naboo 96.0000 ## 31 Gungan Naboo 208.6667 ## 32 Human Naboo 168.4000 ## 33 Hutt Nal Hutta 175.0000 ## 34 Besalisk Ojom 198.0000 ## 35 Quermian Quermia 264.0000 ## 36 Rodian Rodia 173.0000 ## 37 Twi&#39;lek Ryloth 179.0000 ## 38 Human Serenno 193.0000 ## 39 Togruta Shili 178.0000 ## 40 Skakoan Skako 193.0000 ## 41 Human Socorro 177.0000 ## 42 Human Stewjon 182.0000 ## 43 Sullustan Sullust 160.0000 ## 44 Droid Tatooine 132.0000 ## 45 Human Tatooine 179.2500 ## 46 Toydarian Toydaria 137.0000 ## 47 Trandoshan Trandosha 190.0000 ## 48 Xexto Troiken 122.0000 ## 49 Toong Tund 163.0000 ## 50 Pau&#39;an Utapau 206.0000 ## 51 Vulptereen Vulpter 94.0000 ## 52 Clawdite Zolan 168.0000 or use another function: aggregate(starwars$height, by = list(Species = starwars$species), sd) ## Species x ## 1 Aleena NA ## 2 Besalisk NA ## 3 Cerean NA ## 4 Chagrian NA ## 5 Clawdite NA ## 6 Droid NA ## 7 Dug NA ## 8 Ewok NA ## 9 Geonosian NA ## 10 Gungan 14.189198 ## 11 Human NA ## 12 Hutt NA ## 13 Iktotchi NA ## 14 Kaleesh NA ## 15 Kaminoan 11.313708 ## 16 Kel Dor NA ## 17 Mirialan 2.828427 ## 18 Mon Calamari NA ## 19 Muun NA ## 20 Nautolan NA ## 21 Neimodian NA ## 22 Pau&#39;an NA ## 23 Quermian NA ## 24 Rodian NA ## 25 Skakoan NA ## 26 Sullustan NA ## 27 Tholothian NA ## 28 Togruta NA ## 29 Toong NA ## 30 Toydarian NA ## 31 Trandoshan NA ## 32 Twi&#39;lek 1.414214 ## 33 Vulptereen NA ## 34 Wookiee 4.242641 ## 35 Xexto NA ## 36 Yoda&#39;s species NA ## 37 Zabrak 2.828427 aggregate() returns a data.frame object: class(aggregate(starwars$height, by = list(Species = starwars$species), mean)) ## [1] &quot;data.frame&quot; tapply() is another base R alternative: tapply(starwars$height, list(starwars$species), mean) ## Aleena Besalisk Cerean Chagrian Clawdite ## 79.0000 198.0000 198.0000 196.0000 168.0000 ## Droid Dug Ewok Geonosian Gungan ## NA 112.0000 88.0000 183.0000 208.6667 ## Human Hutt Iktotchi Kaleesh Kaminoan ## NA 175.0000 188.0000 216.0000 221.0000 ## Kel Dor Mirialan Mon Calamari Muun Nautolan ## 188.0000 168.0000 180.0000 191.0000 196.0000 ## Neimodian Pau&#39;an Quermian Rodian Skakoan ## 191.0000 206.0000 264.0000 173.0000 193.0000 ## Sullustan Tholothian Togruta Toong Toydarian ## 160.0000 184.0000 178.0000 163.0000 137.0000 ## Trandoshan Twi&#39;lek Vulptereen Wookiee Xexto ## 190.0000 179.0000 94.0000 231.0000 122.0000 ## Yoda&#39;s species Zabrak ## 66.0000 173.0000 which returns an array object, which is similar to a vector. However, tapply() does not work if you want the mean by species for all the variables in the data frame: tapply(starwars, list(starwars$species), mean) Error in tapply(starwars, list(starwars$species), mean) : arguments must have same length In both cases, you can only specify one function. So if you need the average and the standard deviation you have to do it in two steps. Let’s continue now, by only computing the average height by species, but for males: starwars_males &lt;- subset(starwars, gender == &quot;male&quot;) aggregate(starwars_males$height, by = list(Species = starwars_males$species), mean) ## Species x ## 1 Aleena 79.0000 ## 2 Besalisk 198.0000 ## 3 Cerean 198.0000 ## 4 Chagrian 196.0000 ## 5 Dug 112.0000 ## 6 Ewok 88.0000 ## 7 Geonosian 183.0000 ## 8 Gungan 208.6667 ## 9 Human NA ## 10 Iktotchi 188.0000 ## 11 Kaleesh 216.0000 ## 12 Kaminoan 229.0000 ## 13 Kel Dor 188.0000 ## 14 Mon Calamari 180.0000 ## 15 Muun 191.0000 ## 16 Nautolan 196.0000 ## 17 Neimodian 191.0000 ## 18 Pau&#39;an 206.0000 ## 19 Quermian 264.0000 ## 20 Rodian 173.0000 ## 21 Skakoan 193.0000 ## 22 Sullustan 160.0000 ## 23 Toong 163.0000 ## 24 Toydarian 137.0000 ## 25 Trandoshan 190.0000 ## 26 Twi&#39;lek 180.0000 ## 27 Vulptereen 94.0000 ## 28 Wookiee 231.0000 ## 29 Xexto 122.0000 ## 30 Yoda&#39;s species 66.0000 ## 31 Zabrak 173.0000 I first use subset() to create a subset of the data in which I only kept males. Then, I rerun the analysis from before again. subset() can also be used to select columns. So if you want the average of the height and mass for males, you could do something like this: starwars_males_height_mass &lt;- subset(starwars, gender == &quot;male&quot;, select = c(height, mass, species)) aggregate(starwars_males_height_mass, by = list(Species = starwars_males_height_mass$species), mean) ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Warning in mean.default(X[[i]], ...): argument is not numeric or logical: ## returning NA ## Species height mass species ## 1 Aleena 79.0000 15 NA ## 2 Besalisk 198.0000 102 NA ## 3 Cerean 198.0000 82 NA ## 4 Chagrian 196.0000 NA NA ## 5 Dug 112.0000 40 NA ## 6 Ewok 88.0000 20 NA ## 7 Geonosian 183.0000 80 NA ## 8 Gungan 208.6667 NA NA ## 9 Human NA NA NA ## 10 Iktotchi 188.0000 NA NA ## 11 Kaleesh 216.0000 159 NA ## 12 Kaminoan 229.0000 88 NA ## 13 Kel Dor 188.0000 80 NA ## 14 Mon Calamari 180.0000 83 NA ## 15 Muun 191.0000 NA NA ## 16 Nautolan 196.0000 87 NA ## 17 Neimodian 191.0000 90 NA ## 18 Pau&#39;an 206.0000 80 NA ## 19 Quermian 264.0000 NA NA ## 20 Rodian 173.0000 74 NA ## 21 Skakoan 193.0000 48 NA ## 22 Sullustan 160.0000 68 NA ## 23 Toong 163.0000 65 NA ## 24 Toydarian 137.0000 NA NA ## 25 Trandoshan 190.0000 113 NA ## 26 Twi&#39;lek 180.0000 NA NA ## 27 Vulptereen 94.0000 45 NA ## 28 Wookiee 231.0000 124 NA ## 29 Xexto 122.0000 NA NA ## 30 Yoda&#39;s species 66.0000 17 NA ## 31 Zabrak 173.0000 NA NA This is starting to get a bit verbose, but it is quite easy to follow and very powerful. It certainly beats having to write loops to achieve the same thing. Let’s now consider this new dataset: survey_data_base ## id var1 var2 var3 ## 1 1 1.0 0.2 0.3 ## 2 2 1.4 1.9 4.1 ## 3 3 0.1 2.8 8.9 ## 4 4 1.7 1.9 7.6 I will explain later where this comes from. Depending on what you want to do with this data, it is not in the right shape. So let’s reshape it, using the aptly-called reshape() command: survey_data_long &lt;- reshape(survey_data_base, varying = list(2:4), v.names = &quot;variable&quot;, direction = &quot;long&quot;) We can now easily compute the average of variable for each id: aggregate(survey_data_long$variable, by = list(Id = survey_data_long$id), mean) ## Id x ## 1 1 0.500000 ## 2 2 2.466667 ## 3 3 3.933333 ## 4 4 3.733333 There is also the possiblity to merge two datasets with merge(). I won’t go into that however. As you can see, R comes with very powerful functions right out of the box, ready to use. When I was studying, unfortunately, my professors had been brought up on FORTRAN loops, so we had to do to all this using loops (not reshaping, thankfully), which was not so easy. Now that we have seen how base R works, let’s redo the analysis using {tidyverse} verbs. But before deep diving into the {tidyverse}, let’s take a moment to discuss about our lord and saviour, %&gt;%. 5.2 Smoking is bad for you, but pipes are your friend The title of this section might sound weird at first, but by the end of it, you’ll get this (terrible) pun. You probably know the following painting by René Magritte, La trahison des images: It turns out there’s an R package from the tidyverse that is called magrittr. What does this package do? It brings pipes to R. Pipes are a concept from the Unix operating system; if you’re using a GNU+Linux distribution or macOS, you’re basically using a modern unix (that’s an oversimplification, but I’m an economist by training, and outrageously oversimplifying things is what we do, deal with it). The idea of pipes is to take the output of a command, and feed it as the input of another command. The magrittr package brings pipes to R, by using the weird looking %&gt;%. Try the following: library(magrittr) 16 %&gt;% sqrt ## [1] 4 This looks quite weird, but you probably understand what happened; 16 got fed as the first argument of the function sqrt(). You can chain multiple functions: 16 %&gt;% sqrt %&gt;% `+`(18) ## [1] 22 The output of 16 (16) got fed to sqrt(), and the output of sqrt(16) (4) got fed to +(18) (22). Without %&gt;% you’d write the line just above like this: sqrt(16) + 18 ## [1] 22 It might not be very clear right now why this is useful, but the %&gt;% is probably one of the most useful infix operators, because when using packages from the tidyverse, you will naturally want to chain a lot of functions together. Without the %&gt;% it would become messy very fast. %&gt;% is not the only pipe operator in magrittr. There’s %T%, %&lt;&gt;% and %$%. All have their uses, but are basically shortcuts to some common tasks with %&gt;% plus another function. Which means that you can live without them, and because of this, I will not discuss them. 5.3 The {tidyverse}’s enfant prodige: {dplyr} The best way to get started with the tidyverse packages is to get to know {dplyr}. {dplyr} prodives a lot of very useful functions that makes it very easy to get discriptive statistics or add new columns to your data. 5.3.1 A first taste of data manipulation with {dplyr} This section will walk you through a typical analysis using {dplyr} funcitons. Just go with it; I will give more details in the next sections. First, let’s load dplyr and the included starwars dataset. Let’s also take a look at the first 5 lines of the dataset: library(dplyr) data(starwars) head(starwars) ## # A tibble: 6 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke… 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; ## 4 Dart… 202 136 none white yellow 41.9 male ## 5 Leia… 150 49 brown light brown 19 female ## 6 Owen… 178 120 brown, gr… light blue 52 male ## # ... with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; data(starwars) loads the example dataset called starwars that is included in the package dplyr. As I said earlier, this is just an example; you could have loaded an external dataset, from a .csv file for instance. This does not matter for what comes next. R includes a lot of functions for descriptive statistics, such as mean(), sd(), cov(), and many more. What dplyr brings to the table (among other niceties) is the possibility to apply these functions to the dataset easily. For example, imagine you want the average height of everyone in the dataset. Using the basic R functions, you could write this: mean(starwars$height) ## [1] NA starwars$height means that the user wants to access the column called height from the dataset starwars. Remember that the $ symbol is how you access elements of a named list. This is the same for columns of datasets as you can see. This is then given as an argument to the function mean(). But what if the user wants the average height by species? Before dplyr, a solution to this simple problem would have required more than a single command. Now this is as easy as: starwars %&gt;% group_by(species) %&gt;% summarise(mean(height)) ## # A tibble: 38 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Clawdite 168 ## 6 Droid NA ## 7 Dug 112 ## 8 Ewok 88 ## 9 Geonosian 183 ## 10 Gungan 209. ## # ... with 28 more rows The usefulness of the %&gt;% (pipe operator) becomes apparent now. Without it, one would write instead: summarise(group_by(starwars, species), mean(height)) ## # A tibble: 38 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Clawdite 168 ## 6 Droid NA ## 7 Dug 112 ## 8 Ewok 88 ## 9 Geonosian 183 ## 10 Gungan 209. ## # ... with 28 more rows as you can clearly see, it is much more difficult to read. Imagine now that I want the average height by species, but only for males. Again, this is very easy using %&gt;%: starwars %&gt;% filter(gender == &quot;male&quot;) %&gt;% group_by(species) %&gt;% summarise(mean(height)) ## # A tibble: 32 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Dug 112 ## 6 Ewok 88 ## 7 Geonosian 183 ## 8 Gungan 209. ## 9 Human NA ## 10 Iktotchi 188 ## # ... with 22 more rows Again, the %&gt;% makes the above lines of code very easy to read. Without it, one would need to write: summarise(group_by(filter(starwars, gender == &quot;male&quot;), species), mean(height)) ## # A tibble: 32 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Dug 112 ## 6 Ewok 88 ## 7 Geonosian 183 ## 8 Gungan 209. ## 9 Human NA ## 10 Iktotchi 188 ## # ... with 22 more rows I think you agree with me that this is not very readable. One way to make it more readable would be to save intermediary variables: filtered_data &lt;- filter(starwars, gender == &quot;male&quot;) grouped_data &lt;- group_by(filter(starwars, gender == &quot;male&quot;), species) summarise(grouped_data, mean(height)) ## # A tibble: 32 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Dug 112 ## 6 Ewok 88 ## 7 Geonosian 183 ## 8 Gungan 209. ## 9 Human NA ## 10 Iktotchi 188 ## # ... with 22 more rows But this can get very tedious. Once you’re used to %&gt;%, you won’t go back to not use it. Before continuing and to make things clearer; filter(), group_by() and summarise() are functions that are included in dplyr. %&gt;% is actually a function from magrittr, but this package gets loaded on the fly when you load dplyr, so you do not need to worry about it. mean() is a function native to R. The result of all these operations that use dplyr functions are actually other datasets, or tibbles. This means that you can save them in variable, and then work with these as any other datasets. mean_height &lt;- starwars %&gt;% group_by(species) %&gt;% summarise(mean(height)) class(mean_height) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; head(mean_height) ## # A tibble: 6 x 2 ## species `mean(height)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 Aleena 79 ## 2 Besalisk 198 ## 3 Cerean 198 ## 4 Chagrian 196 ## 5 Clawdite 168 ## 6 Droid NA You could then write this data to disk using rio::export() for instance. If you need more than the mean of the height, you can keep adding as many functions as needed: summary_table &lt;- starwars %&gt;% group_by(species) %&gt;% summarise(ave_height = mean(height), var_height = var(height), n_obs = n()) print(summary_table) ## # A tibble: 38 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Aleena 79 NA 1 ## 2 Besalisk 198 NA 1 ## 3 Cerean 198 NA 1 ## 4 Chagrian 196 NA 1 ## 5 Clawdite 168 NA 1 ## 6 Droid NA NA 5 ## 7 Dug 112 NA 1 ## 8 Ewok 88 NA 1 ## 9 Geonosian 183 NA 1 ## 10 Gungan 209. 201. 3 ## # ... with 28 more rows I’ve added more functions, namely var(), to get the variance of height, and n(), which is a function from dplyr, not base R, to get the number of observations. This is quite useful, because we see that for a lot of species we only have one single individual! Let’s focus on the species for which we have more than 1 individual. Since we save all the previous operations (which produce a tibble) in a variable, we can keep going from there: summary_table2 &lt;- summary_table %&gt;% filter(n_obs &gt; 1) print(summary_table2) ## # A tibble: 9 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid NA NA 5 ## 2 Gungan 209. 201. 3 ## 3 Human NA NA 35 ## 4 Kaminoan 221 128 2 ## 5 Mirialan 168 8 2 ## 6 Twi&#39;lek 179 2 2 ## 7 Wookiee 231 18 2 ## 8 Zabrak 173 8 2 ## 9 &lt;NA&gt; NA NA 5 There’s a lot of NAs; this is because by default, mean() and var() return NA if even one single observation is NA. This is good, because it forces you to look at the data to see what is going on. If you would get a number, even if there were NAs you could very easily miss these missing values. It is better for functions to fail early and often than the opposite. mean() and var() have a na.rm option that the user can set to TRUE to get the result by ignoring the NAs: starwars %&gt;% group_by(species) %&gt;% summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %&gt;% filter(n_obs &gt; 1) ## # A tibble: 9 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid 140 2705. 5 ## 2 Gungan 209. 201. 3 ## 3 Human 177. 157. 35 ## 4 Kaminoan 221 128 2 ## 5 Mirialan 168 8 2 ## 6 Twi&#39;lek 179 2 2 ## 7 Wookiee 231 18 2 ## 8 Zabrak 173 8 2 ## 9 &lt;NA&gt; 160 1826 5 In the code above, I have combined the two previous steps to get the result I’m interested in. There’s a line in the final output that says NA for the species. Let’s go back to the raw data and find these lines: starwars %&gt;% filter(is.na(species)) ## # A tibble: 5 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Ric … 183 NA brown fair blue NA male ## 2 Quar… 183 NA black dark brown 62 male ## 3 R4-P… 96 NA none silver, r… red, blue NA female ## 4 Sly … 178 48 none pale white NA female ## 5 Capt… NA NA unknown unknown unknown NA female ## # ... with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; To test for NA, one uses the function is.na() not something like species == &quot;NA&quot; or anything like that. !is.na() does the opposite: starwars %&gt;% filter(!is.na(species)) ## # A tibble: 82 x 13 ## name height mass hair_color skin_color eye_color birth_year gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke… 172 77 blond fair blue 19 male ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 &lt;NA&gt; ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 &lt;NA&gt; ## 4 Dart… 202 136 none white yellow 41.9 male ## 5 Leia… 150 49 brown light brown 19 female ## 6 Owen… 178 120 brown, gr… light blue 52 male ## 7 Beru… 165 75 brown light blue 47 female ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA &lt;NA&gt; ## 9 Bigg… 183 84 black light brown 24 male ## 10 Obi-… 182 77 auburn, w… fair blue-gray 57 male ## # ... with 72 more rows, and 5 more variables: homeworld &lt;chr&gt;, ## # species &lt;chr&gt;, films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; The ! function negates a predicate function (a predicate function is a function that returns TRUE or FALSE). We can then rerun our analysis from before: starwars %&gt;% filter(!is.na(species)) %&gt;% group_by(species) %&gt;% summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %&gt;% filter(n_obs &gt; 1) ## # A tibble: 8 x 4 ## species ave_height var_height n_obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid 140 2705. 5 ## 2 Gungan 209. 201. 3 ## 3 Human 177. 157. 35 ## 4 Kaminoan 221 128 2 ## 5 Mirialan 168 8 2 ## 6 Twi&#39;lek 179 2 2 ## 7 Wookiee 231 18 2 ## 8 Zabrak 173 8 2 And why not compute the same table, but first add another stratifying variable? starwars %&gt;% filter(!is.na(species)) %&gt;% group_by(species, gender) %&gt;% summarise(ave_height = mean(height, na.rm = TRUE), var_height = var(height, na.rm = TRUE), n_obs = n()) %&gt;% filter(n_obs &gt; 1) ## # A tibble: 8 x 5 ## # Groups: species [6] ## species gender ave_height var_height n_obs ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Droid none 200 NA 2 ## 2 Droid &lt;NA&gt; 120 1657 3 ## 3 Gungan male 209. 201. 3 ## 4 Human female 160. 48.8 9 ## 5 Human male 182. 67.1 26 ## 6 Mirialan female 168 8 2 ## 7 Wookiee male 231 18 2 ## 8 Zabrak male 173 8 2 Ok, that’s it for a first taste. We have already discovered some very useful {dplyr} functions, filter(), group_by() and summarise summarise(). Now, we are going to learn more about these functions in more detail. 5.3.2 Filter the rows of a dataset with filter() We’re going to use the Gasoline dataset from the plm package, so install that first: install.packages(&quot;plm&quot;) Then load the required data: data(Gasoline, package = &quot;plm&quot;) and load dplyr: library(dplyr) This dataset gives the consumption of gasoline for 18 countries from 1960 to 1978. When you load the data like this, it is a standard data.frame. dplyr functions can be used on standard data.frame objects, but also on tibbles. tibbles are just like data frame, but with a better print method (and other niceties). I’ll discuss the {tibble} package later, but for now, let’s convert the data to a tibble and change its name: gasoline &lt;- as_tibble(Gasoline) filter() is pretty straightforward. What if you would like to subset the data to focus on the year 1969? Simple: filter(gasoline, year == 1969) ## # A tibble: 18 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## 2 BELGIUM 1969 3.85 -5.86 -0.355 -8.52 ## 3 CANADA 1969 4.86 -5.56 -1.04 -8.10 ## 4 DENMARK 1969 4.17 -5.72 -0.407 -8.47 ## 5 FRANCE 1969 3.77 -5.84 -0.315 -8.37 ## 6 GERMANY 1969 3.90 -5.83 -0.589 -8.44 ## 7 GREECE 1969 4.89 -6.59 -0.180 -10.7 ## 8 IRELAND 1969 4.21 -6.38 -0.272 -8.95 ## 9 ITALY 1969 3.74 -6.28 -0.248 -8.67 ## 10 JAPAN 1969 4.52 -6.16 -0.417 -9.61 ## 11 NETHERLA 1969 3.99 -5.88 -0.417 -8.63 ## 12 NORWAY 1969 4.09 -5.74 -0.338 -8.69 ## 13 SPAIN 1969 3.99 -5.60 0.669 -9.72 ## 14 SWEDEN 1969 3.99 -7.77 -2.73 -8.20 ## 15 SWITZERL 1969 4.21 -5.91 -0.918 -8.47 ## 16 TURKEY 1969 5.72 -7.39 -0.298 -12.5 ## 17 U.K. 1969 3.95 -6.03 -0.383 -8.47 ## 18 U.S.A. 1969 4.84 -5.41 -1.22 -7.79 Let’s use %&gt;%, since we’re familiar with it now: gasoline %&gt;% filter(year == 1969) ## # A tibble: 18 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## 2 BELGIUM 1969 3.85 -5.86 -0.355 -8.52 ## 3 CANADA 1969 4.86 -5.56 -1.04 -8.10 ## 4 DENMARK 1969 4.17 -5.72 -0.407 -8.47 ## 5 FRANCE 1969 3.77 -5.84 -0.315 -8.37 ## 6 GERMANY 1969 3.90 -5.83 -0.589 -8.44 ## 7 GREECE 1969 4.89 -6.59 -0.180 -10.7 ## 8 IRELAND 1969 4.21 -6.38 -0.272 -8.95 ## 9 ITALY 1969 3.74 -6.28 -0.248 -8.67 ## 10 JAPAN 1969 4.52 -6.16 -0.417 -9.61 ## 11 NETHERLA 1969 3.99 -5.88 -0.417 -8.63 ## 12 NORWAY 1969 4.09 -5.74 -0.338 -8.69 ## 13 SPAIN 1969 3.99 -5.60 0.669 -9.72 ## 14 SWEDEN 1969 3.99 -7.77 -2.73 -8.20 ## 15 SWITZERL 1969 4.21 -5.91 -0.918 -8.47 ## 16 TURKEY 1969 5.72 -7.39 -0.298 -12.5 ## 17 U.K. 1969 3.95 -6.03 -0.383 -8.47 ## 18 U.S.A. 1969 4.84 -5.41 -1.22 -7.79 You can also filter more than just one year, by using the %in% operator: gasoline %&gt;% filter(year %in% seq(1969, 1973)) ## # A tibble: 90 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## 2 AUSTRIA 1970 4.08 -6.08 -0.597 -8.73 ## 3 AUSTRIA 1971 4.11 -6.04 -0.654 -8.64 ## 4 AUSTRIA 1972 4.13 -5.98 -0.596 -8.54 ## 5 AUSTRIA 1973 4.20 -5.90 -0.594 -8.49 ## 6 BELGIUM 1969 3.85 -5.86 -0.355 -8.52 ## 7 BELGIUM 1970 3.87 -5.80 -0.378 -8.45 ## 8 BELGIUM 1971 3.87 -5.76 -0.399 -8.41 ## 9 BELGIUM 1972 3.91 -5.71 -0.311 -8.36 ## 10 BELGIUM 1973 3.90 -5.64 -0.373 -8.31 ## # ... with 80 more rows It is also possible use between(), a helper function: gasoline %&gt;% filter(between(year, 1969, 1973)) ## # A tibble: 90 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## 2 AUSTRIA 1970 4.08 -6.08 -0.597 -8.73 ## 3 AUSTRIA 1971 4.11 -6.04 -0.654 -8.64 ## 4 AUSTRIA 1972 4.13 -5.98 -0.596 -8.54 ## 5 AUSTRIA 1973 4.20 -5.90 -0.594 -8.49 ## 6 BELGIUM 1969 3.85 -5.86 -0.355 -8.52 ## 7 BELGIUM 1970 3.87 -5.80 -0.378 -8.45 ## 8 BELGIUM 1971 3.87 -5.76 -0.399 -8.41 ## 9 BELGIUM 1972 3.91 -5.71 -0.311 -8.36 ## 10 BELGIUM 1973 3.90 -5.64 -0.373 -8.31 ## # ... with 80 more rows To select non-consecutive years: gasoline %&gt;% filter(year %in% c(1969, 1973, 1977)) ## # A tibble: 54 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## 2 AUSTRIA 1973 4.20 -5.90 -0.594 -8.49 ## 3 AUSTRIA 1977 3.93 -5.83 -0.422 -8.25 ## 4 BELGIUM 1969 3.85 -5.86 -0.355 -8.52 ## 5 BELGIUM 1973 3.90 -5.64 -0.373 -8.31 ## 6 BELGIUM 1977 3.85 -5.56 -0.432 -8.14 ## 7 CANADA 1969 4.86 -5.56 -1.04 -8.10 ## 8 CANADA 1973 4.90 -5.41 -1.13 -7.94 ## 9 CANADA 1977 4.81 -5.34 -1.07 -7.77 ## 10 DENMARK 1969 4.17 -5.72 -0.407 -8.47 ## # ... with 44 more rows %in% tests if an object is part of a set. 5.3.3 Select columns with select() While filter() allows you to keep or discard rows of data, select() allows you to keep or discard entire columns. To keep columns: gasoline %&gt;% select(country, year, lrpmg) ## # A tibble: 342 x 3 ## country year lrpmg ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 -0.335 ## 2 AUSTRIA 1961 -0.351 ## 3 AUSTRIA 1962 -0.380 ## 4 AUSTRIA 1963 -0.414 ## 5 AUSTRIA 1964 -0.445 ## 6 AUSTRIA 1965 -0.497 ## 7 AUSTRIA 1966 -0.467 ## 8 AUSTRIA 1967 -0.506 ## 9 AUSTRIA 1968 -0.522 ## 10 AUSTRIA 1969 -0.559 ## # ... with 332 more rows To discard them: gasoline %&gt;% select(-country, -year, -lrpmg) ## # A tibble: 342 x 3 ## lgaspcar lincomep lcarpcap ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.17 -6.47 -9.77 ## 2 4.10 -6.43 -9.61 ## 3 4.07 -6.41 -9.46 ## 4 4.06 -6.37 -9.34 ## 5 4.04 -6.32 -9.24 ## 6 4.03 -6.29 -9.12 ## 7 4.05 -6.25 -9.02 ## 8 4.05 -6.23 -8.93 ## 9 4.05 -6.21 -8.85 ## 10 4.05 -6.15 -8.79 ## # ... with 332 more rows To rename them: gasoline %&gt;% select(country, date = year, lrpmg) ## # A tibble: 342 x 3 ## country date lrpmg ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 -0.335 ## 2 AUSTRIA 1961 -0.351 ## 3 AUSTRIA 1962 -0.380 ## 4 AUSTRIA 1963 -0.414 ## 5 AUSTRIA 1964 -0.445 ## 6 AUSTRIA 1965 -0.497 ## 7 AUSTRIA 1966 -0.467 ## 8 AUSTRIA 1967 -0.506 ## 9 AUSTRIA 1968 -0.522 ## 10 AUSTRIA 1969 -0.559 ## # ... with 332 more rows There’s also rename(): gasoline %&gt;% rename(date = year) ## # A tibble: 342 x 6 ## country date lgaspcar lincomep lrpmg lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows rename() does not do any kind of selection, but just renames. You can also use select() to re-order columns: gasoline %&gt;% select(year, country, lrpmg, everything()) ## # A tibble: 342 x 6 ## year country lrpmg lgaspcar lincomep lcarpcap ## * &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1960 AUSTRIA -0.335 4.17 -6.47 -9.77 ## 2 1961 AUSTRIA -0.351 4.10 -6.43 -9.61 ## 3 1962 AUSTRIA -0.380 4.07 -6.41 -9.46 ## 4 1963 AUSTRIA -0.414 4.06 -6.37 -9.34 ## 5 1964 AUSTRIA -0.445 4.04 -6.32 -9.24 ## 6 1965 AUSTRIA -0.497 4.03 -6.29 -9.12 ## 7 1966 AUSTRIA -0.467 4.05 -6.25 -9.02 ## 8 1967 AUSTRIA -0.506 4.05 -6.23 -8.93 ## 9 1968 AUSTRIA -0.522 4.05 -6.21 -8.85 ## 10 1969 AUSTRIA -0.559 4.05 -6.15 -8.79 ## # ... with 332 more rows everything() is a helper function, and there’s also starts_with(), and ends_with(). For example, what if we are only interested in columns whose name start with “l”? gasoline %&gt;% select(starts_with(&quot;l&quot;)) ## # A tibble: 342 x 4 ## lgaspcar lincomep lrpmg lcarpcap ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.17 -6.47 -0.335 -9.77 ## 2 4.10 -6.43 -0.351 -9.61 ## 3 4.07 -6.41 -0.380 -9.46 ## 4 4.06 -6.37 -0.414 -9.34 ## 5 4.04 -6.32 -0.445 -9.24 ## 6 4.03 -6.29 -0.497 -9.12 ## 7 4.05 -6.25 -0.467 -9.02 ## 8 4.05 -6.23 -0.506 -8.93 ## 9 4.05 -6.21 -0.522 -8.85 ## 10 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows ends_with() works in a similar fashion. There is also contains(): gasoline %&gt;% select(country, year, contains(&quot;car&quot;)) ## # A tibble: 342 x 4 ## country year lgaspcar lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -9.77 ## 2 AUSTRIA 1961 4.10 -9.61 ## 3 AUSTRIA 1962 4.07 -9.46 ## 4 AUSTRIA 1963 4.06 -9.34 ## 5 AUSTRIA 1964 4.04 -9.24 ## 6 AUSTRIA 1965 4.03 -9.12 ## 7 AUSTRIA 1966 4.05 -9.02 ## 8 AUSTRIA 1967 4.05 -8.93 ## 9 AUSTRIA 1968 4.05 -8.85 ## 10 AUSTRIA 1969 4.05 -8.79 ## # ... with 332 more rows Another verb, similar to select(), is pull(). Let’s compare the two: gasoline %&gt;% select(lrpmg) ## # A tibble: 342 x 1 ## lrpmg ## * &lt;dbl&gt; ## 1 -0.335 ## 2 -0.351 ## 3 -0.380 ## 4 -0.414 ## 5 -0.445 ## 6 -0.497 ## 7 -0.467 ## 8 -0.506 ## 9 -0.522 ## 10 -0.559 ## # ... with 332 more rows gasoline %&gt;% pull(lrpmg) ## [1] -0.33454761 -0.35132761 -0.37951769 -0.41425139 -0.44533536 ## [6] -0.49706066 -0.46683773 -0.50588340 -0.52241255 -0.55911051 ## [11] -0.59656122 -0.65445914 -0.59633184 -0.59444681 -0.46602693 ## [16] -0.45414221 -0.50008372 -0.42191563 -0.46960312 -0.16570961 ## [21] -0.17173098 -0.22229138 -0.25046225 -0.27591057 -0.34493695 ## [26] -0.23639770 -0.26699499 -0.31116076 -0.35480852 -0.37794044 ## [31] -0.39922992 -0.31064584 -0.37309192 -0.36223563 -0.36430848 ## [36] -0.37896584 -0.43164133 -0.59094964 -0.97210650 -0.97229024 ## [41] -0.97860756 -1.01904791 -1.00285696 -1.01712549 -1.01694436 ## [46] -1.02359713 -1.01984524 -1.03686389 -1.06733308 -1.05803676 ## [51] -1.09966703 -1.13316142 -1.12379997 -1.18568427 -1.06179659 ## [56] -1.07084448 -1.07495073 -0.19570260 -0.25361844 -0.21875400 ## [61] -0.24800936 -0.30654923 -0.32701542 -0.39618846 -0.44257369 ## [66] -0.35204752 -0.40687922 -0.44046082 -0.45473954 -0.49918863 ## [71] -0.43257185 -0.42517720 -0.39395431 -0.35361534 -0.35690917 ## [76] -0.29068135 -0.01959833 -0.02386000 -0.06892022 -0.13792900 ## [81] -0.19784646 -0.23365325 -0.26427164 -0.29405795 -0.32316179 ## [86] -0.31519087 -0.33384616 -0.37945667 -0.40781642 -0.47503429 ## [91] -0.21698191 -0.25838174 -0.24651309 -0.22550681 -0.38075942 ## [96] -0.18591078 -0.23095384 -0.34384171 -0.37464672 -0.39965256 ## [101] -0.43987825 -0.54000197 -0.54998139 -0.43824222 -0.58923137 ## [106] -0.63329520 -0.67176311 -0.71797458 -0.72587521 -0.56982876 ## [111] -0.56482380 -0.62481298 -0.59761210 -0.62817279 -0.08354740 ## [116] -0.10421997 -0.13320751 -0.15653576 -0.18051772 -0.07793999 ## [121] -0.11491900 -0.13775849 -0.15375883 -0.17986997 -0.20252426 ## [126] -0.06761078 -0.11973059 -0.05191029 0.31625351 0.20631574 ## [131] 0.19319312 0.23502961 0.16896037 -0.07648118 -0.12040874 ## [136] -0.14160039 -0.15232915 -0.24428212 -0.16899366 -0.21071901 ## [141] -0.17383533 -0.21339314 -0.27162842 -0.32069023 -0.36041067 ## [146] -0.42393131 -0.64567297 -0.55343875 -0.64126416 -0.66134256 ## [151] -0.56011483 -0.66277808 0.16507708 -0.08559038 -0.18351291 ## [156] -0.26541405 -0.42609643 -0.32712637 -0.24887418 -0.19160048 ## [161] -0.20616656 -0.24756681 -0.23271512 -0.14822267 -0.21508857 ## [166] -0.32508487 -0.22290860 -0.03270913 0.10292798 0.16418805 ## [171] 0.03482212 -0.14532271 -0.14874940 -0.18731459 -0.19996473 ## [176] -0.20386433 -0.23786571 -0.27411537 -0.33167240 -0.35126918 ## [181] -0.41685019 -0.46203546 -0.43941354 -0.52100094 -0.46270739 ## [186] -0.19090636 -0.15948473 -0.20726559 -0.21904447 -0.28707638 ## [191] -0.20148480 -0.21599265 -0.25968008 -0.29718661 -0.36929389 ## [196] -0.34197503 -0.34809007 -0.31232019 -0.44450431 -0.41694955 ## [201] -0.39954544 -0.43393029 -0.31903240 -0.42728193 -0.35253685 ## [206] -0.43426178 -0.42908393 -0.46474195 -0.55791459 -0.13968957 ## [211] -0.15790514 -0.19908809 -0.23263318 -0.26374731 -0.31593124 ## [216] -0.25011726 -0.26555763 -0.30036775 -0.33823045 -0.39072560 ## [221] -0.30127223 -0.26023925 -0.33880765 -0.15100924 -0.32726757 ## [226] -0.35308752 -0.38255762 -0.30765935 1.12531070 1.10956235 ## [231] 1.05700394 0.97683534 0.91532254 0.81666055 0.75671751 ## [236] 0.74130811 0.70386453 0.66948950 0.61217208 0.60699563 ## [241] 0.53716844 0.43377166 0.52492096 0.62955545 0.68385409 ## [246] 0.52627167 0.62141374 -2.52041588 -2.57148340 -2.53448158 ## [251] -2.60511224 -2.65801626 -2.64476790 -2.63901460 -2.65609762 ## [256] -2.67918662 -2.73190414 -2.73359211 -2.77884554 -2.77467537 ## [261] -2.84142900 -2.79840677 -2.76731461 -2.82294480 -2.82005896 ## [266] -2.89649671 -0.82321833 -0.86558473 -0.82218510 -0.86012004 ## [271] -0.86767682 -0.90528668 -0.85956665 -0.90656671 -0.87232520 ## [276] -0.91812162 -0.96344188 -1.03746081 -0.94015345 -0.86722756 ## [281] -0.88692306 -0.88475790 -0.90736205 -0.91147285 -1.03208811 ## [286] -0.25340821 -0.34252375 -0.40820484 -0.22499174 -0.25219448 ## [291] -0.29347614 -0.35640491 -0.33515022 -0.36507386 -0.29845417 ## [296] -0.39882648 -0.30461880 -0.54637424 -0.69162023 -0.33965308 ## [301] -0.53794675 -0.75141027 -0.95552413 -0.35290961 -0.39108581 ## [306] -0.45185308 -0.42287690 -0.46335147 -0.49577430 -0.42654915 ## [311] -0.47068145 -0.44118786 -0.46245080 -0.38332457 -0.41899030 ## [316] -0.46135978 -0.52777246 -0.56529718 -0.56641296 -0.20867428 ## [321] -0.27354010 -0.50886285 -0.78652911 -1.12111489 -1.14624034 ## [326] -1.16187449 -1.17991524 -1.20026222 -1.19428750 -1.19026054 ## [331] -1.18991215 -1.20730059 -1.22314272 -1.25176347 -1.28131560 ## [336] -1.33116930 -1.29066967 -1.23146686 -1.20037697 -1.15468197 ## [341] -1.17590974 -1.21206183 pull(), unlike select(), does not return a tibble, but only the column you want. 5.3.4 Group the observations of your dataset with group_by() group_by() is a very useful verb; as the name implies, it allows you to create groups and then, for example, compute descriptive statistics by groups. For example, let’s group our data by country: gasoline %&gt;% group_by(country) ## # A tibble: 342 x 6 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows It looks like nothing much happened, but if you look at the second line of the output you can read the following: ## # Groups: country [18] this means that the data is grouped, and every computation you will do now will take these groups into account. It is also possible to group by more than one variable: gasoline %&gt;% group_by(country, year) ## # A tibble: 342 x 6 ## # Groups: country, year [342] ## country year lgaspcar lincomep lrpmg lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows and so on. You can then also ungroup: gasoline %&gt;% group_by(country, year) %&gt;% ungroup() ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows Once your data is grouped, the operations that will follow will be executed inside each group. 5.3.5 Get summary statistics with summarise() Ok, now that we have learned the basic verbs, we can start to do more interesting stuff. For example, one might want to compute the average gasoline consumption in each country, for the whole period: gasoline %&gt;% group_by(country) %&gt;% summarise(mean(lgaspcar)) ## # A tibble: 18 x 2 ## country `mean(lgaspcar)` ## &lt;fct&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 ## 2 BELGIUM 3.92 ## 3 CANADA 4.86 ## 4 DENMARK 4.19 ## 5 FRANCE 3.82 ## 6 GERMANY 3.89 ## 7 GREECE 4.88 ## 8 IRELAND 4.23 ## 9 ITALY 3.73 ## 10 JAPAN 4.70 ## 11 NETHERLA 4.08 ## 12 NORWAY 4.11 ## 13 SPAIN 4.06 ## 14 SWEDEN 4.01 ## 15 SWITZERL 4.24 ## 16 TURKEY 5.77 ## 17 U.K. 3.98 ## 18 U.S.A. 4.82 mean() was given as an argument to summarise(), which is a dplyr verb. What we get is another tibble, that contains the variable we used to group, as well as the average per country. We can also rename this column: gasoline %&gt;% group_by(country) %&gt;% summarise(mean_gaspcar = mean(lgaspcar)) ## # A tibble: 18 x 2 ## country mean_gaspcar ## &lt;fct&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 ## 2 BELGIUM 3.92 ## 3 CANADA 4.86 ## 4 DENMARK 4.19 ## 5 FRANCE 3.82 ## 6 GERMANY 3.89 ## 7 GREECE 4.88 ## 8 IRELAND 4.23 ## 9 ITALY 3.73 ## 10 JAPAN 4.70 ## 11 NETHERLA 4.08 ## 12 NORWAY 4.11 ## 13 SPAIN 4.06 ## 14 SWEDEN 4.01 ## 15 SWITZERL 4.24 ## 16 TURKEY 5.77 ## 17 U.K. 3.98 ## 18 U.S.A. 4.82 and because the output is a tibble, we can continue to use dplyr verbs on it: gasoline %&gt;% group_by(country) %&gt;% summarise(mean_gaspcar = mean(lgaspcar)) %&gt;% filter(country == &quot;france&quot;) ## # A tibble: 0 x 2 ## # ... with 2 variables: country &lt;fct&gt;, mean_gaspcar &lt;dbl&gt; summarise() is a very useful verb. For example, we can compute several descriptive statistics at once: gasoline %&gt;% group_by(country) %&gt;% summarise(mean_gaspcar = mean(lgaspcar), sd_gaspcar = sd(lgaspcar), max_gaspcar = max(lgaspcar), min_gaspcar = min(lgaspcar)) ## # A tibble: 18 x 5 ## country mean_gaspcar sd_gaspcar max_gaspcar min_gaspcar ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 0.0693 4.20 3.92 ## 2 BELGIUM 3.92 0.103 4.16 3.82 ## 3 CANADA 4.86 0.0262 4.90 4.81 ## 4 DENMARK 4.19 0.158 4.50 4.00 ## 5 FRANCE 3.82 0.0499 3.91 3.75 ## 6 GERMANY 3.89 0.0239 3.93 3.85 ## 7 GREECE 4.88 0.255 5.38 4.48 ## 8 IRELAND 4.23 0.0437 4.33 4.16 ## 9 ITALY 3.73 0.220 4.05 3.38 ## 10 JAPAN 4.70 0.684 6.00 3.95 ## 11 NETHERLA 4.08 0.286 4.65 3.71 ## 12 NORWAY 4.11 0.123 4.44 3.96 ## 13 SPAIN 4.06 0.317 4.75 3.62 ## 14 SWEDEN 4.01 0.0364 4.07 3.91 ## 15 SWITZERL 4.24 0.102 4.44 4.05 ## 16 TURKEY 5.77 0.329 6.16 5.14 ## 17 U.K. 3.98 0.0479 4.10 3.91 ## 18 U.S.A. 4.82 0.0219 4.86 4.79 Because the output is a tibble, you can save it in a variable of course: desc_gasoline &lt;- gasoline %&gt;% group_by(country) %&gt;% summarise(mean_gaspcar = mean(lgaspcar), sd_gaspcar = sd(lgaspcar), max_gaspcar = max(lgaspcar), min_gaspcar = min(lgaspcar)) And then you can answer questions such as, which country has the maximum average gasoline consumption?: desc_gasoline %&gt;% filter(max(mean_gaspcar) == mean_gaspcar) ## # A tibble: 1 x 5 ## country mean_gaspcar sd_gaspcar max_gaspcar min_gaspcar ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 TURKEY 5.77 0.329 6.16 5.14 Turns out it’s Turkey. What about the minimum consumption? desc_gasoline %&gt;% filter(min(mean_gaspcar) == mean_gaspcar) ## # A tibble: 1 x 5 ## country mean_gaspcar sd_gaspcar max_gaspcar min_gaspcar ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ITALY 3.73 0.220 4.05 3.38 Because the output of dplyr verbs is a tibble, it is possible to continue working with it. This is one shortcoming of using the base summary() function. The object returned by that function is not very easy to manipulate. 5.3.6 Adding columns with mutate() and transmute() mutate() adds a column to the tibble, which can contain any transformation of any other variable: gasoline %&gt;% group_by(country) %&gt;% mutate(n()) ## # A tibble: 342 x 7 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap `n()` ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 19 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 19 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 19 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 19 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 19 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 19 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 19 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 19 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 19 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 19 ## # ... with 332 more rows Using mutate() I’ve added a column that counts how many times the country appears in the tibble, using n(), another dplyr function. There’s also count() and tally(), which we are going to see further down. It is also possible to rename the column on the fly: gasoline %&gt;% group_by(country) %&gt;% mutate(count = n()) ## # A tibble: 342 x 7 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap count ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 19 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 19 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 19 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 19 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 19 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 19 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 19 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 19 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 19 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 19 ## # ... with 332 more rows It is possible to do any arbitrary operation: gasoline %&gt;% group_by(country) %&gt;% mutate(spam = exp(lgaspcar + lincomep)) ## # A tibble: 342 x 7 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap spam ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 0.100 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 0.0978 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 0.0969 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 0.0991 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 0.102 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 0.104 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 0.110 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 0.113 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 0.115 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 0.122 ## # ... with 332 more rows transmute() is the same as mutate(), but only returns the created variable: gasoline %&gt;% group_by(country) %&gt;% transmute(spam = exp(lgaspcar + lincomep)) ## # A tibble: 342 x 2 ## # Groups: country [18] ## country spam ## &lt;fct&gt; &lt;dbl&gt; ## 1 AUSTRIA 0.100 ## 2 AUSTRIA 0.0978 ## 3 AUSTRIA 0.0969 ## 4 AUSTRIA 0.0991 ## 5 AUSTRIA 0.102 ## 6 AUSTRIA 0.104 ## 7 AUSTRIA 0.110 ## 8 AUSTRIA 0.113 ## 9 AUSTRIA 0.115 ## 10 AUSTRIA 0.122 ## # ... with 332 more rows 5.3.7 Joining tibbles with full_join(), left_join(), right_join() and all the others I will end this section on dplyr with the very useful verbs: the *_join() verbs. Let’s first start by loading another dataset from the plm package. SumHes and let’s convert it to tibble and rename it: data(SumHes, package = &quot;plm&quot;) pwt &lt;- SumHes %&gt;% as_tibble() %&gt;% mutate(country = tolower(country)) Let’s take a quick look at the data: glimpse(pwt) ## Observations: 3,250 ## Variables: 7 ## $ year &lt;int&gt; 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, ... ## $ country &lt;chr&gt; &quot;algeria&quot;, &quot;algeria&quot;, &quot;algeria&quot;, &quot;algeria&quot;, &quot;algeria&quot;,... ## $ opec &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no... ## $ com &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no... ## $ pop &lt;int&gt; 10800, 11016, 11236, 11460, 11690, 11923, 12267, 12622... ## $ gdp &lt;int&gt; 1723, 1599, 1275, 1517, 1589, 1584, 1548, 1600, 1758, ... ## $ sr &lt;dbl&gt; 19.9, 21.1, 15.0, 13.9, 10.6, 11.0, 8.3, 11.3, 15.1, 1... We can merge both gasoline and pwt by country and year, as these two variables are common to both datasets. There are more countries and years in the pwt dataset, so when merging both, and depending on which function you use, you will either have NA’s for the variables where there is no match, or rows that will be dropped. Let’s start with full_join: gas_pwt_full &lt;- gasoline %&gt;% full_join(pwt, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining factor and character vector, coercing ## into character vector Let’s see which countries and years are included: gas_pwt_full %&gt;% count(country, year) ## # A tibble: 3,592 x 3 ## country year n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 algeria 1960 1 ## 2 algeria 1961 1 ## 3 algeria 1962 1 ## 4 algeria 1963 1 ## 5 algeria 1964 1 ## 6 algeria 1965 1 ## 7 algeria 1966 1 ## 8 algeria 1967 1 ## 9 algeria 1968 1 ## 10 algeria 1969 1 ## # ... with 3,582 more rows As you see, every country and year was included, but what happened for, say, the U.S.S.R? This country is in pwt but not in gasoline at all: gas_pwt_full %&gt;% filter(country == &quot;u.s.s.r.&quot;) ## # A tibble: 26 x 11 ## country year lgaspcar lincomep lrpmg lcarpcap opec com pop gdp ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; ## 1 u.s.s.… 1960 NA NA NA NA no yes 214400 2397 ## 2 u.s.s.… 1961 NA NA NA NA no yes 217896 2542 ## 3 u.s.s.… 1962 NA NA NA NA no yes 221449 2656 ## 4 u.s.s.… 1963 NA NA NA NA no yes 225060 2681 ## 5 u.s.s.… 1964 NA NA NA NA no yes 227571 2854 ## 6 u.s.s.… 1965 NA NA NA NA no yes 230109 3049 ## 7 u.s.s.… 1966 NA NA NA NA no yes 232676 3247 ## 8 u.s.s.… 1967 NA NA NA NA no yes 235272 3454 ## 9 u.s.s.… 1968 NA NA NA NA no yes 237896 3730 ## 10 u.s.s.… 1969 NA NA NA NA no yes 240550 3808 ## # ... with 16 more rows, and 1 more variable: sr &lt;dbl&gt; As you probably guessed, the variables from gasoline that are not included in pwt are filled with NAs. One could remove all these lines and only keep countries for which these variables are not NA everywhere with filter(), but there is a simpler solution: gas_pwt_inner &lt;- gasoline %&gt;% inner_join(pwt, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining factor and character vector, coercing ## into character vector Let’s use the tabyl() from the janitor packages which is a very nice alternative to the table() function from base R: library(janitor) gas_pwt_inner %&gt;% tabyl(country) ## [1] country n percent ## &lt;0 rows&gt; (or 0-length row.names) Only countries with values in both datasets were returned. It’s almost every country from gasoline, apart from Germany (called “germany west” in pwt and “germany” in gasoline. I left it as is to provide an example of a country not in pwt). Let’s also look at the variables: glimpse(gas_pwt_inner) ## Observations: 0 ## Variables: 11 ## $ country &lt;chr&gt; ## $ year &lt;int&gt; ## $ lgaspcar &lt;dbl&gt; ## $ lincomep &lt;dbl&gt; ## $ lrpmg &lt;dbl&gt; ## $ lcarpcap &lt;dbl&gt; ## $ opec &lt;fct&gt; ## $ com &lt;fct&gt; ## $ pop &lt;int&gt; ## $ gdp &lt;int&gt; ## $ sr &lt;dbl&gt; The variables from both datasets are in the joined data. Contrast this to semi_join(): gas_pwt_semi &lt;- gasoline %&gt;% semi_join(pwt, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining factor and character vector, coercing ## into character vector glimpse(gas_pwt_semi) ## Observations: 0 ## Variables: 6 ## $ country &lt;fct&gt; ## $ year &lt;int&gt; ## $ lgaspcar &lt;dbl&gt; ## $ lincomep &lt;dbl&gt; ## $ lrpmg &lt;dbl&gt; ## $ lcarpcap &lt;dbl&gt; gas_pwt_semi %&gt;% tabyl(country) ## country n percent ## AUSTRIA 0 NaN ## BELGIUM 0 NaN ## CANADA 0 NaN ## DENMARK 0 NaN ## FRANCE 0 NaN ## GERMANY 0 NaN ## GREECE 0 NaN ## IRELAND 0 NaN ## ITALY 0 NaN ## JAPAN 0 NaN ## NETHERLA 0 NaN ## NORWAY 0 NaN ## SPAIN 0 NaN ## SWEDEN 0 NaN ## SWITZERL 0 NaN ## TURKEY 0 NaN ## U.K. 0 NaN ## U.S.A. 0 NaN Only columns of gasoline are returned, and only rows of gasoline that were matched with rows from pwt. semi_join() is not a commutative operation: pwt_gas_semi &lt;- pwt %&gt;% semi_join(gasoline, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining character vector and factor, coercing ## into character vector glimpse(pwt_gas_semi) ## Observations: 0 ## Variables: 7 ## $ year &lt;int&gt; ## $ country &lt;chr&gt; ## $ opec &lt;fct&gt; ## $ com &lt;fct&gt; ## $ pop &lt;int&gt; ## $ gdp &lt;int&gt; ## $ sr &lt;dbl&gt; gas_pwt_semi %&gt;% tabyl(country) ## country n percent ## AUSTRIA 0 NaN ## BELGIUM 0 NaN ## CANADA 0 NaN ## DENMARK 0 NaN ## FRANCE 0 NaN ## GERMANY 0 NaN ## GREECE 0 NaN ## IRELAND 0 NaN ## ITALY 0 NaN ## JAPAN 0 NaN ## NETHERLA 0 NaN ## NORWAY 0 NaN ## SPAIN 0 NaN ## SWEDEN 0 NaN ## SWITZERL 0 NaN ## TURKEY 0 NaN ## U.K. 0 NaN ## U.S.A. 0 NaN The rows are the same, but not the columns. left_join() and right_join() return all the rows from either the dataset that is on the “left” (the first argument of the fonction) or on the “right” (the second argument of the function) but all columns from both datasets. So depending on which countries you’re interested in, you’re going to use either one of these functions: gas_pwt_left &lt;- gasoline %&gt;% left_join(pwt, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining factor and character vector, coercing ## into character vector gas_pwt_left %&gt;% tabyl(country) ## country n percent ## AUSTRIA 19 0.05555556 ## BELGIUM 19 0.05555556 ## CANADA 19 0.05555556 ## DENMARK 19 0.05555556 ## FRANCE 19 0.05555556 ## GERMANY 19 0.05555556 ## GREECE 19 0.05555556 ## IRELAND 19 0.05555556 ## ITALY 19 0.05555556 ## JAPAN 19 0.05555556 ## NETHERLA 19 0.05555556 ## NORWAY 19 0.05555556 ## SPAIN 19 0.05555556 ## SWEDEN 19 0.05555556 ## SWITZERL 19 0.05555556 ## TURKEY 19 0.05555556 ## U.K. 19 0.05555556 ## U.S.A. 19 0.05555556 gas_pwt_right &lt;- gasoline %&gt;% right_join(pwt, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining factor and character vector, coercing ## into character vector gas_pwt_right %&gt;% tabyl(country) ## country n percent ## algeria 26 0.008 ## angola 26 0.008 ## argentina 26 0.008 ## australia 26 0.008 ## austria 26 0.008 ## bangladesh 26 0.008 ## barbados 26 0.008 ## belgium 26 0.008 ## benin 26 0.008 ## bolivia 26 0.008 ## botswana 26 0.008 ## brazil 26 0.008 ## burkina faso 26 0.008 ## burundi 26 0.008 ## cameroon 26 0.008 ## canada 26 0.008 ## cape verde is. 26 0.008 ## central afr.r. 26 0.008 ## chad 26 0.008 ## chile 26 0.008 ## china 26 0.008 ## colombia 26 0.008 ## comoros 26 0.008 ## congo 26 0.008 ## costa rica 26 0.008 ## cyprus 26 0.008 ## czechoslovakia 26 0.008 ## denmark 26 0.008 ## dominican rep. 26 0.008 ## ecuador 26 0.008 ## egypt 26 0.008 ## el salvador 26 0.008 ## ethiopia 26 0.008 ## fiji 26 0.008 ## finland 26 0.008 ## france 26 0.008 ## gabon 26 0.008 ## gambia 26 0.008 ## germany west 26 0.008 ## ghana 26 0.008 ## greece 26 0.008 ## guatemala 26 0.008 ## guinea 26 0.008 ## guinea-biss 26 0.008 ## guyana 26 0.008 ## haiti 26 0.008 ## honduras 26 0.008 ## hong kong 26 0.008 ## iceland 26 0.008 ## india 26 0.008 ## indonesia 26 0.008 ## iran 26 0.008 ## iraq 26 0.008 ## ireland 26 0.008 ## israel 26 0.008 ## italy 26 0.008 ## ivory coast 26 0.008 ## jamaica 26 0.008 ## japan 26 0.008 ## jordan 26 0.008 ## kenya 26 0.008 ## korea 26 0.008 ## lesotho 26 0.008 ## liberia 26 0.008 ## luxembourg 26 0.008 ## madagascar 26 0.008 ## malawi 26 0.008 ## malaysia 26 0.008 ## mali 26 0.008 ## malta 26 0.008 ## mauritania 26 0.008 ## mauritius 26 0.008 ## mexico 26 0.008 ## morocco 26 0.008 ## mozambique 26 0.008 ## myanmar 26 0.008 ## namibia 26 0.008 ## nepal 26 0.008 ## netherlands 26 0.008 ## new zealand 26 0.008 ## nicaragua 26 0.008 ## niger 26 0.008 ## nigeria 26 0.008 ## norway 26 0.008 ## pakistan 26 0.008 ## panama 26 0.008 ## papua n.guinea 26 0.008 ## paraguay 26 0.008 ## peru 26 0.008 ## philippines 26 0.008 ## portugal 26 0.008 ## puerto rico 26 0.008 ## reunion 26 0.008 ## romania 26 0.008 ## rwanda 26 0.008 ## saudi arabia 26 0.008 ## senegal 26 0.008 ## seychelles 26 0.008 ## singapore 26 0.008 ## somalia 26 0.008 ## south africa 26 0.008 ## spain 26 0.008 ## sri lanka 26 0.008 ## suriname 26 0.008 ## swaziland 26 0.008 ## sweden 26 0.008 ## switzerland 26 0.008 ## syria 26 0.008 ## taiwan 26 0.008 ## tanzania 26 0.008 ## thailand 26 0.008 ## togo 26 0.008 ## trinidad&amp;tobago 26 0.008 ## tunisia 26 0.008 ## turkey 26 0.008 ## u.k. 26 0.008 ## u.s.a. 26 0.008 ## u.s.s.r. 26 0.008 ## uganda 26 0.008 ## uruguay 26 0.008 ## venezuela 26 0.008 ## yugoslavia 26 0.008 ## zaire 26 0.008 ## zambia 26 0.008 ## zimbabwe 26 0.008 The last merge function is anti_join(): gas_pwt_anti &lt;- gasoline %&gt;% anti_join(pwt, by = c(&quot;country&quot;, &quot;year&quot;)) ## Warning: Column `country` joining factor and character vector, coercing ## into character vector glimpse(gas_pwt_anti) ## Observations: 342 ## Variables: 6 ## $ country &lt;fct&gt; AUSTRIA, AUSTRIA, AUSTRIA, AUSTRIA, AUSTRIA, AUSTRIA,... ## $ year &lt;int&gt; 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968,... ## $ lgaspcar &lt;dbl&gt; 4.173244, 4.100989, 4.073177, 4.059509, 4.037689, 4.0... ## $ lincomep &lt;dbl&gt; -6.474277, -6.426006, -6.407308, -6.370679, -6.322247... ## $ lrpmg &lt;dbl&gt; -0.3345476, -0.3513276, -0.3795177, -0.4142514, -0.44... ## $ lcarpcap &lt;dbl&gt; -9.766840, -9.608622, -9.457257, -9.343155, -9.237739... gas_pwt_anti %&gt;% tabyl(country) ## country n percent ## AUSTRIA 19 0.05555556 ## BELGIUM 19 0.05555556 ## CANADA 19 0.05555556 ## DENMARK 19 0.05555556 ## FRANCE 19 0.05555556 ## GERMANY 19 0.05555556 ## GREECE 19 0.05555556 ## IRELAND 19 0.05555556 ## ITALY 19 0.05555556 ## JAPAN 19 0.05555556 ## NETHERLA 19 0.05555556 ## NORWAY 19 0.05555556 ## SPAIN 19 0.05555556 ## SWEDEN 19 0.05555556 ## SWITZERL 19 0.05555556 ## TURKEY 19 0.05555556 ## U.K. 19 0.05555556 ## U.S.A. 19 0.05555556 gas_pwt_anti has the columns the gasoline dataset as well as the only country from gasoline that is not in pwt: “germany”. That was it for the basic {dplyr} verbs. Next, we’re going to learn about {tidyr}. 5.4 Reshaping data with tidyr Another important package from the tidyverse that goes hand in hand with dplyr is tidyr. tidyr is the package you need when it’s time to reshape data. The basic functions from tidyr, spread() and gather() make it possible to go from long to wide datasets respectively. 5.4.1 spread() and gather() Let’s first create a fake dataset: library(tidyr) survey_data &lt;- tribble( ~id, ~variable, ~value, 1, &quot;var1&quot;, 1, 1, &quot;var2&quot;, 0.2, NA, &quot;var3&quot;, 0.3, 2, &quot;var1&quot;, 1.4, 2, &quot;var2&quot;, 1.9, 2, &quot;var3&quot;, 4.1, 3, &quot;var1&quot;, 0.1, 3, &quot;var2&quot;, 2.8, 3, &quot;var3&quot;, 8.9, 4, &quot;var1&quot;, 1.7, NA, &quot;var2&quot;, 1.9, 4, &quot;var3&quot;, 7.6 ) head(survey_data) ## # A tibble: 6 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1 1.4 ## 5 2 var2 1.9 ## 6 2 var3 4.1 I used the tribble() function from the {tibble} package to create this fake dataset. I’ll discuss this package later, for now, let’s focus on {tidyr}. survey_data is a long dataset. We can reshape it to be wide using the spread() function: wide_data &lt;- survey_data %&gt;% spread(variable, value) head(wide_data) ## # A tibble: 5 x 4 ## id var1 var2 var3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0.2 NA ## 2 2 1.4 1.9 4.1 ## 3 3 0.1 2.8 8.9 ## 4 4 1.7 NA 7.6 ## 5 NA NA 1.9 0.3 This means that we spread the column called “variable”, which will produce one column per category of “variable”. Then we fill in the rows with the data contained in the column “value”. To go from a wide dataset to a long one, we use gather(): long_data &lt;- wide_data %&gt;% gather(variable, value, var1, var2) print(long_data) ## # A tibble: 10 x 4 ## id var3 variable value ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 NA var1 1 ## 2 2 4.1 var1 1.4 ## 3 3 8.9 var1 0.1 ## 4 4 7.6 var1 1.7 ## 5 NA 0.3 var1 NA ## 6 1 NA var2 0.2 ## 7 2 4.1 var2 1.9 ## 8 3 8.9 var2 2.8 ## 9 4 7.6 var2 NA ## 10 NA 0.3 var2 1.9 long_data and survey_data are the same datasets, but in a different order. In the wide_data tibble, we had 3 columns: id, var1 and var2. We want to stack ‘var1’ and ‘var2’ in a new column, that we choose to call “variable”. This is the “key”. For the value, we are using the values contained in var1 and var2. Sometimes using spread() or gather() requires some trial and error. I advise you play around with the examples above to really grasp how these powerful functions work. 5.4.2 fill() and full_seq() fill() is pretty useful to… fill in missing values. For instance, in survey_data, some “id”s are missing: survey_data ## # A tibble: 12 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1 1.4 ## 5 2 var2 1.9 ## 6 2 var3 4.1 ## 7 3 var1 0.1 ## 8 3 var2 2.8 ## 9 3 var3 8.9 ## 10 4 var1 1.7 ## 11 NA var2 1.9 ## 12 4 var3 7.6 It seems pretty obvious that the first NA is supposed to be 1 and the second missing is supposed to be 4. With fill(), this is pretty easy to achieve: survey_data %&gt;% fill(.direction = &quot;down&quot;, variable = &quot;id&quot;) ## # A tibble: 12 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 1 var3 0.3 ## 4 2 var1 1.4 ## 5 2 var2 1.9 ## 6 2 var3 4.1 ## 7 3 var1 0.1 ## 8 3 var2 2.8 ## 9 3 var3 8.9 ## 10 4 var1 1.7 ## 11 4 var2 1.9 ## 12 4 var3 7.6 full_seq() is similar: full_seq(c(as.Date(&quot;2018-08-01&quot;), as.Date(&quot;2018-08-03&quot;)), 1) ## [1] &quot;2018-08-01&quot; &quot;2018-08-02&quot; &quot;2018-08-03&quot; We can add this as the date column to our survey data: survey_data %&gt;% mutate(date = rep(full_seq(c(as.Date(&quot;2018-08-01&quot;), as.Date(&quot;2018-08-03&quot;)), 1), 4)) ## # A tibble: 12 x 4 ## id variable value date ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; ## 1 1 var1 1 2018-08-01 ## 2 1 var2 0.2 2018-08-02 ## 3 NA var3 0.3 2018-08-03 ## 4 2 var1 1.4 2018-08-01 ## 5 2 var2 1.9 2018-08-02 ## 6 2 var3 4.1 2018-08-03 ## 7 3 var1 0.1 2018-08-01 ## 8 3 var2 2.8 2018-08-02 ## 9 3 var3 8.9 2018-08-03 ## 10 4 var1 1.7 2018-08-01 ## 11 NA var2 1.9 2018-08-02 ## 12 4 var3 7.6 2018-08-03 I use the base rep() function to repeat the date 4 times and then using mutate() I have added it the data frame. Putting all these operations together: survey_data %&gt;% fill(.direction = &quot;down&quot;, variable = &quot;id&quot;) %&gt;% mutate(date = rep(full_seq(c(as.Date(&quot;2018-08-01&quot;), as.Date(&quot;2018-08-03&quot;)), 1), 4)) %&gt;% spread(variable, value) ## # A tibble: 12 x 5 ## id date var1 var2 var3 ## &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2018-08-01 1 NA NA ## 2 1 2018-08-02 NA 0.2 NA ## 3 1 2018-08-03 NA NA 0.3 ## 4 2 2018-08-01 1.4 NA NA ## 5 2 2018-08-02 NA 1.9 NA ## 6 2 2018-08-03 NA NA 4.1 ## 7 3 2018-08-01 0.1 NA NA ## 8 3 2018-08-02 NA 2.8 NA ## 9 3 2018-08-03 NA NA 8.9 ## 10 4 2018-08-01 1.7 NA NA ## 11 4 2018-08-02 NA 1.9 NA ## 12 4 2018-08-03 NA NA 7.6 As you can see, this creates a lot of explicit NA values. The best would be to fill in the missing values and add the date column, and then work with that format. For example, to get the average of the values by date: survey_data %&gt;% fill(.direction = &quot;down&quot;, variable = &quot;id&quot;) %&gt;% mutate(date = rep(full_seq(c(as.Date(&quot;2018-08-01&quot;), as.Date(&quot;2018-08-03&quot;)), 1), 4)) %&gt;% group_by(date) %&gt;% summarise(mean(value)) ## # A tibble: 3 x 2 ## date `mean(value)` ## &lt;date&gt; &lt;dbl&gt; ## 1 2018-08-01 1.05 ## 2 2018-08-02 1.7 ## 3 2018-08-03 5.22 Or by date and variable: survey_data %&gt;% fill(.direction = &quot;down&quot;, variable = &quot;id&quot;) %&gt;% mutate(date = rep(full_seq(c(as.Date(&quot;2018-08-01&quot;), as.Date(&quot;2018-08-03&quot;)), 1), 4)) %&gt;% group_by(date, variable) %&gt;% summarise(mean(value)) ## # A tibble: 3 x 3 ## # Groups: date [?] ## date variable `mean(value)` ## &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2018-08-01 var1 1.05 ## 2 2018-08-02 var2 1.7 ## 3 2018-08-03 var3 5.22 As you can see, you can chain any {tidyverse} verbs, wether they come from {dplyr} or {tidyr}. 5.4.3 Put order in your columns with separate(), unite(), and in your rows with separate_rows() Sometimes, data can be in a format that makes working with it needlessly painful. For example, you get this: survey_data_not_tidy ## # A tibble: 12 x 3 ## id variable_date value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1/2018-08-01 1 ## 2 1 var2/2018-08-02 0.2 ## 3 1 var3/2018-08-03 0.3 ## 4 2 var1/2018-08-01 1.4 ## 5 2 var2/2018-08-02 1.9 ## 6 2 var3/2018-08-03 4.1 ## 7 3 var1/2018-08-01 0.1 ## 8 3 var2/2018-08-02 2.8 ## 9 3 var3/2018-08-03 8.9 ## 10 4 var1/2018-08-01 1.7 ## 11 4 var2/2018-08-02 1.9 ## 12 4 var3/2018-08-03 7.6 Dealing with this is simple, thanks to separate(): survey_data_not_tidy %&gt;% separate(variable_date, into = c(&quot;variable&quot;, &quot;date&quot;), sep = &quot;/&quot;) ## # A tibble: 12 x 4 ## id variable date value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 2018-08-01 1 ## 2 1 var2 2018-08-02 0.2 ## 3 1 var3 2018-08-03 0.3 ## 4 2 var1 2018-08-01 1.4 ## 5 2 var2 2018-08-02 1.9 ## 6 2 var3 2018-08-03 4.1 ## 7 3 var1 2018-08-01 0.1 ## 8 3 var2 2018-08-02 2.8 ## 9 3 var3 2018-08-03 8.9 ## 10 4 var1 2018-08-01 1.7 ## 11 4 var2 2018-08-02 1.9 ## 12 4 var3 2018-08-03 7.6 The variable_date column gets separated into two columns, variable and date. One also needs to specify the separator, in this case “/”. unite() is the reverse operation, which can be useful when you are confronted to this situation: survey_data2 ## # A tibble: 12 x 6 ## id variable year month day value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 2018 08 01 1 ## 2 1 var2 2018 08 02 0.2 ## 3 1 var3 2018 08 03 0.3 ## 4 2 var1 2018 08 01 1.4 ## 5 2 var2 2018 08 02 1.9 ## 6 2 var3 2018 08 03 4.1 ## 7 3 var1 2018 08 01 0.1 ## 8 3 var2 2018 08 02 2.8 ## 9 3 var3 2018 08 03 8.9 ## 10 4 var1 2018 08 01 1.7 ## 11 4 var2 2018 08 02 1.9 ## 12 4 var3 2018 08 03 7.6 In some situation, it is better to have the date as a single column: survey_data2 %&gt;% unite(date, year, month, day, sep = &quot;-&quot;) ## # A tibble: 12 x 4 ## id variable date value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 2018-08-01 1 ## 2 1 var2 2018-08-02 0.2 ## 3 1 var3 2018-08-03 0.3 ## 4 2 var1 2018-08-01 1.4 ## 5 2 var2 2018-08-02 1.9 ## 6 2 var3 2018-08-03 4.1 ## 7 3 var1 2018-08-01 0.1 ## 8 3 var2 2018-08-02 2.8 ## 9 3 var3 2018-08-03 8.9 ## 10 4 var1 2018-08-01 1.7 ## 11 4 var2 2018-08-02 1.9 ## 12 4 var3 2018-08-03 7.6 Another awful situation is the following: survey_data_from_hell ## id variable value ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1, var2, var3 1.4, 1.9, 4.1 ## 5 3 var1, var2 0.1, 2.8 ## 6 3 var3 8.9 ## 7 4 var1 1.7 ## 8 NA var2 1.9 ## 9 4 var3 7.6 separate_rows() saves the day: survey_data_from_hell %&gt;% separate_rows(variable, value) ## id variable value ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1 1.4 ## 5 2 var2 1.9 ## 6 2 var3 4.1 ## 7 3 var1 0.1 ## 8 3 var2 2.8 ## 9 3 var3 8.9 ## 10 4 var1 1.7 ## 11 NA var2 1.9 ## 12 4 var3 7.6 So to summarise… you can go from this: survey_data_from_hell ## id variable value ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1, var2, var3 1.4, 1.9, 4.1 ## 5 3 var1, var2 0.1, 2.8 ## 6 3 var3 8.9 ## 7 4 var1 1.7 ## 8 NA var2 1.9 ## 9 4 var3 7.6 to this: survey_data_clean ## # A tibble: 12 x 4 ## id variable date value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 2018-08-01 1 ## 2 1 var2 2018-08-02 0.2 ## 3 1 var3 2018-08-03 0.3 ## 4 2 var1 2018-08-01 1.4 ## 5 2 var2 2018-08-02 1.9 ## 6 2 var3 2018-08-03 4.1 ## 7 3 var1 2018-08-01 0.1 ## 8 3 var2 2018-08-02 2.8 ## 9 3 var3 2018-08-03 8.9 ## 10 4 var1 2018-08-01 1.7 ## 11 4 var2 2018-08-02 1.9 ## 12 4 var3 2018-08-03 7.6 quite easily: survey_data_from_hell %&gt;% separate_rows(variable, value, convert = TRUE) %&gt;% fill(.direction = &quot;down&quot;, variable = &quot;id&quot;) %&gt;% mutate(date = rep(full_seq(c(as.Date(&quot;2018-08-01&quot;), as.Date(&quot;2018-08-03&quot;)), 1), 4)) ## id variable value date ## 1 1 var1 1.0 2018-08-01 ## 2 1 var2 0.2 2018-08-02 ## 3 1 var3 0.3 2018-08-03 ## 4 2 var1 1.4 2018-08-01 ## 5 2 var2 1.9 2018-08-02 ## 6 2 var3 4.1 2018-08-03 ## 7 3 var1 0.1 2018-08-01 ## 8 3 var2 2.8 2018-08-02 ## 9 3 var3 8.9 2018-08-03 ## 10 4 var1 1.7 2018-08-01 ## 11 4 var2 1.9 2018-08-02 ## 12 4 var3 7.6 2018-08-03 5.4.4 A sneak peek to Chapter 9; nest() Let’s take a look at our clean survey data: survey_data_clean ## # A tibble: 12 x 4 ## id variable date value ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 2018-08-01 1 ## 2 1 var2 2018-08-02 0.2 ## 3 1 var3 2018-08-03 0.3 ## 4 2 var1 2018-08-01 1.4 ## 5 2 var2 2018-08-02 1.9 ## 6 2 var3 2018-08-03 4.1 ## 7 3 var1 2018-08-01 0.1 ## 8 3 var2 2018-08-02 2.8 ## 9 3 var3 2018-08-03 8.9 ## 10 4 var1 2018-08-01 1.7 ## 11 4 var2 2018-08-02 1.9 ## 12 4 var3 2018-08-03 7.6 {tidyr} has another very useful function, called nest(): survey_data_clean %&gt;% nest(-id) ## # A tibble: 4 x 2 ## id data ## &lt;dbl&gt; &lt;list&gt; ## 1 1 &lt;tibble [3 × 3]&gt; ## 2 2 &lt;tibble [3 × 3]&gt; ## 3 3 &lt;tibble [3 × 3]&gt; ## 4 4 &lt;tibble [3 × 3]&gt; You can achieve the same result by using group_by() first: survey_data_clean %&gt;% group_by(id) %&gt;% nest() ## # A tibble: 4 x 2 ## id data ## &lt;dbl&gt; &lt;list&gt; ## 1 1 &lt;tibble [3 × 3]&gt; ## 2 2 &lt;tibble [3 × 3]&gt; ## 3 3 &lt;tibble [3 × 3]&gt; ## 4 4 &lt;tibble [3 × 3]&gt; This cerates a new tibble object, whith two columns, one with the id column, and a new one called data. Let’s take a look at the first element of this column: nested_survey_data &lt;- survey_data_clean %&gt;% group_by(id) %&gt;% nest() nested_survey_data$data[1] ## [[1]] ## # A tibble: 3 x 3 ## variable date value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 var1 2018-08-01 1 ## 2 var2 2018-08-02 0.2 ## 3 var3 2018-08-03 0.3 As you can see, the first element of the data is also a tibble! You may wonder why this is useful; I will give you a small taste of what’s waiting in chapter 9. Imagine that you want to create a barplot for each id. For instance, for the first id (we are going to learn about making plots with {ggplot2} in the next chapter. For now, just follow along, even if you don’t understand everything I write): survey_data_id1 &lt;- survey_data_clean %&gt;% filter(id == 1) Now, let’s create the plot: ggplot(data = survey_data_id1) + geom_bar(aes(y = value, x = date, fill = variable), stat = &quot;identity&quot;) + ggtitle(&quot;id 1&quot;) Ok great. But now I want to create this plot for each id… so I have to copy paste this 3 times. But copy-pasting is error prone. So there are two alternatives; I either write a function that takes as argument the data and the id I want to plot and run it for each id (we will learn to do this in Chapter 8), or I can use tidyr::nest(), combined with purrr::map(). {purrr} is another very useful {tidevyrse} package, and we are going to learn about it in Chapter 9. Again, just follow along for now: my_plots &lt;- nested_survey_data %&gt;% mutate(plot = map2(.x = id, .y = data, ~ggplot(data = .y) + geom_bar(aes(y = value, x = date, fill = variable), stat = &quot;identity&quot;) + ggtitle(paste0(&quot;id&quot;, .x)))) This is some very advanced stuff, and again, do not worry if you don’t understand everything now. We are going to learn about this in detail in Chapter 9. Let’s go through each line. In the first line, I have started from my clean data nested_survey_data and then, using the %&gt;% and mutate() I create a new column called plot. Inside the mutate() function, I called map2. map2 is a {purrr} function that takes three inputs: .x, .y and a function. .x is the id column from my data, and .y is the data column from nested_survey_data. The function is the ggplot I created before. Think of map2() has a loop over two lists, all while applying a function. The following illustration, taken from Vaudor (2018) by Lise Vaudor, illustrates this perfectly: Two inputs go in at the same type, the factory, your function, does what it has to do, and an output comes out. Forget about the factory’s chimney, which represents walk2() for now. We’ll learn about it in due time. By the way, you really should read Lise’s blog, her posts are really great and informative. It’s in French, but that’s not a problem, you know how to read R code, right? Here’s a link to her blog. Now, let’s take a look at the result: my_plots ## # A tibble: 4 x 3 ## id data plot ## &lt;dbl&gt; &lt;list&gt; &lt;list&gt; ## 1 1 &lt;tibble [3 × 3]&gt; &lt;S3: gg&gt; ## 2 2 &lt;tibble [3 × 3]&gt; &lt;S3: gg&gt; ## 3 3 &lt;tibble [3 × 3]&gt; &lt;S3: gg&gt; ## 4 4 &lt;tibble [3 × 3]&gt; &lt;S3: gg&gt; my_plots is a tibble with three columns: id, data and.. plot! plot is a very interesting column. It is a list, where each element is of type S3: gg. Yes, you guessed it, each element of that list-column is a ggplot! If you now want to take a look at the plots, it is enough to do this: my_plots$plot ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] Ok, that was quite complicated, but again, this was only to introduce nest() and give you a taste of the power of the {tidyverse}. By the end of Chapter 9, you’ll be used to this. That was it for a first introduction to {tidyr}. Now, it’s time to learn about scoped verbs. 5.5 Scoped {tidyverse} verbs Scoped verbs are special versions of the verbs you are now familiar with. 5.5.1 filter_*() Let’s go back to the gasoline data from the {plm} package. filter() is not the only filtering verb there is. Suppose that we have a condition that we want to use to filter out a lot of columns at once. For example, for every column that is of type numeric, keep only the lines where the condition value &gt; -8 is satisfied. The next line does that: gasoline %&gt;% filter_if( ~all(is.numeric(.)), all_vars(. &gt; -8)) ## # A tibble: 30 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CANADA 1972 4.89 -5.44 -1.10 -7.99 ## 2 CANADA 1973 4.90 -5.41 -1.13 -7.94 ## 3 CANADA 1974 4.89 -5.42 -1.12 -7.90 ## 4 CANADA 1975 4.89 -5.38 -1.19 -7.87 ## 5 CANADA 1976 4.84 -5.36 -1.06 -7.81 ## 6 CANADA 1977 4.81 -5.34 -1.07 -7.77 ## 7 CANADA 1978 4.86 -5.31 -1.07 -7.79 ## 8 GERMANY 1978 3.88 -5.56 -0.628 -7.95 ## 9 SWEDEN 1975 3.97 -7.68 -2.77 -7.99 ## 10 SWEDEN 1976 3.98 -7.67 -2.82 -7.96 ## # ... with 20 more rows This is a bit more complicated than before, but let’s go through it, step by step. filter_if() needs 3 arguments to work; the data, a predicate function (a function that returns TRUE, or FALSE) which will select the columns we want to work on, and then the condition. The condition can be applied to all the columns that were selected by the predicate function (hence the all_vars()) or only to at least one (you’d use any_vars() then). Try to change the condition, or the predicate function, to figure out how filter_if() works. The dot is a placeholder that stands for whatever columns where selected. Another scoped filter() verb is filter_at(); it allows the user to filter columns by position: gasoline %&gt;% filter_at(vars(ends_with(&quot;p&quot;)), all_vars(. &gt; -8)) ## # A tibble: 30 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CANADA 1972 4.89 -5.44 -1.10 -7.99 ## 2 CANADA 1973 4.90 -5.41 -1.13 -7.94 ## 3 CANADA 1974 4.89 -5.42 -1.12 -7.90 ## 4 CANADA 1975 4.89 -5.38 -1.19 -7.87 ## 5 CANADA 1976 4.84 -5.36 -1.06 -7.81 ## 6 CANADA 1977 4.81 -5.34 -1.07 -7.77 ## 7 CANADA 1978 4.86 -5.31 -1.07 -7.79 ## 8 GERMANY 1978 3.88 -5.56 -0.628 -7.95 ## 9 SWEDEN 1975 3.97 -7.68 -2.77 -7.99 ## 10 SWEDEN 1976 3.98 -7.67 -2.82 -7.96 ## # ... with 20 more rows we already know about ends_with() and starts_with(). So the above line means “for the columns whose name end with a ‘p’ only keep the lines where, for all the selected columns, the values are strictly superior to -8”. Again, this is not very easy the first time you deal with that, so play around with it for a bit. Finally, there is also filter_all() which, as the name implies, uses all the variables for the filtering step. filter_if() and filter_at() are very useful when you have very large datasets with a lot of variables and you want to apply a filtering function only to a subset of them. filter_all() is useful if, for example, you only want to keep the positive values for all the columns. 5.5.2 select_*() and rename_*() Just as with filter(), select() also has scoped versions. select_if() makes it easy to select columns that satisfy a criterium: gasoline %&gt;% select_if(is.numeric) ## # A tibble: 342 x 5 ## year lgaspcar lincomep lrpmg lcarpcap ## * &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1960 4.17 -6.47 -0.335 -9.77 ## 2 1961 4.10 -6.43 -0.351 -9.61 ## 3 1962 4.07 -6.41 -0.380 -9.46 ## 4 1963 4.06 -6.37 -0.414 -9.34 ## 5 1964 4.04 -6.32 -0.445 -9.24 ## 6 1965 4.03 -6.29 -0.497 -9.12 ## 7 1966 4.05 -6.25 -0.467 -9.02 ## 8 1967 4.05 -6.23 -0.506 -8.93 ## 9 1968 4.05 -6.21 -0.522 -8.85 ## 10 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows You can even pass a further function to select_if() that will be applied to the selected columns: gasoline %&gt;% select_if(is.numeric, toupper) ## # A tibble: 342 x 5 ## YEAR LGASPCAR LINCOMEP LRPMG LCARPCAP ## * &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1960 4.17 -6.47 -0.335 -9.77 ## 2 1961 4.10 -6.43 -0.351 -9.61 ## 3 1962 4.07 -6.41 -0.380 -9.46 ## 4 1963 4.06 -6.37 -0.414 -9.34 ## 5 1964 4.04 -6.32 -0.445 -9.24 ## 6 1965 4.03 -6.29 -0.497 -9.12 ## 7 1966 4.05 -6.25 -0.467 -9.02 ## 8 1967 4.05 -6.23 -0.506 -8.93 ## 9 1968 4.05 -6.21 -0.522 -8.85 ## 10 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows select_at() makes it easy to select all the variables that start with “l” for example: gasoline %&gt;% select_at(vars(starts_with(&quot;l&quot;))) ## # A tibble: 342 x 4 ## lgaspcar lincomep lrpmg lcarpcap ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.17 -6.47 -0.335 -9.77 ## 2 4.10 -6.43 -0.351 -9.61 ## 3 4.07 -6.41 -0.380 -9.46 ## 4 4.06 -6.37 -0.414 -9.34 ## 5 4.04 -6.32 -0.445 -9.24 ## 6 4.03 -6.29 -0.497 -9.12 ## 7 4.05 -6.25 -0.467 -9.02 ## 8 4.05 -6.23 -0.506 -8.93 ## 9 4.05 -6.21 -0.522 -8.85 ## 10 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows select_at() also works if you specify the position of the columns you’re interested in: gasoline %&gt;% select_at(vars(c(1,2,5))) ## # A tibble: 342 x 3 ## country year lrpmg ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 -0.335 ## 2 AUSTRIA 1961 -0.351 ## 3 AUSTRIA 1962 -0.380 ## 4 AUSTRIA 1963 -0.414 ## 5 AUSTRIA 1964 -0.445 ## 6 AUSTRIA 1965 -0.497 ## 7 AUSTRIA 1966 -0.467 ## 8 AUSTRIA 1967 -0.506 ## 9 AUSTRIA 1968 -0.522 ## 10 AUSTRIA 1969 -0.559 ## # ... with 332 more rows Notice that I use a new helper function, vars(), which allows me to specify which variables I want to select. This is similar to the helper functions we have seen before, all_vars() and any_vars(). So the way to read the above line would be something like “Start with the gasoline data, then select the variables at position 1, 2, 5”. Knowing how to read your code makes it even easier to write. There is also a select_all(), and you might be wondering why it is useful: gasoline %&gt;% select_all() ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows This simply returns all the columns of the data frame… but wait, selec_all() allows you to do something very useful, which is rename all the columns in bulk: gasoline %&gt;% select_all(toupper) ## # A tibble: 342 x 6 ## COUNTRY YEAR LGASPCAR LINCOMEP LRPMG LCARPCAP ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows You can apply any arbitrary function: gasoline %&gt;% select_all(funs(paste0(&quot;hello_&quot;, .))) ## # A tibble: 342 x 6 ## hello_country hello_year hello_lgaspcar hello_lincomep hello_lrpmg ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 ## # ... with 332 more rows, and 1 more variable: hello_lcarpcap &lt;dbl&gt; I have passed the paste0() function to the funs() helper function of select_all(). funs() is used a lot with scoped verbs, just like vars(), which we have already seen. The scoped version of rename() work just as you expect. But I’ll leave these for the exercices down below. 5.5.3 group_by_*() To illustrate group_by_*() I have to first modify the gasoline data a little bit. As you can see below, the data column is of type integer: gasoline ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## * &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 4.17 -6.47 -0.335 -9.77 ## 2 AUSTRIA 1961 4.10 -6.43 -0.351 -9.61 ## 3 AUSTRIA 1962 4.07 -6.41 -0.380 -9.46 ## 4 AUSTRIA 1963 4.06 -6.37 -0.414 -9.34 ## 5 AUSTRIA 1964 4.04 -6.32 -0.445 -9.24 ## 6 AUSTRIA 1965 4.03 -6.29 -0.497 -9.12 ## 7 AUSTRIA 1966 4.05 -6.25 -0.467 -9.02 ## 8 AUSTRIA 1967 4.05 -6.23 -0.506 -8.93 ## 9 AUSTRIA 1968 4.05 -6.21 -0.522 -8.85 ## 10 AUSTRIA 1969 4.05 -6.15 -0.559 -8.79 ## # ... with 332 more rows Let’s change that to character: gasoline &lt;- gasoline %&gt;% mutate(year = as.character(year)) Now, this allows me to do the following: gasoline %&gt;% group_by_if(is.character) %&gt;% summarise(mean(lincomep)) ## # A tibble: 19 x 2 ## year `mean(lincomep)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 1960 -6.50 ## 2 1961 -6.46 ## 3 1962 -6.42 ## 4 1963 -6.37 ## 5 1964 -6.33 ## 6 1965 -6.29 ## 7 1966 -6.25 ## 8 1967 -6.21 ## 9 1968 -6.18 ## 10 1969 -6.12 ## 11 1970 -6.07 ## 12 1971 -6.04 ## 13 1972 -5.99 ## 14 1973 -5.94 ## 15 1974 -5.93 ## 16 1975 -5.93 ## 17 1976 -5.89 ## 18 1977 -5.87 ## 19 1978 -5.84 This is faster than having to write: gasoline %&gt;% group_by(country, year) %&gt;% summarise(mean(lincomep)) ## # A tibble: 342 x 3 ## # Groups: country [?] ## country year `mean(lincomep)` ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 -6.47 ## 2 AUSTRIA 1961 -6.43 ## 3 AUSTRIA 1962 -6.41 ## 4 AUSTRIA 1963 -6.37 ## 5 AUSTRIA 1964 -6.32 ## 6 AUSTRIA 1965 -6.29 ## 7 AUSTRIA 1966 -6.25 ## 8 AUSTRIA 1967 -6.23 ## 9 AUSTRIA 1968 -6.21 ## 10 AUSTRIA 1969 -6.15 ## # ... with 332 more rows You may think that having two write the name of two variables is not a huge hassle, which is true. But imagine that you have dozens of character columns that you want to group by. This is the kind of situation where group_by_if() is very useful. If you prefer, you can specify the position of the columns instead of the name of the columns, with group_by_at(): gasoline %&gt;% group_by_at(vars(1, 2)) %&gt;% summarise(mean(lincomep)) ## # A tibble: 342 x 3 ## # Groups: country [?] ## country year `mean(lincomep)` ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 -6.47 ## 2 AUSTRIA 1961 -6.43 ## 3 AUSTRIA 1962 -6.41 ## 4 AUSTRIA 1963 -6.37 ## 5 AUSTRIA 1964 -6.32 ## 6 AUSTRIA 1965 -6.29 ## 7 AUSTRIA 1966 -6.25 ## 8 AUSTRIA 1967 -6.23 ## 9 AUSTRIA 1968 -6.21 ## 10 AUSTRIA 1969 -6.15 ## # ... with 332 more rows There is also a group_by_all(), but I fail to see the use case… 5.5.4 summarise_() Just like for filter(), select(), and group_by(), summarise()` comes with scoped versions: gasoline %&gt;% group_by(country) %&gt;% summarise_at(vars(starts_with(&quot;l&quot;)), mean) ## # A tibble: 18 x 5 ## country lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 -6.12 -0.486 -8.85 ## 2 BELGIUM 3.92 -5.85 -0.326 -8.63 ## 3 CANADA 4.86 -5.58 -1.05 -8.08 ## 4 DENMARK 4.19 -5.76 -0.358 -8.58 ## 5 FRANCE 3.82 -5.87 -0.253 -8.45 ## 6 GERMANY 3.89 -5.85 -0.517 -8.51 ## 7 GREECE 4.88 -6.61 -0.0339 -10.8 ## 8 IRELAND 4.23 -6.44 -0.348 -9.04 ## 9 ITALY 3.73 -6.35 -0.152 -8.83 ## 10 JAPAN 4.70 -6.25 -0.287 -9.95 ## 11 NETHERLA 4.08 -5.92 -0.370 -8.82 ## 12 NORWAY 4.11 -5.75 -0.278 -8.77 ## 13 SPAIN 4.06 -5.63 0.739 -9.90 ## 14 SWEDEN 4.01 -7.82 -2.71 -8.25 ## 15 SWITZERL 4.24 -5.93 -0.902 -8.54 ## 16 TURKEY 5.77 -7.34 -0.422 -12.5 ## 17 U.K. 3.98 -6.02 -0.459 -8.55 ## 18 U.S.A. 4.82 -5.45 -1.21 -7.78 See how I managed to summarise every variable in one simple call to summarise_at()? Simply by using vars() and specifying that I was interested in the ones that started with “l” and then I specified the function I wanted. But what if I wanted to use more than one function to summarise the data? Very easy: gasoline %&gt;% group_by(country) %&gt;% summarise_at(vars(starts_with(&quot;l&quot;)), funs(mean, sd, max, min)) ## # A tibble: 18 x 17 ## country lgaspcar_mean lincomep_mean lrpmg_mean lcarpcap_mean lgaspcar_sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 -6.12 -0.486 -8.85 0.0693 ## 2 BELGIUM 3.92 -5.85 -0.326 -8.63 0.103 ## 3 CANADA 4.86 -5.58 -1.05 -8.08 0.0262 ## 4 DENMARK 4.19 -5.76 -0.358 -8.58 0.158 ## 5 FRANCE 3.82 -5.87 -0.253 -8.45 0.0499 ## 6 GERMANY 3.89 -5.85 -0.517 -8.51 0.0239 ## 7 GREECE 4.88 -6.61 -0.0339 -10.8 0.255 ## 8 IRELAND 4.23 -6.44 -0.348 -9.04 0.0437 ## 9 ITALY 3.73 -6.35 -0.152 -8.83 0.220 ## 10 JAPAN 4.70 -6.25 -0.287 -9.95 0.684 ## 11 NETHER… 4.08 -5.92 -0.370 -8.82 0.286 ## 12 NORWAY 4.11 -5.75 -0.278 -8.77 0.123 ## 13 SPAIN 4.06 -5.63 0.739 -9.90 0.317 ## 14 SWEDEN 4.01 -7.82 -2.71 -8.25 0.0364 ## 15 SWITZE… 4.24 -5.93 -0.902 -8.54 0.102 ## 16 TURKEY 5.77 -7.34 -0.422 -12.5 0.329 ## 17 U.K. 3.98 -6.02 -0.459 -8.55 0.0479 ## 18 U.S.A. 4.82 -5.45 -1.21 -7.78 0.0219 ## # ... with 11 more variables: lincomep_sd &lt;dbl&gt;, lrpmg_sd &lt;dbl&gt;, ## # lcarpcap_sd &lt;dbl&gt;, lgaspcar_max &lt;dbl&gt;, lincomep_max &lt;dbl&gt;, ## # lrpmg_max &lt;dbl&gt;, lcarpcap_max &lt;dbl&gt;, lgaspcar_min &lt;dbl&gt;, ## # lincomep_min &lt;dbl&gt;, lrpmg_min &lt;dbl&gt;, lcarpcap_min &lt;dbl&gt; Just use vars() to specify the variables you want to summarise, and then funs() to list all the functions you want to use on each of the columns. But maybe you’re just interested in descriptive statistics for some variables, but not all those that start with “l”? What if you want to use another pattern? Easy to do with the contains() helper: gasoline %&gt;% group_by(country) %&gt;% summarise_at(vars(dplyr::contains(&quot;car&quot;)), funs(mean, sd, max, min)) ## # A tibble: 18 x 9 ## country lgaspcar_mean lcarpcap_mean lgaspcar_sd lcarpcap_sd lgaspcar_max ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 -8.85 0.0693 0.473 4.20 ## 2 BELGIUM 3.92 -8.63 0.103 0.417 4.16 ## 3 CANADA 4.86 -8.08 0.0262 0.195 4.90 ## 4 DENMARK 4.19 -8.58 0.158 0.349 4.50 ## 5 FRANCE 3.82 -8.45 0.0499 0.344 3.91 ## 6 GERMANY 3.89 -8.51 0.0239 0.406 3.93 ## 7 GREECE 4.88 -10.8 0.255 0.839 5.38 ## 8 IRELAND 4.23 -9.04 0.0437 0.345 4.33 ## 9 ITALY 3.73 -8.83 0.220 0.639 4.05 ## 10 JAPAN 4.70 -9.95 0.684 1.20 6.00 ## 11 NETHER… 4.08 -8.82 0.286 0.617 4.65 ## 12 NORWAY 4.11 -8.77 0.123 0.438 4.44 ## 13 SPAIN 4.06 -9.90 0.317 0.960 4.75 ## 14 SWEDEN 4.01 -8.25 0.0364 0.242 4.07 ## 15 SWITZE… 4.24 -8.54 0.102 0.378 4.44 ## 16 TURKEY 5.77 -12.5 0.329 0.751 6.16 ## 17 U.K. 3.98 -8.55 0.0479 0.281 4.10 ## 18 U.S.A. 4.82 -7.78 0.0219 0.162 4.86 ## # ... with 3 more variables: lcarpcap_max &lt;dbl&gt;, lgaspcar_min &lt;dbl&gt;, ## # lcarpcap_min &lt;dbl&gt; I used dplyr::contains() instead of simply contains() because there’s also a purrr::contains(). If you load purrr after dplyr, contains() will actually be purrr::contains() and not dplyr::contains() which causes the above code to fail. There’s also summarise_if(): gasoline %&gt;% group_by(country) %&gt;% summarise_if(is.double, funs(mean, sd, min, max)) ## # A tibble: 18 x 17 ## country lgaspcar_mean lincomep_mean lrpmg_mean lcarpcap_mean lgaspcar_sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 -6.12 -0.486 -8.85 0.0693 ## 2 BELGIUM 3.92 -5.85 -0.326 -8.63 0.103 ## 3 CANADA 4.86 -5.58 -1.05 -8.08 0.0262 ## 4 DENMARK 4.19 -5.76 -0.358 -8.58 0.158 ## 5 FRANCE 3.82 -5.87 -0.253 -8.45 0.0499 ## 6 GERMANY 3.89 -5.85 -0.517 -8.51 0.0239 ## 7 GREECE 4.88 -6.61 -0.0339 -10.8 0.255 ## 8 IRELAND 4.23 -6.44 -0.348 -9.04 0.0437 ## 9 ITALY 3.73 -6.35 -0.152 -8.83 0.220 ## 10 JAPAN 4.70 -6.25 -0.287 -9.95 0.684 ## 11 NETHER… 4.08 -5.92 -0.370 -8.82 0.286 ## 12 NORWAY 4.11 -5.75 -0.278 -8.77 0.123 ## 13 SPAIN 4.06 -5.63 0.739 -9.90 0.317 ## 14 SWEDEN 4.01 -7.82 -2.71 -8.25 0.0364 ## 15 SWITZE… 4.24 -5.93 -0.902 -8.54 0.102 ## 16 TURKEY 5.77 -7.34 -0.422 -12.5 0.329 ## 17 U.K. 3.98 -6.02 -0.459 -8.55 0.0479 ## 18 U.S.A. 4.82 -5.45 -1.21 -7.78 0.0219 ## # ... with 11 more variables: lincomep_sd &lt;dbl&gt;, lrpmg_sd &lt;dbl&gt;, ## # lcarpcap_sd &lt;dbl&gt;, lgaspcar_min &lt;dbl&gt;, lincomep_min &lt;dbl&gt;, ## # lrpmg_min &lt;dbl&gt;, lcarpcap_min &lt;dbl&gt;, lgaspcar_max &lt;dbl&gt;, ## # lincomep_max &lt;dbl&gt;, lrpmg_max &lt;dbl&gt;, lcarpcap_max &lt;dbl&gt; This allows you to summarise every column that contain real numbers. The difference between is.double() and is.numeric() is that is.numeric() returns TRUE for integers too, whereas is.double() returns TRUE for real numbers only (integers are real numbers too, but you know what I mean). To go faster, you can also use summarise_all(): gasoline %&gt;% select(-year) %&gt;% group_by(country) %&gt;% summarise_all(funs(mean, sd, min, max)) ## # A tibble: 18 x 17 ## country lgaspcar_mean lincomep_mean lrpmg_mean lcarpcap_mean lgaspcar_sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 4.06 -6.12 -0.486 -8.85 0.0693 ## 2 BELGIUM 3.92 -5.85 -0.326 -8.63 0.103 ## 3 CANADA 4.86 -5.58 -1.05 -8.08 0.0262 ## 4 DENMARK 4.19 -5.76 -0.358 -8.58 0.158 ## 5 FRANCE 3.82 -5.87 -0.253 -8.45 0.0499 ## 6 GERMANY 3.89 -5.85 -0.517 -8.51 0.0239 ## 7 GREECE 4.88 -6.61 -0.0339 -10.8 0.255 ## 8 IRELAND 4.23 -6.44 -0.348 -9.04 0.0437 ## 9 ITALY 3.73 -6.35 -0.152 -8.83 0.220 ## 10 JAPAN 4.70 -6.25 -0.287 -9.95 0.684 ## 11 NETHER… 4.08 -5.92 -0.370 -8.82 0.286 ## 12 NORWAY 4.11 -5.75 -0.278 -8.77 0.123 ## 13 SPAIN 4.06 -5.63 0.739 -9.90 0.317 ## 14 SWEDEN 4.01 -7.82 -2.71 -8.25 0.0364 ## 15 SWITZE… 4.24 -5.93 -0.902 -8.54 0.102 ## 16 TURKEY 5.77 -7.34 -0.422 -12.5 0.329 ## 17 U.K. 3.98 -6.02 -0.459 -8.55 0.0479 ## 18 U.S.A. 4.82 -5.45 -1.21 -7.78 0.0219 ## # ... with 11 more variables: lincomep_sd &lt;dbl&gt;, lrpmg_sd &lt;dbl&gt;, ## # lcarpcap_sd &lt;dbl&gt;, lgaspcar_min &lt;dbl&gt;, lincomep_min &lt;dbl&gt;, ## # lrpmg_min &lt;dbl&gt;, lcarpcap_min &lt;dbl&gt;, lgaspcar_max &lt;dbl&gt;, ## # lincomep_max &lt;dbl&gt;, lrpmg_max &lt;dbl&gt;, lcarpcap_max &lt;dbl&gt; I removed the year variable because it’s not a variable for which we want to have descriptive statistics. 5.5.5 mutate_*() Of course, mutate() and transmute() also come with scoped versions: gasoline %&gt;% mutate_if(is.double, exp) ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 64.9 0.00154 0.716 0.0000573 ## 2 AUSTRIA 1961 60.4 0.00162 0.704 0.0000671 ## 3 AUSTRIA 1962 58.7 0.00165 0.684 0.0000781 ## 4 AUSTRIA 1963 57.9 0.00171 0.661 0.0000876 ## 5 AUSTRIA 1964 56.7 0.00180 0.641 0.0000973 ## 6 AUSTRIA 1965 56.5 0.00185 0.608 0.000109 ## 7 AUSTRIA 1966 57.3 0.00193 0.627 0.000121 ## 8 AUSTRIA 1967 57.6 0.00196 0.603 0.000132 ## 9 AUSTRIA 1968 57.1 0.00202 0.593 0.000144 ## 10 AUSTRIA 1969 57.2 0.00213 0.572 0.000152 ## # ... with 332 more rows gasoline %&gt;% mutate_at(vars(starts_with(&quot;l&quot;)), exp) ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AUSTRIA 1960 64.9 0.00154 0.716 0.0000573 ## 2 AUSTRIA 1961 60.4 0.00162 0.704 0.0000671 ## 3 AUSTRIA 1962 58.7 0.00165 0.684 0.0000781 ## 4 AUSTRIA 1963 57.9 0.00171 0.661 0.0000876 ## 5 AUSTRIA 1964 56.7 0.00180 0.641 0.0000973 ## 6 AUSTRIA 1965 56.5 0.00185 0.608 0.000109 ## 7 AUSTRIA 1966 57.3 0.00193 0.627 0.000121 ## 8 AUSTRIA 1967 57.6 0.00196 0.603 0.000132 ## 9 AUSTRIA 1968 57.1 0.00202 0.593 0.000144 ## 10 AUSTRIA 1969 57.2 0.00213 0.572 0.000152 ## # ... with 332 more rows gasoline %&gt;% mutate_all(as.character) ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 AUSTRIA 1960 4.173244195 -6.474277179 -0.334547613 -9.766839569 ## 2 AUSTRIA 1961 4.1009891049 -6.426005835 -0.351327614 -9.608621845 ## 3 AUSTRIA 1962 4.0731765511 -6.407308295 -0.379517692 -9.457256552 ## 4 AUSTRIA 1963 4.0595091239 -6.370678539 -0.414251392 -9.343154947 ## 5 AUSTRIA 1964 4.037688787 -6.322246805 -0.445335362 -9.237739346 ## 6 AUSTRIA 1965 4.033983285 -6.294667914 -0.497060662 -9.123903477 ## 7 AUSTRIA 1966 4.0475365589 -6.252545451 -0.466837731 -9.019822048 ## 8 AUSTRIA 1967 4.0529106939 -6.234580709 -0.505883405 -8.934402537 ## 9 AUSTRIA 1968 4.045507048 -6.206894403 -0.522412545 -8.847967407 ## 10 AUSTRIA 1969 4.0463547891 -6.153139668 -0.559110514 -8.788686207 ## # ... with 332 more rows I think that by now, you are able to understand the above lines quite easily. If not, try some other functions, or mutating other variables and you’ll see that it is not that complicated! 5.6 Other useful {tidyverse} functions 5.6.1 if_else(), case_when() and recode() Some other very useful {tidyverse} functions are if_else() and case_when. These two functions, combined with mutate() make it easy to create a new variable whose values must respect certain conditions. For instance, we might want to have a dummy that equals 1 if a country in the European Union (to simplify, say as of 2017) and 0 if not. First let’s create a list of countries that are in the EU: eu_countries &lt;- c(&quot;austria&quot;, &quot;belgium&quot;, &quot;bulgaria&quot;, &quot;croatia&quot;, &quot;republic of cyprus&quot;, &quot;czech republic&quot;, &quot;denmark&quot;, &quot;estonia&quot;, &quot;finland&quot;, &quot;france&quot;, &quot;germany&quot;, &quot;greece&quot;, &quot;hungary&quot;, &quot;ireland&quot;, &quot;italy&quot;, &quot;latvia&quot;, &quot;lithuania&quot;, &quot;luxembourg&quot;, &quot;malta&quot;, &quot;netherla&quot;, &quot;poland&quot;, &quot;portugal&quot;, &quot;romania&quot;, &quot;slovakia&quot;, &quot;slovenia&quot;, &quot;spain&quot;, &quot;sweden&quot;, &quot;u.k.&quot;) I’ve had to change “netherlands” to “netherla” because that’s how the country is called in the gasoline data. Now let’s create a dummy variable that equals 1 for EU countries, and 0 for the others: gasoline %&gt;% mutate(country = tolower(country)) %&gt;% mutate(in_eu = if_else(country %in% eu_countries, 1, 0)) ## # A tibble: 342 x 7 ## country year lgaspcar lincomep lrpmg lcarpcap in_eu ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 1 ## 2 austria 1961 4.10 -6.43 -0.351 -9.61 1 ## 3 austria 1962 4.07 -6.41 -0.380 -9.46 1 ## 4 austria 1963 4.06 -6.37 -0.414 -9.34 1 ## 5 austria 1964 4.04 -6.32 -0.445 -9.24 1 ## 6 austria 1965 4.03 -6.29 -0.497 -9.12 1 ## 7 austria 1966 4.05 -6.25 -0.467 -9.02 1 ## 8 austria 1967 4.05 -6.23 -0.506 -8.93 1 ## 9 austria 1968 4.05 -6.21 -0.522 -8.85 1 ## 10 austria 1969 4.05 -6.15 -0.559 -8.79 1 ## # ... with 332 more rows Instead of 1 and 0, we can of course use strings (I add filter(year == 1960) at the end to have a better view of what happened): gasoline %&gt;% mutate(country = tolower(country)) %&gt;% mutate(in_eu = if_else(country %in% eu_countries, &quot;yes&quot;, &quot;no&quot;)) %&gt;% filter(year == 1960) ## # A tibble: 18 x 7 ## country year lgaspcar lincomep lrpmg lcarpcap in_eu ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 yes ## 2 belgium 1960 4.16 -6.22 -0.166 -9.41 yes ## 3 canada 1960 4.86 -5.89 -0.972 -8.38 no ## 4 denmark 1960 4.50 -6.06 -0.196 -9.33 yes ## 5 france 1960 3.91 -6.26 -0.0196 -9.15 yes ## 6 germany 1960 3.92 -6.16 -0.186 -9.34 yes ## 7 greece 1960 5.04 -7.16 -0.0835 -12.2 yes ## 8 ireland 1960 4.27 -6.72 -0.0765 -9.70 yes ## 9 italy 1960 4.05 -6.73 0.165 -10.1 yes ## 10 japan 1960 6.00 -6.99 -0.145 -12.2 no ## 11 netherla 1960 4.65 -6.22 -0.201 -10.00 yes ## 12 norway 1960 4.44 -6.09 -0.140 -9.68 no ## 13 spain 1960 4.75 -6.17 1.13 -11.6 yes ## 14 sweden 1960 4.06 -8.07 -2.52 -8.74 yes ## 15 switzerl 1960 4.40 -6.16 -0.823 -9.26 no ## 16 turkey 1960 6.13 -7.80 -0.253 -13.5 no ## 17 u.k. 1960 4.10 -6.19 -0.391 -9.12 yes ## 18 u.s.a. 1960 4.82 -5.70 -1.12 -8.02 no I think that if_else() is fairly straightforward, especially if you know ifelse() already. You might be wondering what is the difference between these two. if_else() is stricter than ifelse() and does not do type conversion. Compare the two next lines: ifelse(1 == 1, &quot;0&quot;, 1) ## [1] &quot;0&quot; if_else(1 == 1, &quot;0&quot;, 1) Error: `false` must be type string, not double Type conversion, especially without a warning is very dangerous. if_else()’s behaviour which consists in failing as soon as possble avoids a lot of pain and suffering, especially when programming non-interactively. if_else() also accepts an optional argument, that allows you to specify what should be returned in case of NA: if_else(1 &lt;= NA, 0, 1, 999) ## [1] 999 # Or if_else(1 &lt;= NA, 0, 1, NA_real_) ## [1] NA case_when() can be seen as a generalization of if_else(). Whenever you want to use multiple if_else()s, that’s when you know you should use case_when() (I’m adding the filter at the end for the same reason as before, to see the output better): gasoline %&gt;% mutate(country = tolower(country)) %&gt;% mutate(region = case_when( country %in% c(&quot;france&quot;, &quot;italy&quot;, &quot;turkey&quot;, &quot;greece&quot;, &quot;spain&quot;) ~ &quot;mediterranean&quot;, country %in% c(&quot;germany&quot;, &quot;austria&quot;, &quot;switzerl&quot;, &quot;belgium&quot;, &quot;netherla&quot;) ~ &quot;central europe&quot;, country %in% c(&quot;canada&quot;, &quot;u.s.a.&quot;, &quot;u.k.&quot;, &quot;ireland&quot;) ~ &quot;anglosphere&quot;, country %in% c(&quot;denmark&quot;, &quot;norway&quot;, &quot;sweden&quot;) ~ &quot;nordic&quot;, country %in% c(&quot;japan&quot;) ~ &quot;asia&quot;)) %&gt;% filter(year == 1960) ## # A tibble: 18 x 7 ## country year lgaspcar lincomep lrpmg lcarpcap region ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 central europe ## 2 belgium 1960 4.16 -6.22 -0.166 -9.41 central europe ## 3 canada 1960 4.86 -5.89 -0.972 -8.38 anglosphere ## 4 denmark 1960 4.50 -6.06 -0.196 -9.33 nordic ## 5 france 1960 3.91 -6.26 -0.0196 -9.15 mediterranean ## 6 germany 1960 3.92 -6.16 -0.186 -9.34 central europe ## 7 greece 1960 5.04 -7.16 -0.0835 -12.2 mediterranean ## 8 ireland 1960 4.27 -6.72 -0.0765 -9.70 anglosphere ## 9 italy 1960 4.05 -6.73 0.165 -10.1 mediterranean ## 10 japan 1960 6.00 -6.99 -0.145 -12.2 asia ## 11 netherla 1960 4.65 -6.22 -0.201 -10.00 central europe ## 12 norway 1960 4.44 -6.09 -0.140 -9.68 nordic ## 13 spain 1960 4.75 -6.17 1.13 -11.6 mediterranean ## 14 sweden 1960 4.06 -8.07 -2.52 -8.74 nordic ## 15 switzerl 1960 4.40 -6.16 -0.823 -9.26 central europe ## 16 turkey 1960 6.13 -7.80 -0.253 -13.5 mediterranean ## 17 u.k. 1960 4.10 -6.19 -0.391 -9.12 anglosphere ## 18 u.s.a. 1960 4.82 -5.70 -1.12 -8.02 anglosphere If all you want is to recode values, you can use recode(). For example, the Netherlands is written as “NETHERLA” in the gasoline data, which is quite ugly. Same for Switzerland: gasoline &lt;- gasoline %&gt;% mutate(country = tolower(country)) %&gt;% mutate(country = recode(country, &quot;netherla&quot; = &quot;netherlands&quot;, &quot;switzerl&quot; = &quot;switzerland&quot;)) I saved the data with these changes as they will become useful in the future. Let’s take a look at the data: gasoline %&gt;% filter(country %in% c(&quot;netherlands&quot;, &quot;switzerland&quot;), year == 1960) ## # A tibble: 2 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 netherlands 1960 4.65 -6.22 -0.201 -10.00 ## 2 switzerland 1960 4.40 -6.16 -0.823 -9.26 5.6.2 lead() and lag() lead() and lag() are especially useful in econometrics. When I was doing my masters, in 4 B.d. (Before dplyr) lagging variables in panel data was quite tricky. Now, with dplyr it’s really very easy: gasoline %&gt;% group_by(country) %&gt;% mutate(lag_lgaspcar = lag(lgaspcar)) %&gt;% mutate(lead_lgaspcar = lead(lgaspcar)) %&gt;% filter(year %in% seq(1960, 1963)) ## # A tibble: 72 x 8 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap lag_lgaspcar ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 NA ## 2 austria 1961 4.10 -6.43 -0.351 -9.61 4.17 ## 3 austria 1962 4.07 -6.41 -0.380 -9.46 4.10 ## 4 austria 1963 4.06 -6.37 -0.414 -9.34 4.07 ## 5 belgium 1960 4.16 -6.22 -0.166 -9.41 NA ## 6 belgium 1961 4.12 -6.18 -0.172 -9.30 4.16 ## 7 belgium 1962 4.08 -6.13 -0.222 -9.22 4.12 ## 8 belgium 1963 4.00 -6.09 -0.250 -9.11 4.08 ## 9 canada 1960 4.86 -5.89 -0.972 -8.38 NA ## 10 canada 1961 4.83 -5.88 -0.972 -8.35 4.86 ## # ... with 62 more rows, and 1 more variable: lead_lgaspcar &lt;dbl&gt; To lag every variable, remember that you can use mutate_if(): gasoline %&gt;% group_by(country) %&gt;% mutate_if(is.double, lag) %&gt;% filter(year %in% seq(1960, 1963)) ## # A tibble: 72 x 6 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 ## 2 austria 1961 4.10 -6.43 -0.351 -9.61 ## 3 austria 1962 4.07 -6.41 -0.380 -9.46 ## 4 austria 1963 4.06 -6.37 -0.414 -9.34 ## 5 belgium 1960 4.16 -6.22 -0.166 -9.41 ## 6 belgium 1961 4.12 -6.18 -0.172 -9.30 ## 7 belgium 1962 4.08 -6.13 -0.222 -9.22 ## 8 belgium 1963 4.00 -6.09 -0.250 -9.11 ## 9 canada 1960 4.86 -5.89 -0.972 -8.38 ## 10 canada 1961 4.83 -5.88 -0.972 -8.35 ## # ... with 62 more rows you can replace lag() with lead(), but just keep in mind that the columns get transformed in place. 5.6.3 ntile() The last helper function I will discuss is ntile(). There are some other, so do read mutate()’s documentation with help(mutate)! If you need quantiles, you need ntile(). Let’s see how it works: gasoline %&gt;% mutate(quintile = ntile(lgaspcar, 5)) %&gt;% mutate(decile = ntile(lgaspcar, 10)) %&gt;% select(country, year, lgaspcar, quintile, decile) ## # A tibble: 342 x 5 ## country year lgaspcar quintile decile ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 austria 1960 4.17 3 6 ## 2 austria 1961 4.10 3 6 ## 3 austria 1962 4.07 3 5 ## 4 austria 1963 4.06 3 5 ## 5 austria 1964 4.04 3 5 ## 6 austria 1965 4.03 3 5 ## 7 austria 1966 4.05 3 5 ## 8 austria 1967 4.05 3 5 ## 9 austria 1968 4.05 3 5 ## 10 austria 1969 4.05 3 5 ## # ... with 332 more rows quintile and decile do not hold the values but the quantile the value lies in. If you want to have a column that contains the median for instance, you can use good ol’ quantile(): gasoline %&gt;% group_by(country) %&gt;% mutate(median = quantile(lgaspcar, 0.5)) %&gt;% # quantile(x, 0.5) is equivalent to median(x) filter(year == 1960) %&gt;% select(country, year, median) ## # A tibble: 18 x 3 ## # Groups: country [18] ## country year median ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 austria 1960 4.05 ## 2 belgium 1960 3.88 ## 3 canada 1960 4.86 ## 4 denmark 1960 4.16 ## 5 france 1960 3.81 ## 6 germany 1960 3.89 ## 7 greece 1960 4.89 ## 8 ireland 1960 4.22 ## 9 italy 1960 3.74 ## 10 japan 1960 4.52 ## 11 netherlands 1960 3.99 ## 12 norway 1960 4.08 ## 13 spain 1960 3.99 ## 14 sweden 1960 4.00 ## 15 switzerland 1960 4.26 ## 16 turkey 1960 5.72 ## 17 u.k. 1960 3.98 ## 18 u.s.a. 1960 4.81 5.6.4 arrange() arrange() re-orders the whole tibble according to values of the supplied variable: gasoline %&gt;% arrange(lgaspcar) ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 italy 1977 3.38 -6.10 0.164 -8.15 ## 2 italy 1978 3.39 -6.08 0.0348 -8.11 ## 3 italy 1976 3.43 -6.12 0.103 -8.17 ## 4 italy 1974 3.50 -6.13 -0.223 -8.26 ## 5 italy 1975 3.52 -6.17 -0.0327 -8.22 ## 6 spain 1978 3.62 -5.29 0.621 -8.63 ## 7 italy 1972 3.63 -6.21 -0.215 -8.38 ## 8 italy 1971 3.65 -6.22 -0.148 -8.47 ## 9 spain 1977 3.65 -5.30 0.526 -8.73 ## 10 italy 1973 3.65 -6.16 -0.325 -8.32 ## # ... with 332 more rows If you want to re-order the tibble in descending order of the variable: gasoline %&gt;% arrange(desc(lgaspcar)) ## # A tibble: 342 x 6 ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 turkey 1966 6.16 -7.51 -0.356 -13.0 ## 2 turkey 1960 6.13 -7.80 -0.253 -13.5 ## 3 turkey 1961 6.11 -7.79 -0.343 -13.4 ## 4 turkey 1962 6.08 -7.84 -0.408 -13.2 ## 5 turkey 1968 6.08 -7.42 -0.365 -12.8 ## 6 turkey 1963 6.08 -7.63 -0.225 -13.3 ## 7 turkey 1964 6.06 -7.63 -0.252 -13.2 ## 8 turkey 1967 6.04 -7.46 -0.335 -12.8 ## 9 japan 1960 6.00 -6.99 -0.145 -12.2 ## 10 turkey 1965 5.82 -7.62 -0.293 -12.9 ## # ... with 332 more rows arrange’s documentation alerts the user that re-ording by group is only possible by explicitely specifying an option: gasoline %&gt;% filter(year %in% seq(1960, 1963)) %&gt;% group_by(country) %&gt;% arrange(desc(lgaspcar), .by_group = TRUE) ## # A tibble: 72 x 6 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 ## 2 austria 1961 4.10 -6.43 -0.351 -9.61 ## 3 austria 1962 4.07 -6.41 -0.380 -9.46 ## 4 austria 1963 4.06 -6.37 -0.414 -9.34 ## 5 belgium 1960 4.16 -6.22 -0.166 -9.41 ## 6 belgium 1961 4.12 -6.18 -0.172 -9.30 ## 7 belgium 1962 4.08 -6.13 -0.222 -9.22 ## 8 belgium 1963 4.00 -6.09 -0.250 -9.11 ## 9 canada 1960 4.86 -5.89 -0.972 -8.38 ## 10 canada 1962 4.85 -5.84 -0.979 -8.32 ## # ... with 62 more rows This is especially useful for plotting. We’ll see this in Chapter 6. 5.6.5 tally() and count() tally() and count() count the number of observations in your data. I believe count() is the more useful of the two, as it counts the number of observations within a group that you can provide: gasoline %&gt;% count(country) ## # A tibble: 18 x 2 ## country n ## &lt;chr&gt; &lt;int&gt; ## 1 austria 19 ## 2 belgium 19 ## 3 canada 19 ## 4 denmark 19 ## 5 france 19 ## 6 germany 19 ## 7 greece 19 ## 8 ireland 19 ## 9 italy 19 ## 10 japan 19 ## 11 netherlands 19 ## 12 norway 19 ## 13 spain 19 ## 14 sweden 19 ## 15 switzerland 19 ## 16 turkey 19 ## 17 u.k. 19 ## 18 u.s.a. 19 There’s also add_count() which adds the column to the data: gasoline %&gt;% add_count(country) ## # A tibble: 342 x 7 ## country year lgaspcar lincomep lrpmg lcarpcap n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 19 ## 2 austria 1961 4.10 -6.43 -0.351 -9.61 19 ## 3 austria 1962 4.07 -6.41 -0.380 -9.46 19 ## 4 austria 1963 4.06 -6.37 -0.414 -9.34 19 ## 5 austria 1964 4.04 -6.32 -0.445 -9.24 19 ## 6 austria 1965 4.03 -6.29 -0.497 -9.12 19 ## 7 austria 1966 4.05 -6.25 -0.467 -9.02 19 ## 8 austria 1967 4.05 -6.23 -0.506 -8.93 19 ## 9 austria 1968 4.05 -6.21 -0.522 -8.85 19 ## 10 austria 1969 4.05 -6.15 -0.559 -8.79 19 ## # ... with 332 more rows add_count() is a shortcut for the following code: gasoline %&gt;% group_by(country) %&gt;% mutate(n = n()) ## # A tibble: 342 x 7 ## # Groups: country [18] ## country year lgaspcar lincomep lrpmg lcarpcap n ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 austria 1960 4.17 -6.47 -0.335 -9.77 19 ## 2 austria 1961 4.10 -6.43 -0.351 -9.61 19 ## 3 austria 1962 4.07 -6.41 -0.380 -9.46 19 ## 4 austria 1963 4.06 -6.37 -0.414 -9.34 19 ## 5 austria 1964 4.04 -6.32 -0.445 -9.24 19 ## 6 austria 1965 4.03 -6.29 -0.497 -9.12 19 ## 7 austria 1966 4.05 -6.25 -0.467 -9.02 19 ## 8 austria 1967 4.05 -6.23 -0.506 -8.93 19 ## 9 austria 1968 4.05 -6.21 -0.522 -8.85 19 ## 10 austria 1969 4.05 -6.15 -0.559 -8.79 19 ## # ... with 332 more rows where n() is a dplyr function that can only be used within summarise(), mutate() and filter(). 5.7 Special packages for special kinds of data: {forcats}, {lubridate}, and {stringr} 5.7.1 🐈🐈🐈🐈 Factor variables are very useful but not very easy to manipulate. forcats contains very useful functions that make working on factor variables painless. In my opinion, the four following functions, fct_recode(), fct_relevel(), fct_reorder() and fct_relabel(), are the ones you must know, so that’s what I’ll be showing. Remember in chapter 3 when I very quickly explained what were factor variables? In this section, we are going to work a little bit with these type of variable. factors are very useful, and the forcats package includes some handy functions to work with them. First, let’s load the forcats package: library(forcats) as an example, we are going to work with the gss_cat dataset that is included in forcats. Let’s load the data: data(gss_cat) head(gss_cat) ## # A tibble: 6 x 9 ## year marital age race rincome partyid relig denom tvhours ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 2000 Never ma… 26 White $8000 to… Ind,near … Protes… Southe… 12 ## 2 2000 Divorced 48 White $8000 to… Not str r… Protes… Baptis… NA ## 3 2000 Widowed 67 White Not appl… Independe… Protes… No den… 2 ## 4 2000 Never ma… 39 White Not appl… Ind,near … Orthod… Not ap… 4 ## 5 2000 Divorced 25 White Not appl… Not str d… None Not ap… 1 ## 6 2000 Married 25 White $20000 -… Strong de… Protes… Southe… NA as you can see, marital, race, rincome and partyid are all factor variables. Let’s take a closer look at marital: str(gss_cat$marital) ## Factor w/ 6 levels &quot;No answer&quot;,&quot;Never married&quot;,..: 2 4 5 2 4 6 2 4 6 6 ... and let’s see rincome: str(gss_cat$rincome) ## Factor w/ 16 levels &quot;No answer&quot;,&quot;Don&#39;t know&quot;,..: 8 8 16 16 16 5 4 9 4 4 ... factor variables have different levels and the forcats package includes functions that allow you to recode, collapse and do all sorts of things on these levels. For example , using forcats::fct_recode() you can recode levels: gss_cat &lt;- gss_cat %&gt;% mutate(marital = fct_recode(marital, refuse = &quot;No answer&quot;, never_married = &quot;Never married&quot;, divorced = &quot;Separated&quot;, divorced = &quot;Divorced&quot;, widowed = &quot;Widowed&quot;, married = &quot;Married&quot;)) gss_cat %&gt;% tabyl(marital) ## marital n percent ## refuse 17 0.0007913234 ## never_married 5416 0.2521063166 ## divorced 4126 0.1920588372 ## widowed 1807 0.0841130196 ## married 10117 0.4709305032 Using fct_recode(), I was able to recode the levels and collapse Separated and Divorced to a single category called divorced. As you can see, refuse and widowed are less than 10%, so maybe you’d want to lump these categories together: gss_cat &lt;- gss_cat %&gt;% mutate(marital = fct_lump(marital, prop = 0.10, other_level = &quot;other&quot;)) gss_cat %&gt;% tabyl(marital) ## marital n percent ## never_married 5416 0.25210632 ## divorced 4126 0.19205884 ## married 10117 0.47093050 ## other 1824 0.08490434 fct_reorder() is especially useful for plotting. We will explore plotting in the next chapter, but to show you why fct_reorder() is so useful, I will create a barplot, first without using fct_reorder() to re-order the factors, then with reordering. Do not worry if you don’t understand all the code for now: gss_cat %&gt;% tabyl(marital) %&gt;% ggplot() + geom_col(aes(y = n, x = marital)) + coord_flip() It would be much better if the categories were ordered by frequency. This is easy to do with fct_reorder(): gss_cat %&gt;% tabyl(marital) %&gt;% mutate(marital = fct_reorder(marital, n, .desc = FALSE)) %&gt;% ggplot() + geom_col(aes(y = n, x = marital)) + coord_flip() Much better! In Chapter 6, we are going to learn about {ggplot2}. {forcats} contains other very useful functions, so I urge you to go through the documentation. 5.7.2 Get your dates right with {lubridate} Just like {forcats}, {lubridate} contains numerous functions, each one of them very useful. However, here, I will only focus on a handful of them (those that I use very often). If you need to work with dates a lot in your work, consider reading all the documentation. 5.7.3 Manipulate strings with {stringr} {stringr} contains functions to manipulate strings. In Chapter 11, I will teach you about regular expressions, but the functions contained in {stringr} allow you to already do a lot of work on strings, without needing to be a regular expression expert. I will discuss the most common string operations: search and replace (or remove), detect, locate or match, and trim a string. 5.8 List-columns To learn about list-columns, let’s first focus on a single character of the starwars dataset: data(starwars) starwars %&gt;% filter(name == &quot;Luke Skywalker&quot;) %&gt;% glimpse() ## Observations: 1 ## Variables: 13 ## $ name &lt;chr&gt; &quot;Luke Skywalker&quot; ## $ height &lt;int&gt; 172 ## $ mass &lt;dbl&gt; 77 ## $ hair_color &lt;chr&gt; &quot;blond&quot; ## $ skin_color &lt;chr&gt; &quot;fair&quot; ## $ eye_color &lt;chr&gt; &quot;blue&quot; ## $ birth_year &lt;dbl&gt; 19 ## $ gender &lt;chr&gt; &quot;male&quot; ## $ homeworld &lt;chr&gt; &quot;Tatooine&quot; ## $ species &lt;chr&gt; &quot;Human&quot; ## $ films &lt;list&gt; [&lt;&quot;Revenge of the Sith&quot;, &quot;Return of the Jedi&quot;, &quot;Th... ## $ vehicles &lt;list&gt; [&lt;&quot;Snowspeeder&quot;, &quot;Imperial Speeder Bike&quot;&gt;] ## $ starships &lt;list&gt; [&lt;&quot;X-wing&quot;, &quot;Imperial shuttle&quot;&gt;] We see that the columns films, vehicles and starships are all lists, and in the case of films, it lists all the films where Luke Skywalker has appeared. What if you want to take a closer look at this list? starwars %&gt;% filter(name == &quot;Luke Skywalker&quot;) %&gt;% pull(films) ## [[1]] ## [1] &quot;Revenge of the Sith&quot; &quot;Return of the Jedi&quot; ## [3] &quot;The Empire Strikes Back&quot; &quot;A New Hope&quot; ## [5] &quot;The Force Awakens&quot; pull() is a dplyr function that extract (pulls) the column you’re interested in. It is quite useful when you want to inspect a column. Suppose we want to create a categorical variable which counts the number of movies in which the characters have appeared. For this we need to compute the length of the list, or count the number of elements this list has. Let’s try with length() a base R function: starwars %&gt;% filter(name == &quot;Luke Skywalker&quot;) %&gt;% pull(films) %&gt;% length() ## [1] 1 This might be surprising at first, because we know that Luke Skywalker has appeared in more than 1 movie… the problem here is that for each individual, films is a list, whose single element is a vector of characters. This means that length(films) computes the length of the list, which is one, and not the length of the vector contained in the list! How can we get the length of the vector of characters contained in the list and for each character? For this we need to use dplyr::rowwise() and remove the filter() function and use mutate() to add this column to the dataset: starwars &lt;- starwars %&gt;% rowwise() %&gt;% mutate(n_films = length(films)) dplyr::rowwise() is useful when working with list-columns: columns that have lists as elements. Let’s take a look at the characters and the number of films they have appeared in: starwars %&gt;% select(name, n_films) ## Source: local data frame [87 x 2] ## Groups: &lt;by row&gt; ## ## # A tibble: 87 x 2 ## name n_films ## &lt;chr&gt; &lt;int&gt; ## 1 Luke Skywalker 5 ## 2 C-3PO 6 ## 3 R2-D2 7 ## 4 Darth Vader 4 ## 5 Leia Organa 5 ## 6 Owen Lars 3 ## 7 Beru Whitesun lars 3 ## 8 R5-D4 1 ## 9 Biggs Darklighter 1 ## 10 Obi-Wan Kenobi 6 ## # ... with 77 more rows Now we can create a factor variable that groups characters by asking whether they appeared only in 1 movie, or more: starwars &lt;- starwars %&gt;% mutate(more_1 = case_when(n_films == 1 ~ &quot;Exactly one movie&quot;, n_films != 1 ~ &quot;More than 1 movie&quot;)) case_when() is a dplyr function that works similarly to the standard if..else.. construct of many programming languages (R also has this, we are going to learn about it in later chapters). You can also create list columns with your own datasets, by using tidyr::nest(). Remember the fake survey_data I created to illustrate spread() and gather()? Let’s go back to that dataset again: print(survey_data) ## # A tibble: 12 x 3 ## id variable value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 var1 1 ## 2 1 var2 0.2 ## 3 NA var3 0.3 ## 4 2 var1 1.4 ## 5 2 var2 1.9 ## 6 2 var3 4.1 ## 7 3 var1 0.1 ## 8 3 var2 2.8 ## 9 3 var3 8.9 ## 10 4 var1 1.7 ## 11 NA var2 1.9 ## 12 4 var3 7.6 nested_data = survey_data %&gt;% nest(variable, value) print(nested_data) ## # A tibble: 5 x 2 ## id data ## &lt;dbl&gt; &lt;list&gt; ## 1 1 &lt;tibble [2 × 2]&gt; ## 2 NA &lt;tibble [2 × 2]&gt; ## 3 2 &lt;tibble [3 × 2]&gt; ## 4 3 &lt;tibble [3 × 2]&gt; ## 5 4 &lt;tibble [2 × 2]&gt; This creates a new tibble, with columns id and data. data is a list-column that contains tibbles; each tibble is the variable and value for each individual: nested_data %&gt;% filter(id == &quot;1&quot;) %&gt;% pull(data) ## [[1]] ## # A tibble: 2 x 2 ## variable value ## &lt;chr&gt; &lt;dbl&gt; ## 1 var1 1 ## 2 var2 0.2 As you can see, for individual 1, the column data contains a 2x2 tibble with columns variable and value. You might be wondering why this is useful, because this seems to introduce an unnecessary layer of complexity. The usefulness of list-columns will become apparent in the next chapters, where we are going to learn how to repeat actions over, say, individuals. 5.9 Exercises Exercise 1 Load the LaborSupply dataset from the Ecdat package and answer the following questions: Compute the average annual hours worked by year (plus standard deviation) What age group worked the most hours in the year 1982? Create a variable, n_years that equals the number of years an individual stays in the panel. Is the panel balanced? Which are the individuals that do not have any kids during the whole period? Create a variable, no_kids, that flags these individuals (1 = no kids, 0 = kids) Using the no_kids variable from before compute the average wage, standard deviation and number of observations in each group for the year 1980 (no kids group vs kids group). Create the lagged logarithm of hours worked and wages. Remember that this is a panel. Exercise 2 What does the following code do? Copy and paste it in an R interpreter to find out! LaborSupply %&gt;% group_by(id) %&gt;% mutate_at(vars(starts_with(&quot;l&quot;)), funs(lag, lead)) mutate_at() is a scoped version of mutate() which allows you to specify a number of columns and functions in one go. This also exists for summarise(). Using summarise_at(), compute the mean, standard deviation and number of individuals of lnhr and lnwg for each individual. Exercise 3 In the dataset folder you downloaded at the beginning of the chapter, there is a folder called “unemployment”. I used the data in the section about working with lists of datasets. Using rio::import_list(), read the 4 datasets into R. Using map(), map the janitor::clean_names() function to each dataset (just like in the example in the section on working with lists of datasets). Then, still with map() and mutate() convert all commune names in the commune column with the function tolower(), in a new column called lcommune. This is not an easy exercise; so here are some hints: Remember that all_datasets is a list of datasets. Which function do you use when you want to map a function to each element of a list? Each element of all_datasets are data.frame objects. Which function do you use to add a column to a data.frame? What symbol can you use to access a column of a data.frame? References "],
["graphs.html", "Chapter 6 Graphs 6.1 Resources 6.2 Examples 6.3 Customization 6.4 Exercises", " Chapter 6 Graphs By default, it is possible to make a lot of graphs with R without the need of any external packages. However, in this chapter, we are going to learn how to make graphs using ggplot2 which is a very powerful package that produces amazing graphs. There is an entry cost to ggplot2 as it works in a very different way than what you would expect, especially if you know how to make plots with the basic R functions already. But the resulting graphs are well worth the effort and once you’ll know more about ggplot2 you’ll see that in a lot of situations it is actually faster and easier. Even if you are not interested in drawing plots, I advise you continue reading, as we will dig deeper into functional programming territory and learn how to graph an arbitrary large amount of plots with a few lines of code. 6.1 Resources Before showing some examples and the general functionality of ggplot2, I list here some online resources that I keep coming back to: Data Visualization for Social Science R Graphics Cookbook R graph gallery Tufte in R ggplot2 extensions ggthemes Vignette ggplot2 cheatsheet I have a cookbook approach to using ggplot2; I try to find an example online that looks similar to what I have in mind, copy and paste the code and then adapt it to my case. The above resources are the ones I consult the most in these situations (I also go back to past code I’ve written, of course). Don’t hesitate to skim these resources for inspiration and to learn more about some extensions to ggplot2. In the next subsections I am going to show you how to draw the most common plots, as well as show you how to customize your plots with ggthemes. 6.2 Examples 6.2.1 Barplots To follow the examples below, load the following libraries: library(ggplot2) library(ggthemes) ggplot2 is an implementation of the Grammar of Graphics by Wilkinson (2006), but you don’t need to read the books to start using it. If we go back to the Star Wars data (contained in dplyr), and wish to draw a barplot of the gender, the following lines are enough: ggplot(starwars, aes(gender)) + geom_bar() The first argument of the function is the data (called starwars in this example), and then the function aes(). This function is where you list the variables you want to map, and to quote the help file of aes(), describes how the variables are mapped to visual properties (aesthetics) of geoms. You can get different kind of plots by using different geom_ functions. You can also change the coordinate system in your barplot: ggplot(starwars, aes(gender)) + geom_bar() + coord_flip() 6.2.2 Density geom_density() is the geom that allows you to get density plots: ggplot(starwars, aes(height)) + geom_density() ## Warning: Removed 6 rows containing non-finite values (stat_density). Let’s go into more detail now; what if you would like to plot the densities for females and males only (removing the droids from the data first)? This can be done by first filtering the data using dplyr and then separating the dataset by gender: starwars %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;)) The above lines do the filtering; only keep gender if gender is in the vector &quot;female&quot;, &quot;male&quot;. This is much easier than having to write gender == &quot;female&quot; | gender == &quot;male&quot;. Then, we pipe this dataset to ggplot: starwars %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;)) %&gt;% ggplot(aes(height, fill = gender)) + geom_density() ## Warning: Removed 5 rows containing non-finite values (stat_density). Let’s take a closer look to the aes() function: I’ve added fill = gender. This means that the there will be one density plot for each gender in the data, and each will be coloured accordingly. This is where ggplot2 might be confusing; there is no need to write explicitly (even if it is possible) that you want the female density to be red and the male density to be blue. You just map the variable gender to this particular aesthetic. You conclude the plot by adding geom_density() which is this case is the plot you want. We will see later how to change the colours of your plot. 6.2.3 Line plots For the line plots, we are going to use official unemployment data (the same as in the previous chapter, but with all the available years). Get it from here (downloaded from: http://www.statistiques.public.lu/stat/TableViewer/tableView.aspx?ReportId=12950&amp;IF_Language=eng&amp;MainTheme=2&amp;FldrName=3&amp;RFPath=91). Let’s plot the unemployment for the canton of Luxembourg only: unemp_lux_data = import(&quot;datasets/unemployment/all/unemployment_lux_all.csv&quot;) unemp_lux_data %&gt;% filter(division == &quot;Luxembourg&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = 1)) + geom_line() Because line plots are 2D, you need to specify the y and x axes. There is also another option you need to add, group = 1. This is to tell aes() that the dots have to be connected with a single line. What if you want to plot more than one commune? unemp_lux_data %&gt;% filter(division == &quot;Luxembourg&quot; | division == &quot;Esch-sur-Alzette&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + geom_line() This time, I’ve specified group = division which means that there has to be one line per as many communes as in the variable division. I do the same for colours. I think the next example illustrates how ggplot2 is actually brilliant; if you need to add a third commune, there is no need to specify anything else; no need to add anything to the legend, no need to specify a third colour etc: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + geom_line() 6.2.4 Facets In some case you have a factor variable that separates the data you wish to plot into different categories. If you want to have a plot per category you can use the facet_grid() function. Careful though, this function does not take a variable as an argument, but a formula, hence the ~ symbol in the code below: starwars %&gt;% mutate(human = case_when(species == &quot;Human&quot; ~ &quot;Human&quot;, species != &quot;Human&quot; ~ &quot;Not Human&quot;)) %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;), !is.na(human)) %&gt;% ggplot(aes(height, fill = gender)) + facet_grid(. ~ human) + #&lt;--- this is a formula geom_density() ## Warning: Removed 4 rows containing non-finite values (stat_density). By changing the formula, you change how the facetting is done: starwars %&gt;% mutate(human = case_when(species == &quot;Human&quot; ~ &quot;Human&quot;, species != &quot;Human&quot; ~ &quot;Not Human&quot;)) %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;), !is.na(human)) %&gt;% ggplot(aes(height, fill = gender)) + facet_grid(human ~ .) + geom_density() ## Warning: Removed 4 rows containing non-finite values (stat_density). Recall the categorical variable more_1 that we computed in the previous chapter? Let’s use it as a faceting variable: starwars %&gt;% rowwise() %&gt;% mutate(n_films = length(films)) %&gt;% mutate(more_1 = case_when(n_films == 1 ~ &quot;Exactly one movie&quot;, n_films != 1 ~ &quot;More than 1 movie&quot;)) %&gt;% mutate(human = case_when(species == &quot;Human&quot; ~ &quot;Human&quot;, species != &quot;Human&quot; ~ &quot;Not Human&quot;)) %&gt;% filter(gender %in% c(&quot;female&quot;, &quot;male&quot;), !is.na(human)) %&gt;% ggplot(aes(height, fill = gender)) + facet_grid(human ~ more_1) + geom_density() ## Warning: Removed 4 rows containing non-finite values (stat_density). 6.2.5 Pie Charts I am not a huge fan of pie charts, but sometimes this is what you have to do. So let’s see how you can create pie charts. First, let’s create a mock dataset with the function tibble::tribble() which allows you to create a dataset line by line: test_data &lt;- tribble( ~id, ~var1, ~var2, ~var3, ~var4, ~var5, &quot;a&quot;, 26.5, 38, 30, 32, 34, &quot;b&quot;, 30, 30, 28, 32, 30, &quot;c&quot;, 34, 32, 30, 28, 26.5 ) This data is not in the right format though, which is wide. We need to have it in the long format for it to work with ggplot2. For this, let’s use tidyr::gather() as seen in the previous chapter: test_data_long = test_data %&gt;% gather(variable, value, starts_with(&quot;var&quot;)) Now, let’s plot this data, first by creating 3 bar plots: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) In the code above, I introduce a new option, called stat = &quot;identity&quot;. By default, geom_bar() counts the number of observations of each category that is plotted, which is a statistical transformation. By adding stat = &quot;identity&quot;, I force the statistical transformation to be the identity function, and thus plot the data as is. To create the pie chart, first we need to compute the share of each id to var1, var2, etc… To do this, we first group by id, then compute the total. Then we use a new function ungroup(). After using ungroup() all the computations are done on the whole dataset instead of by group, which is what we need to compute the share: test_data_long = test_data_long %&gt;% group_by(id) %&gt;% mutate(total = sum(value)) %&gt;% ungroup() %&gt;% mutate(share = value/total) Let’s take a look to see if this is what we wanted: print(test_data_long) ## # A tibble: 15 x 5 ## id variable value total share ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a var1 26.5 160. 0.165 ## 2 b var1 30 150 0.2 ## 3 c var1 34 150. 0.226 ## 4 a var2 38 160. 0.237 ## 5 b var2 30 150 0.2 ## 6 c var2 32 150. 0.213 ## 7 a var3 30 160. 0.187 ## 8 b var3 28 150 0.187 ## 9 c var3 30 150. 0.199 ## 10 a var4 32 160. 0.199 ## 11 b var4 32 150 0.213 ## 12 c var4 28 150. 0.186 ## 13 a var5 34 160. 0.212 ## 14 b var5 30 150 0.2 ## 15 c var5 26.5 150. 0.176 If you didn’t understand what ungroup() did, rerun the last few lines with it and inspect the output. To plot the pie chart, we create a barplot again, but specify polar coordinates: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(y = share, x = &quot;&quot;, fill = variable), stat = &quot;identity&quot;) + theme() + coord_polar(&quot;y&quot;, start = 0) As you can see, this typical pie chart is not very easy to read; compared to the barplots above it is not easy to distinguish a from b from c. It is possible to amend the pie chart a bit to make it clearer, by specifying variable as the x: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(y = share, x = variable, fill = variable), stat = &quot;identity&quot;) + theme() + coord_polar(&quot;x&quot;, start = 0) But as a general rule, avoid pie charts if possible. Barplots show the same information, much, much clearer. 6.2.6 Adding text to plots Sometimes you might want to add some text to your plots. This is possible with geom_text(): ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = value)) You can put anything after label =but in general what you’d want are the values, so that’s what I put there. But you can also refine it, imagine the values are actualy, say €: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = paste(value, &quot;€&quot;))) 6.3 Customization Every plot you’ve seen until now was made with the default look of ggplot2. If you want to change the look, you can apply a theme, and a colour scheme. Let’s take a look at themes first by using the ones found in the package ggthemes. But first, let’s learn how to change the names of the axes and how to title a plot. 6.3.1 Titles, axes names and more To change the title of the plot, and of the axes, you need to pass the names to the labs() function: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() What if you want to make the lines thicker? unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line(size = 2) 6.3.2 Themes Let’s go back to the unemployment line plots. For now, let’s keep the base ggplot2 theme, but modify it a bit. For example, the legend placement is actually a feature of the theme. This means that if you want to change where the legend is placed you need to modify this feature from the theme. This is done with the function theme(): unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme(legend.position = &quot;bottom&quot;) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;)+ geom_line() What I also like to do is remove the title of the legend, because it is often superfluous: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;)+ geom_line() The legend title has to be an element_text object.element_text objects are used with theme to specify how text should be displayed. element_blank() draws nothing and assigns no space (not even blank space). You could modify every feature of the theme like that, but there are built-in themes that you can use: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() For example in the code above, I have used theme_minimal() which I like quite a lot. You can also use themes from the ggthemes package, which even contains a STATA theme, if you like it: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_stata() + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() As you can see, theme_stata() has the legend on the bottom by default, because this is how the legend position is defined within the theme. However the legend title is still there. Let’s remove it: unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_stata() + theme(legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() ggthemes even features an Excel 2003 theme (don’t use it though): unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_excel() + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() 6.3.3 Colour schemes from ggthemes You can also change colour schemes, by specifying either scale_colour_* or scale_fill_* functions. scale_colour_* functions are used for continuous variables, while scale_fill_* functions for discrete variables (so for barplots for example). A colour scheme I like is the Highcharts colour scheme. unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_minimal() + scale_colour_hc() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() An example with a barplot: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = value)) + theme_minimal() + scale_fill_hc() 6.3.4 Using your own colours To use your own colours you can use scale_colour_manual() and scale_fill_manual() and specify the html codes of the colours you want to use. unemp_lux_data %&gt;% filter(division %in% c(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;)) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division, colour = division)) + theme_minimal() + scale_colour_manual(values = c(&quot;#FF336C&quot;, &quot;#334BFF&quot;, &quot;#2CAE00&quot;)) + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + labs(title = &quot;Unemployment in Luxembourg, Esch/Alzette and Wiltz&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() To get html codes of colours you can use this online tool. There is also a very nice package, called colourpicker that allows you to pick colours from with RStudio. Also, you do not even need to load it to use it, since it comes with an Addin: For a barplot you would do the same: ggplot(test_data_long) + facet_wrap(~id) + geom_bar(aes(variable, value, fill = variable), stat = &quot;identity&quot;) + geom_text(aes(variable, value + 1.5, label = value)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, legend.title = element_blank()) + scale_fill_manual(values = c(&quot;#FF336C&quot;, &quot;#334BFF&quot;, &quot;#2CAE00&quot;, &quot;#B3C9C6&quot;, &quot;#765234&quot;)) 6.3.5 Saving plots on disk There are two ways to save plots on disk; one through the Plots in RStudio and another using the ggsave() function. Using RStudio, navigate to the Plots pane and click on Export. You can then choose where to save the plot and other various options: knitr::include_graphics(&quot;pics/rstudio_save_plots.gif&quot;) This is fine if you only generate one or two plots but if you generate a large number of them, it is less tedious to use the ggsave() function: my_plot1 = ggplot(my_data) + geom_bar(aes(variable)) ggsave(&quot;path/you/want/to/save/the/plot/to/my_plot1.pdf&quot;, my_plot1) There are other options that you can specify such as the width and height, resolution, units, etc… 6.4 Exercises Exercise 1 This exercise will force you to look for ggplot2 functions that you don’t know yet. But it’s a good exercise, so my advice is to try to do it, even if takes you a long time to find the right functions. Load the Bwages dataset from the Ecdat package. Your first task is to create a new variable, educ_level, which is a factor variable that equals: “Primary school” if educ == 1 “High school” if educ == 2 “Some university” if educ == 3 “Master’s degree” if educ == 4 “Doctoral degree” if educ == 5 Use case_when() for this. Then, plot a scatter plot of wages on experience, by education level. Add a theme that you like, and remove the title of the legend. The scatter plot is not very useful, because you cannot make anything out. Instead, use another geom that shows you a non-parametric fit with confidence bands. You do not need to estimate a model or anything like that, you just need to find the right geom. References "],
["statistical-models.html", "Chapter 7 Statistical models 7.1 Fitting a model to data 7.2 Diagnostics 7.3 Interpreting models 7.4 Comparing models 7.5 Using a model for prediction 7.6 Beyond linear regression", " Chapter 7 Statistical models In this chapter, we will not learn about all the models out there that you may or may not need. Instead, I will show you how can use what you have learned until now and how you can apply these concepts to modeling. Also, as you read in the beginning of the book, R has many many packages. So the model you need is most probably already implemented in some package. 7.1 Fitting a model to data Suppose you have a variable y that you wish to explain using a set of other variables x1, x2, x3, etc. Let’s take a look at the Housing dataset from the Ecdat package: library(Ecdat) data(Housing) You can read a description of the dataset by running: ?Housing Housing package:Ecdat R Documentation Sales Prices of Houses in the City of Windsor Description: a cross-section from 1987 _number of observations_ : 546 _observation_ : goods _country_ : Canada Usage: data(Housing) Format: A dataframe containing : price: sale price of a house lotsize: the lot size of a property in square feet bedrooms: number of bedrooms bathrms: number of full bathrooms stories: number of stories excluding basement driveway: does the house has a driveway ? recroom: does the house has a recreational room ? fullbase: does the house has a full finished basement ? gashw: does the house uses gas for hot water heating ? airco: does the house has central air conditioning ? garagepl: number of garage places prefarea: is the house located in the preferred neighbourhood of the city ? Source: Anglin, P.M. and R. Gencay (1996) “Semiparametric estimation of a hedonic price function”, _Journal of Applied Econometrics_, *11(6)*, 633-648. References: Verbeek, Marno (2004) _A Guide to Modern Econometrics_, John Wiley and Sons, chapter 3. Journal of Applied Econometrics data archive : &lt;URL: http://qed.econ.queensu.ca/jae/&gt;. See Also: ‘Index.Source’, ‘Index.Economics’, ‘Index.Econometrics’, ‘Index.Observations’ or by looking for Housing in the help pane of RStudio. Usually, you would take a look a the data before doing any modeling: glimpse(Housing) ## Observations: 546 ## Variables: 12 ## $ price &lt;dbl&gt; 42000, 38500, 49500, 60500, 61000, 66000, 66000, 6900... ## $ lotsize &lt;dbl&gt; 5850, 4000, 3060, 6650, 6360, 4160, 3880, 4160, 4800,... ## $ bedrooms &lt;dbl&gt; 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 4,... ## $ bathrms &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,... ## $ stories &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, 3,... ## $ driveway &lt;fct&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, yes... ## $ recroom &lt;fct&gt; no, no, no, yes, no, yes, no, no, yes, yes, no, no, n... ## $ fullbase &lt;fct&gt; yes, no, no, no, no, yes, yes, no, yes, no, yes, no, ... ## $ gashw &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, n... ## $ airco &lt;fct&gt; no, no, no, no, no, yes, no, no, no, yes, yes, no, no... ## $ garagepl &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, 0,... ## $ prefarea &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, n... Housing prices depend on a set of variables such as the number of bedrooms, the area it is located and so on. If you believe that housing prices depend linearly on a set of explanatory variables, you will want to estimate a linear model. To estimate a linear model, you will need to use the built-in lm() function: model1 = lm(price ~ lotsize + bedrooms, data = Housing) lm() takes a formula as an argument, which defines the model you want to estimate. In this case, I ran the following regression: \\[ \\text{price} = \\alpha + \\beta_1 * \\text{lotsize} + \\beta_2 * \\text{bedrooms} + \\varepsilon \\] where \\(alpha, beta_1\\) and \\(beta_2\\) are three parameters to estimate. To take a look at the results, you can use the summary() method (not to be confused with dplyr::summarise(): summary(model1) ## ## Call: ## lm(formula = price ~ lotsize + bedrooms, data = Housing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -65665 -12498 -2075 8970 97205 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.613e+03 4.103e+03 1.368 0.172 ## lotsize 6.053e+00 4.243e-01 14.265 &lt; 2e-16 *** ## bedrooms 1.057e+04 1.248e+03 8.470 2.31e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21230 on 543 degrees of freedom ## Multiple R-squared: 0.3703, Adjusted R-squared: 0.3679 ## F-statistic: 159.6 on 2 and 543 DF, p-value: &lt; 2.2e-16 if you wish to remove the intercept (\\(alpha\\)) from your model, you can do so with -1: model2 = lm(price ~ -1 + lotsize + bedrooms, data = Housing) summary(model2) ## ## Call: ## lm(formula = price ~ -1 + lotsize + bedrooms, data = Housing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -67229 -12342 -1333 9627 95509 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## lotsize 6.283 0.390 16.11 &lt;2e-16 *** ## bedrooms 11968.362 713.194 16.78 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21250 on 544 degrees of freedom ## Multiple R-squared: 0.916, Adjusted R-squared: 0.9157 ## F-statistic: 2965 on 2 and 544 DF, p-value: &lt; 2.2e-16 or if you want to use all the columns inside Housing: model3 = lm(price ~ ., data = Housing) summary(model3) ## ## Call: ## lm(formula = price ~ ., data = Housing) ## ## Residuals: ## Min 1Q Median 3Q Max ## -41389 -9307 -591 7353 74875 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4038.3504 3409.4713 -1.184 0.236762 ## lotsize 3.5463 0.3503 10.124 &lt; 2e-16 *** ## bedrooms 1832.0035 1047.0002 1.750 0.080733 . ## bathrms 14335.5585 1489.9209 9.622 &lt; 2e-16 *** ## stories 6556.9457 925.2899 7.086 4.37e-12 *** ## drivewayyes 6687.7789 2045.2458 3.270 0.001145 ** ## recroomyes 4511.2838 1899.9577 2.374 0.017929 * ## fullbaseyes 5452.3855 1588.0239 3.433 0.000642 *** ## gashwyes 12831.4063 3217.5971 3.988 7.60e-05 *** ## aircoyes 12632.8904 1555.0211 8.124 3.15e-15 *** ## garagepl 4244.8290 840.5442 5.050 6.07e-07 *** ## prefareayes 9369.5132 1669.0907 5.614 3.19e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15420 on 534 degrees of freedom ## Multiple R-squared: 0.6731, Adjusted R-squared: 0.6664 ## F-statistic: 99.97 on 11 and 534 DF, p-value: &lt; 2.2e-16 You can access different elements of model3 (for example) with $, because the result of lm() is a list: print(model3$coefficients) ## (Intercept) lotsize bedrooms bathrms stories ## -4038.350425 3.546303 1832.003466 14335.558468 6556.945711 ## drivewayyes recroomyes fullbaseyes gashwyes aircoyes ## 6687.778890 4511.283826 5452.385539 12831.406266 12632.890405 ## garagepl prefareayes ## 4244.829004 9369.513239 but I prefer to use the broom package, and more specifically the tidy() function, which converts model3 into a neat data.frame: results3 = tidy(model3) glimpse(results3) ## Observations: 12 ## Variables: 5 ## $ term &lt;chr&gt; &quot;(Intercept)&quot;, &quot;lotsize&quot;, &quot;bedrooms&quot;, &quot;bathrms&quot;, &quot;st... ## $ estimate &lt;dbl&gt; -4038.350425, 3.546303, 1832.003466, 14335.558468, 6... ## $ std.error &lt;dbl&gt; 3409.4713, 0.3503, 1047.0002, 1489.9209, 925.2899, 2... ## $ statistic &lt;dbl&gt; -1.184451, 10.123618, 1.749764, 9.621691, 7.086369, ... ## $ p.value &lt;dbl&gt; 2.367616e-01, 3.732442e-22, 8.073341e-02, 2.570369e-... this is useful, because you can then work on the results easily, for example if you wish to only keep results that are significant at the 5% level: results3 %&gt;% filter(p.value &lt; 0.05) ## # A tibble: 10 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 lotsize 3.55 0.350 10.1 3.73e-22 ## 2 bathrms 14336. 1490. 9.62 2.57e-20 ## 3 stories 6557. 925. 7.09 4.37e-12 ## 4 drivewayyes 6688. 2045. 3.27 1.15e- 3 ## 5 recroomyes 4511. 1900. 2.37 1.79e- 2 ## 6 fullbaseyes 5452. 1588. 3.43 6.42e- 4 ## 7 gashwyes 12831. 3218. 3.99 7.60e- 5 ## 8 aircoyes 12633. 1555. 8.12 3.15e-15 ## 9 garagepl 4245. 841. 5.05 6.07e- 7 ## 10 prefareayes 9370. 1669. 5.61 3.19e- 8 You can even add new columns, such as the confidence intervals: results3 = tidy(model3, conf.int = TRUE, conf.level = 0.95) print(results3) ## # A tibble: 12 x 7 ## term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -4038. 3409. -1.18 2.37e- 1 -10736. 2659. ## 2 lotsize 3.55 0.350 10.1 3.73e-22 2.86 4.23 ## 3 bedrooms 1832. 1047. 1.75 8.07e- 2 -225. 3889. ## 4 bathrms 14336. 1490. 9.62 2.57e-20 11409. 17262. ## 5 stories 6557. 925. 7.09 4.37e-12 4739. 8375. ## 6 drivewayyes 6688. 2045. 3.27 1.15e- 3 2670. 10705. ## 7 recroomyes 4511. 1900. 2.37 1.79e- 2 779. 8244. ## 8 fullbaseyes 5452. 1588. 3.43 6.42e- 4 2333. 8572. ## 9 gashwyes 12831. 3218. 3.99 7.60e- 5 6511. 19152. ## 10 aircoyes 12633. 1555. 8.12 3.15e-15 9578. 15688. ## 11 garagepl 4245. 841. 5.05 6.07e- 7 2594. 5896. ## 12 prefareayes 9370. 1669. 5.61 3.19e- 8 6091. 12648. Going back to model estimation, you can of course use lm() in a pipe workflow: Housing %&gt;% select(-driveway, -stories) %&gt;% lm(price ~ ., data = .) %&gt;% tidy() ## # A tibble: 10 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 3025. 3263. 0.927 3.54e- 1 ## 2 lotsize 3.67 0.363 10.1 4.52e-22 ## 3 bedrooms 4140. 1036. 3.99 7.38e- 5 ## 4 bathrms 16443. 1546. 10.6 4.29e-24 ## 5 recroomyes 5660. 2010. 2.82 5.05e- 3 ## 6 fullbaseyes 2241. 1618. 1.38 1.67e- 1 ## 7 gashwyes 13568. 3411. 3.98 7.93e- 5 ## 8 aircoyes 15578. 1597. 9.75 8.53e-21 ## 9 garagepl 4232. 883. 4.79 2.12e- 6 ## 10 prefareayes 10729. 1753. 6.12 1.81e- 9 The first . in the lm() function is used to indicate that we wish to use all the data from Housing (minus driveway and stories which I removed using select() and the - sign), and the second . is used to place the result from the two dplyr instructions that preceded is to be placed there. The picture below should help you understand: knitr::include_graphics(&quot;pics/pipe_to_second_position.png&quot;) You have to specify this, because by default, when using %&gt;% the left hand side argument gets passed as the first argument of the function on the right hand side. 7.2 Diagnostics Diagnostics are useful metrics to assess model fit. You can read some of these diagnostics, such as the \\(R^2\\) at the bottom of the summary (when running summary(my_model)), but if you want to do more than simply reading these diagnostics from RStudio, you can put those in a data.frame too, using broom::glance(): glance(model3) ## # A tibble: 1 x 11 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.673 0.666 15423. 100.0 6.18e-122 12 -6034. 12094. ## # ... with 3 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt; You can also plot the usual diagnostics plots using ggfortify::autoplot() which uses the ggplot2 package under the hood: library(ggfortify) autoplot(model3, which = 1:6) + theme_minimal() which=1:6 is an additional option that shows you all the diagnostics plot. If you omit this option, you will only get 4 of them. You can also get the residuals of the regression in two ways; either you grab them directly from the model fit: resi3 = residuals(model3) or you can augment the original data with a residuals column, using broom::augment(): housing_aug = augment(model3) Let’s take a look at housing_aug: glimpse(housing_aug) ## Observations: 546 ## Variables: 19 ## $ price &lt;dbl&gt; 42000, 38500, 49500, 60500, 61000, 66000, 66000, 69... ## $ lotsize &lt;dbl&gt; 5850, 4000, 3060, 6650, 6360, 4160, 3880, 4160, 480... ## $ bedrooms &lt;dbl&gt; 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, ... ## $ bathrms &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, ... ## $ stories &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 2, 1, 1, 1, 2, ... ## $ driveway &lt;fct&gt; yes, yes, yes, yes, yes, yes, yes, yes, yes, yes, y... ## $ recroom &lt;fct&gt; no, no, no, yes, no, yes, no, no, yes, yes, no, no,... ## $ fullbase &lt;fct&gt; yes, no, no, no, no, yes, yes, no, yes, no, yes, no... ## $ gashw &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no,... ## $ airco &lt;fct&gt; no, no, no, no, no, yes, no, no, no, yes, yes, no, ... ## $ garagepl &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1, ... ## $ prefarea &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no,... ## $ .fitted &lt;dbl&gt; 66037.98, 41391.15, 39889.63, 63689.09, 49760.43, 6... ## $ .se.fit &lt;dbl&gt; 1790.507, 1406.500, 1534.102, 2262.056, 1567.689, 2... ## $ .resid &lt;dbl&gt; -24037.9757, -2891.1515, 9610.3699, -3189.0873, 112... ## $ .hat &lt;dbl&gt; 0.013477335, 0.008316321, 0.009893730, 0.021510891,... ## $ .sigma &lt;dbl&gt; 15402.01, 15437.14, 15431.98, 15437.02, 15429.89, 1... ## $ .cooksd &lt;dbl&gt; 2.803214e-03, 2.476265e-05, 3.265481e-04, 8.004787e... ## $ .std.resid &lt;dbl&gt; -1.56917096, -0.18823924, 0.62621736, -0.20903274, ... A few columns have been added to the original data, among them .resid which contains the residuals. Let’s plot them: ggplot(housing_aug) + geom_density(aes(.resid)) Fitted values are also added to the original data, under the variable .fitted. It would also have been possible to get the fitted values with: fit3 = fitted(model3) but I prefer using augment(), because the columns get merged to the original data, which then makes it easier to find specific individuals, for example, you might want to know for which housing units the model underestimates the price: total_pos = housing_aug %&gt;% filter(.resid &gt; 0) %&gt;% summarise(total = n()) %&gt;% pull(total) we find 261 individuals where the residuals are positive. It is also easier to extract outliers: housing_aug %&gt;% mutate(prank = cume_dist(.cooksd)) %&gt;% filter(prank &gt; 0.99) %&gt;% glimpse() ## Observations: 6 ## Variables: 20 ## $ price &lt;dbl&gt; 163000, 125000, 132000, 175000, 190000, 174500 ## $ lotsize &lt;dbl&gt; 7420, 4320, 3500, 9960, 7420, 7500 ## $ bedrooms &lt;dbl&gt; 4, 3, 4, 3, 4, 4 ## $ bathrms &lt;dbl&gt; 1, 1, 2, 2, 2, 2 ## $ stories &lt;dbl&gt; 2, 2, 2, 2, 3, 2 ## $ driveway &lt;fct&gt; yes, yes, yes, yes, yes, yes ## $ recroom &lt;fct&gt; yes, no, no, no, no, no ## $ fullbase &lt;fct&gt; yes, yes, no, yes, no, yes ## $ gashw &lt;fct&gt; no, yes, yes, no, no, no ## $ airco &lt;fct&gt; yes, no, no, no, yes, yes ## $ garagepl &lt;dbl&gt; 2, 2, 2, 2, 2, 3 ## $ prefarea &lt;fct&gt; no, no, no, yes, yes, yes ## $ .fitted &lt;dbl&gt; 94826.68, 77688.37, 85495.58, 108563.18, 115125.03,... ## $ .se.fit &lt;dbl&gt; 2520.691, 3551.954, 3544.961, 2589.680, 2185.603, 2... ## $ .resid &lt;dbl&gt; 68173.32, 47311.63, 46504.42, 66436.82, 74874.97, 5... ## $ .hat &lt;dbl&gt; 0.02671105, 0.05303793, 0.05282929, 0.02819317, 0.0... ## $ .sigma &lt;dbl&gt; 15144.70, 15293.34, 15298.27, 15159.14, 15085.99, 1... ## $ .cooksd &lt;dbl&gt; 0.04590995, 0.04637969, 0.04461464, 0.04616068, 0.0... ## $ .std.resid &lt;dbl&gt; 4.480428, 3.152300, 3.098176, 4.369631, 4.904193, 3... ## $ prank &lt;dbl&gt; 0.9963370, 1.0000000, 0.9945055, 0.9981685, 0.99267... prank is a variable I created with cume_dist() which is a dplyr function that returns the proportion of all values less than or equal to the current rank. For example: example = c(5, 4.6, 2, 1, 0.8, 0, -1) cume_dist(example) ## [1] 1.0000000 0.8571429 0.7142857 0.5714286 0.4285714 0.2857143 0.1428571 by filtering prank &gt; 0.99 we get the top 1% of outliers according to Cook’s distance. 7.3 Interpreting models Model interpretation is essential in the social sciences. If one wants to know the effect of variable x on the dependent variable y, marginal effects have to be computed. This is easily done in R with the margins package, which aims to provide the same functionality as the margins command in STATA: library(margins) effects_model3 = margins(model3) summary(effects_model3) ## factor AME SE z p lower upper ## aircoyes 12632.8904 1555.0329 8.1239 0.0000 9585.0819 15680.6989 ## bathrms 14335.5585 1482.9885 9.6667 0.0000 11428.9545 17242.1624 ## bedrooms 1832.0035 1045.6558 1.7520 0.0798 -217.4442 3881.4512 ## drivewayyes 6687.7789 2045.2636 3.2699 0.0011 2679.1359 10696.4219 ## fullbaseyes 5452.3855 1587.9782 3.4335 0.0006 2340.0054 8564.7657 ## garagepl 4244.8290 847.2173 5.0103 0.0000 2584.3136 5905.3444 ## gashwyes 12831.4063 3217.6211 3.9879 0.0001 6524.9848 19137.8277 ## lotsize 3.5463 0.3503 10.1250 0.0000 2.8598 4.2328 ## prefareayes 9369.5132 1669.1034 5.6135 0.0000 6098.1307 12640.8957 ## recroomyes 4511.2838 1899.9255 2.3745 0.0176 787.4982 8235.0694 ## stories 6556.9457 924.4211 7.0930 0.0000 4745.1137 8368.7777 It is also possible to plot the results: plot(effects_model3) This uses the basic R plotting capabilities, which is useful because it is a simple call to the function plot() but if you’ve been using ggplot2 and want this graph to have the same feel as the others made with ggplot2 you first need to save the summary in a variable. summary(effects_model3) is a data.frame with many more details. Let’s overwrite this effects_model3 with its summary: effects_model3 = summary(effects_model3) And now it is possible to use ggplot2 to have the same plot: ggplot(data = effects_model3) + geom_point(aes(factor, AME)) + geom_errorbar(aes(x = factor, ymin = lower, ymax = upper)) + geom_hline(yintercept = 0) + theme_minimal() + theme(axis.text.x = element_text(angle = 45)) Of course for model3, the marginal effects are the same as the coefficients, so let’s estimate a logit model and compute the marginal effects. Logit models can be estimated using the glm() function. As an example, we are going to use the Participation data, also from the Ecdat package: data(Participation) ?Particpation Participation package:Ecdat R Documentation Labor Force Participation Description: a cross-section _number of observations_ : 872 _observation_ : individuals _country_ : Switzerland Usage: data(Participation) Format: A dataframe containing : lfp labour force participation ? lnnlinc the log of nonlabour income age age in years divided by 10 educ years of formal education nyc the number of young children (younger than 7) noc number of older children foreign foreigner ? Source: Gerfin, Michael (1996) “Parametric and semiparametric estimation of the binary response”, _Journal of Applied Econometrics_, *11(3)*, 321-340. References: Davidson, R. and James G. MacKinnon (2004) _Econometric Theory and Methods_, New York, Oxford University Press, &lt;URL: http://www.econ.queensu.ca/ETM/&gt;, chapter 11. Journal of Applied Econometrics data archive : &lt;URL: http://qed.econ.queensu.ca/jae/&gt;. See Also: ‘Index.Source’, ‘Index.Economics’, ‘Index.Econometrics’, ‘Index.Observations’ The variable of interest is lfp: whether the individual participates in the labour force. To know which variables are relevant in the decision to participate in the labour force, one could estimate a logit model, using glm(). logit_participation = glm(lfp ~ ., data = Participation, family = &quot;binomial&quot;) tidy(logit_participation) ## # A tibble: 7 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 10.4 2.17 4.79 1.69e- 6 ## 2 lnnlinc -0.815 0.206 -3.97 7.31e- 5 ## 3 age -0.510 0.0905 -5.64 1.72e- 8 ## 4 educ 0.0317 0.0290 1.09 2.75e- 1 ## 5 nyc -1.33 0.180 -7.39 1.51e-13 ## 6 noc -0.0220 0.0738 -0.298 7.66e- 1 ## 7 foreignyes 1.31 0.200 6.56 5.38e-11 From the results above, one can only interpret the sign of the coefficients. To know how much a variable influences the labour force participation, one has to use margins(): effects_logit_participation = margins(logit_participation) %&gt;% summary() print(effects_logit_participation) ## factor AME SE z p lower upper ## age -0.1064 0.0176 -6.0494 0.0000 -0.1409 -0.0719 ## educ 0.0066 0.0060 1.0955 0.2733 -0.0052 0.0185 ## foreignyes 0.2834 0.0399 7.1102 0.0000 0.2053 0.3615 ## lnnlinc -0.1699 0.0415 -4.0994 0.0000 -0.2512 -0.0887 ## noc -0.0046 0.0154 -0.2981 0.7656 -0.0347 0.0256 ## nyc -0.2775 0.0333 -8.3433 0.0000 -0.3426 -0.2123 We can use the previous code to plot the marginal effects: ggplot(data = effects_logit_participation) + geom_point(aes(factor, AME)) + geom_errorbar(aes(x = factor, ymin = lower, ymax = upper)) + geom_hline(yintercept = 0) + theme_minimal() + theme(axis.text.x = element_text(angle = 45)) So an infinitesimal increase, in say, non-labour income (lnnlinc) of 0.001 is associated with a decrease of the probability of labour force participation by 0.001*17 percentage points. You can also extract the marginal effects of a single variable: head(dydx(Participation, logit_participation, &quot;lnnlinc&quot;)) ## dydx_lnnlinc ## 1 -0.15667764 ## 2 -0.20014487 ## 3 -0.18495109 ## 4 -0.05377262 ## 5 -0.18710476 ## 6 -0.19586986 Which makes it possible to extract the effect for a list of individuals that you can create yourself: my_subjects = tribble( ~lfp, ~lnnlinc, ~age, ~educ, ~nyc, ~noc, ~foreign, &quot;yes&quot;, 10.780, 7.0, 4, 1, 1, &quot;yes&quot;, &quot;no&quot;, 1.30, 9.0, 1, 4, 1, &quot;yes&quot; ) dydx(my_subjects, logit_participation, &quot;lnnlinc&quot;) ## dydx_lnnlinc ## 1 -0.09228119 ## 2 -0.17953451 I used the tribble() function from the tibble package to create this test data set, row by row. Then, using dydx(), I get the marginal effect of variable lnnlinc for these two individuals. 7.4 Comparing models Let’s estimate another model on the same data; prices are only positive, so a linear regression might not be the best model, because the model allows for negative prices. Let’s look at the distribution of prices: ggplot(Housing) + geom_density(aes(price)) it looks like modeling the log of price might provide a better fit: model_log = lm(log(price) ~ ., data = Housing) result_log = tidy(model_log) print(result_log) ## # A tibble: 12 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 10.0 0.0472 212. 0. ## 2 lotsize 0.0000506 0.00000485 10.4 2.91e-23 ## 3 bedrooms 0.0340 0.0145 2.34 1.94e- 2 ## 4 bathrms 0.168 0.0206 8.13 3.10e-15 ## 5 stories 0.0923 0.0128 7.20 2.10e-12 ## 6 drivewayyes 0.131 0.0283 4.61 5.04e- 6 ## 7 recroomyes 0.0735 0.0263 2.79 5.42e- 3 ## 8 fullbaseyes 0.0994 0.0220 4.52 7.72e- 6 ## 9 gashwyes 0.178 0.0446 4.00 7.22e- 5 ## 10 aircoyes 0.178 0.0215 8.26 1.14e-15 ## 11 garagepl 0.0508 0.0116 4.36 1.58e- 5 ## 12 prefareayes 0.127 0.0231 5.50 6.02e- 8 Let’s take a look at the diagnostics: glance(model_log) ## # A tibble: 1 x 11 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.677 0.670 0.214 102. 3.67e-123 12 73.9 -122. ## # ... with 3 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt; Let’s compare these to the ones from the previous model: diag_lm = glance(model3) diag_lm = diag_lm %&gt;% mutate(model = &quot;lin-lin model&quot;) diag_log = glance(model_log) diag_log = diag_log %&gt;% mutate(model = &quot;log-lin model&quot;) diagnostics_models = full_join(diag_lm, diag_log) ## Joining, by = c(&quot;r.squared&quot;, &quot;adj.r.squared&quot;, &quot;sigma&quot;, &quot;statistic&quot;, &quot;p.value&quot;, &quot;df&quot;, &quot;logLik&quot;, &quot;AIC&quot;, &quot;BIC&quot;, &quot;deviance&quot;, &quot;df.residual&quot;, &quot;model&quot;) print(diagnostics_models) ## # A tibble: 2 x 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.673 0.666 1.54e+4 100.0 6.18e-122 12 -6034. 12094. ## 2 0.677 0.670 2.14e-1 102. 3.67e-123 12 73.9 -122. ## # ... with 4 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;, ## # model &lt;chr&gt; I saved the diagnostics in two different data.frame using the glance() function and added a model column to indicate which model the diagnostics come from. Then I merged both datasets using full_join(), a dplyr function. As you can see, the model with the logarithm of the prices as the explained variable has a higher likelihood (and thus lower AIC and BIC) than the simple linear model. Let’s take a look at the diagnostics plots: autoplot(model_log, which = 1:6) + theme_minimal() 7.5 Using a model for prediction Once you estimated a model, you might want to use it for prediction. This is easily done using the predict() function that works with most models. Prediction is also useful as a way to test the accuracy of your model: split your data into a training set (used for estimation) and a testing set (used for the pseudo-prediction) and see if your model overfits the data. We are going to see how to do that in a later section; for now, let’s just get acquainted with predict(). Let’s go back to the models we estimated in the previous section, model3 and model_log. Let’s also take a subsample of data, which we will be using for prediction: set.seed(1234) pred_set = Housing %&gt;% sample_n(20) so that we get always the same pred_set I set the random seed first. Let’s take a look at the data: print(pred_set) ## price lotsize bedrooms bathrms stories driveway recroom fullbase ## 63 52000 4280 2 1 1 yes no no ## 340 62500 3900 3 1 2 yes no no ## 332 175000 8960 4 4 4 yes no no ## 339 141000 8100 4 1 2 yes yes yes ## 467 54000 2856 3 1 3 yes no no ## 347 52000 4130 3 2 2 yes no no ## 6 66000 4160 3 1 1 yes yes yes ## 126 95000 4260 4 2 2 yes no no ## 359 97000 12090 4 2 2 yes no no ## 277 70000 6300 3 1 1 yes no no ## 372 85000 6420 3 1 1 yes no yes ## 292 39000 4000 3 1 2 yes no no ## 151 59900 3450 3 1 2 yes no no ## 493 53000 4050 2 1 1 yes no no ## 156 60000 2610 4 3 2 no no no ## 445 72500 5720 2 1 2 yes no no ## 152 35500 3000 3 1 2 no no no ## 142 40000 2650 3 1 2 yes no yes ## 99 35000 3500 2 1 1 yes yes no ## 123 37000 4400 2 1 1 yes no no ## gashw airco garagepl prefarea ## 63 no yes 2 no ## 340 no no 0 no ## 332 no yes 3 no ## 339 no yes 2 yes ## 467 no no 0 yes ## 347 no no 2 no ## 6 no yes 0 no ## 126 yes no 0 no ## 359 no no 2 yes ## 277 no yes 2 no ## 372 no yes 0 yes ## 292 no no 1 no ## 151 no no 1 no ## 493 no no 0 no ## 156 no no 0 no ## 445 no yes 0 yes ## 152 no no 0 no ## 142 no no 1 no ## 99 no no 0 no ## 123 no no 0 no If we wish to use it for prediction, this is easily done with predict(): predict(model3, pred_set) ## 63 340 332 339 467 347 6 ## 63506.66 49425.47 150689.71 106607.68 61649.59 73066.34 66387.12 ## 126 359 277 372 292 151 493 ## 79701.11 112496.42 72502.20 79260.00 54024.93 52074.46 41568.47 ## 156 445 152 142 99 123 ## 68666.08 76050.14 39546.02 54689.81 44129.28 42809.67 This returns a vector of predicted prices. This can then be used to compute the Root Mean Squared Error for instance. Let’s do it within a tidyverse pipeline: rmse = pred_set %&gt;% mutate(predictions = predict(model3, .)) %&gt;% summarise(sqrt(sum(predictions - price)**2/n())) The root mean square error of model3 is 1666.1312666. I also use the n() function which returns the number of observations in a group (or all the observations, if the data is not grouped). Let’s compare model3 ’s RMSE with the one from model_log: rmse2 = pred_set %&gt;% mutate(predictions = exp(predict(model_log, .))) %&gt;% summarise(sqrt(sum(predictions - price)**2/n())) Don’t forget to exponentiate the predictions, remember you’re dealing with a log-linear model! model_log’s RMSE is 1359.0392252 which is lower than model3’s. However, keep in mind that the model was estimated on the whole data, and then the prediction quality was assessed using a subsample of the data the model was estimated on… so actually we can’t really say if model_log’s predictions are very useful. Of course, this is the same for model3. In a later section we are going to learn how to do cross validation to avoid this issue. Also another problem of what I did before, unrelated to statistics per se, is that I wanted to compute the same quantity for two different models, and did so by copy and pasting 3 lines of code. That’s not much, but if I wanted to compare 10 models, copy and paste mistakes could have sneaked in. Instead, it would have been nice to have a function that computes the RMSE and then use it on my models. We are going to learn how to write our own function and use it just like if it was another built-in R function. 7.6 Beyond linear regression R has a lot of other built-in functions for regression, such as glm() (for Generalized Linear Models) and nls() for (for Nonlinear Least Squares). There are also functions and additional packages for time series, panel data, machine learning, bayesian and nonparametric methods. Presenting everything here would take too much space, and would be pretty useless as you can find whatever you need using an internet search engine. What you have learned until now is quite general and should work on many type of models. To help you out, here is a list of methods and the recommended packages that you can use: Model Package Quick example Robust Linear Regression MASS rlm(y ~ x, data = mydata) Nonlinear Least Squares stats2 nls(y ~ x1 / (1 + x2), data = mydata)3 Logit stats glm(y ~ x, data = mydata, family = &quot;binomial&quot;) Probit stats glm(y ~ x, data = mydata, family = binomial(link = &quot;probit&quot;)) K-Means stats kmeans(data, n)4 PCA stats prcomp(data, scale = TRUE, center = TRUE)5 Multinomial Logit mlogit Requires several steps of data pre-processing and formula definition, refer to the Vignette for more details. Cox PH survival coxph(Surv(y_time, y_status) ~ x, data = mydata)6 Time series Several, depending on your needs. Time series in R is a vast subject that would require a very thick book to cover. You can get started with the following series of blog articles, Tidy time-series, part 1, Tidy time-series, part 2, Tidy time-series, part 3 and Tidy time-series, part 3 Panel data plm plm(y ~ x, data = mydata, model = &quot;within|random&quot;) Neural Networks Several, depending on your needs. R is a very popular programming language for machine learning. This blog post lists and compares some of the most useful packages for Neural nets and deep learning. Nonparametric regression np Several functions and options available, refer to the Vignette for more details. I put neural networks in the table, but you can also find packages for regression trees, naive bayes, and pretty much any machine learning method out there! The same goes for Bayesian methods. Popular packages include rstan, rjags which link R to STAN and JAGS (two other pieces of software that do the Gibbs sampling for you) which are tools that allow you to fit very general models. It is also possible to estimate models using Bayesian inference without the need of external tools, with the bayesm package which estimates the usual micro-econometric models. There really are a lot of packages available for Bayesian inference, and you can find them all in the related CRAN Task View. This package gets installed with R, no need to add it↩ The formula in the example is shown for illustration purposes.↩ data must only contain numeric values, and n is the number of clusters.↩ data must only contain numeric values, or a formula can be provided.↩ Surv(y_time, y_status) creates a survival object, where y_time is the time to event y_status. It is possible to create more complex survival objects depending on exactly which data you are dealing with.↩ "],
["defining-your-own-functions.html", "Chapter 8 Defining your own functions 8.1 Control flow 8.2 Writing your own functions 8.3 Exercises 8.4 Functions that take functions as arguments 8.5 Functions that take columns of data as arguments 8.6 Functions that use loops 8.7 Anonymous functions 8.8 Exercises", " Chapter 8 Defining your own functions In this section we are going to learn some advanced concepts that are going to make you into a full-fledged R programmer. Before this chapter you only used whatever R came with, as well as the numerous R packages. This already allowed you to do a lot of things and solve a variety of problems! The next step is now to learn how to actually build your own functions. 8.1 Control flow 8.1.1 If-else Imagine you want a variable to be equal to a certain value if a condition is met. This is a typical problem that requires the if ... else ... construct. For instance: a = 4 b = 5 If a &gt; b then f should be equal to 20, else f should be equal to 10. Using if ... else ... you can achieve this like so: if (a &gt; b) { f = 20 } else { f = 10 } Obviously, here f = 10. Another way to achieve this is by using the ifelse() function: f = ifelse(a &gt; b, 20, 10) This is exactly equivalent as using the longer if ... else ... construct. Nested if ... else ... constructs can get messy: if (10 %% 3 == 0) { print(&quot;10 is divisible by 3&quot;) } else if (10 %% 2 == 0) { print(&quot;10 is divisible by 2&quot;) } ## [1] &quot;10 is divisible by 2&quot; 10 being obviously divisible by 2 and not 3, it is the second phrase that will be printed. The %% operator is the modulus operator, which gives the rest of the division of 10 by 2. Remember that if you are working on a dataset and wish to create a new column with values conditionally on the values of another column, you can use case_when(), which is much easier. 8.1.2 For loops For loops make it possible to repeat a set of instructions i times. For example, try the following: for (i in 1:10){ print(&quot;hello&quot;) } ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; It is also possible to do computations using for loops. Let’s compute the sum of the first 100 integers: result = 0 for (i in 1:100){ result = result + i } print(result) ## [1] 5050 result is equal to 5050, the expected result. What happened in that loop? First, we defined a variable called result and set it to 0. Then, when the loops starts, i equals 1, so we add result to 1, which is 1. Then, i equals 2, and again, we add result to i. But this time, result equals 1 and i equals 2, so now result equals 3, and we repeat this until i equals 100. 8.1.3 While loops While loops are very similar to for loops. The instructions inside a while loop are repeat while a certain condition holds true. Let’s consider the sum of the first 100 integers again: result = 0 i = 1 while (i&lt;=100){ result = result + i i = i + 1 } print(result) ## [1] 5050 Here, we first set result and i to 0. Then, while i is inferior, or equal to 100, we add i to result. Notice that there is one more line than in the for loop: we need to increment the value of i, if not, i would stay equal to 1, and the condition would always be fulfilled, and the loop would run forever (not really, only until your computer runs out of memory). In the next section we are going to learn how to write our own functions; this is when we are going to learn about recursive relationships that for and while loops can solve very well. 8.2 Writing your own functions As you have seen by now, R includes a very large amount of preprogrammed functions, but also much more functions are available in packages. However, you will always need to write your own. In this section we are going to learn how to write our own functions. 8.2.1 Declaring functions in R Suppose you want to create the following function: \\(f(x) = \\dfrac{1}{\\sqrt{x}}\\). This is the syntax you would use: my_function &lt;- function(x){ return(1/sqrt(x)) } While in general, it is a good idea to add comments to your functions to explain what they do, I would avoid adding comments to functions that do things that are very obvious, such as with this one. Function names should be of the form: function_name(). Always give your function very explicit names! In mathematics it is standard to give functions just one letter as a name, but I would advise against doing that in your code. Functions that you write are not special in any way; this means that R will treat them the same way, and they will work in conjunction with any other function just as if it was built-in into R. They have one limitation though (which is shared with R’s native function): just like in math, they can only return one value. However, sometimes, you may need to return more than one value. To be able to do this, you must put your values in a list, and return the list of values. For example: average_and_sd &lt;- function(x){ result &lt;- c(mean(x), sd(x)) return(result) } average_and_sd(c(1, 3, 8, 9, 10, 12)) ## [1] 7.166667 4.262237 If you need to use a function from a package inside your function use ::: my_sum &lt;- function(a_vector){ purrr::reduce(a_vector, `+`) } However, if you need to use more than one function, this can become tedious. A quick and dirty way of doing that, is to use library(package_name), inside the function: my_sum &lt;- function(a_vector){ library(purrr) reduce(a_vector, `+`) } Loading the library inside the function has the advantage that you will be sure that the package upon which your function depends will be loaded. If the package is already loaded, it will not be loaded again, thus not impacting performance, but if you forgot to load it at the beginning of your script, then, no worries, your function will load it the first time you use it! However, the very best way would be to write your own package and declare the packages upon which your functions depend as dependencies. This is something we are going to explore in Chapter 11. You can put a lot of instructions inside a function, such as loops. Let’s create the function that returns Fionacci numbers. 8.2.2 Fibonacci numbers The Fibonacci sequence is the following: \\[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, ...\\] Each subsequent number is composed of the sum of the two preceding ones. In R, it is possible to define a function that returns the \\(n^{th}\\) my_fibonacci number: my_fibo &lt;- function(n){ a &lt;- 0 b &lt;- 1 for (i in 1:n){ temp &lt;- b b &lt;- a a &lt;- a + temp } return(a) } Inside the loop, we defined a variable called temp. Defining temporary variables is usually very useful inside loops. Let’s try to understand what happens inside this loop: First, we assign the value 0 to variable a and value 1 to variable b. We start a loop, that goes from 1 to n. We assign the value inside of b to a temporary variable, called temp. b becomes a. We assign the sum of a and temp to a. When the loop is finished, we return a. What happens if we want the 3rd my_fibonacci number? At n = 1 we have first a = 0 and b = 1, then temp = 1, b = 0 and a = 0 + 1. Then n = 2. Now b = 0 and temp = 0. The previous result, a = 0 + 1 is now assigned to b, so b = 1. Then, a = 1 + 0. Finally, n = 3. temp = 1 (because b = 1), the previous result a = 1 is assigned to b and finally, a = 1 + 1. So the third my_fibonacci number equals 2. Reading this might be a bit confusing; I strongly advise you to run the algorithm on a sheet of paper, step by step. The above algorithm is called an iterative algorithm, because it uses a loop to compute the result. Let’s look at another way to think about the problem, with a so-called recursive function: fibo_recur &lt;- function(n){ if (n == 0 || n == 1){ return(n) } else { return(fibo_recur(n-1) + fibo_recur(n-2)) } } This algorithm should be easier to understand: if n = 0 or n = 1 the function should return n (0 or 1). If n is strictly bigger than 1, fibo_recur() should return the sum of fibo_recur(n-1) and fibo_recur(n-2). This version of the function is very much the same as the mathematical definition of the fibonacci sequence. So why not use only recursive algorithms then? Try to run the following: system.time(my_fibo(30)) ## user system elapsed ## 0.168 0.242 0.447 The result should be printed very fast (the system.time() function returns the time that it took to execute my_fibo(30)). Let’s try with the recursive version: system.time(fibo_recur(30)) ## user system elapsed ## 1.284 0.158 1.448 It takes much longer to execute! Recursive algorithms are very CPU demanding, so if speed is critical, it’s best to avoid recursive algorithms. Also, in fibo_recur() try to remove this line: if (n == 0 || n == 1) and try to run fibo_recur(5) for example and see what happens. You should get an error: this is because for recursive algorithms you need a stopping condition, or else, it would run forever. This is not the case for iterative algorithms, because the stopping condition is the last step of the loop. So as you can see, for recursive relationships, for or while loops are the way to go in R, whether you’re writing these loops inside functions or not. 8.3 Exercises Exercise 1 In this exercise, you will write a function to compute the sum of the n first integers. Combine the algorithm we saw in section about while loops and what you learned about functions in this section. Exercise 2 Write a function called my_fact() that computes the factorial of a number n. Do it using a loop, using a recursive function, and using a functional: Exercise 3 Write a function to find the roots of quadratic functions. Your function should take 3 arguments, a, b and c and return the two roots. Only consider the case where there are two real roots (delta &gt; 0). 8.4 Functions that take functions as arguments Functions that take functions as arguments are very powerful and useful tools. You already know a couple, purrr::map() and purrr::reduce(). But you can also write your own! A very simple example would be the following: my_func &lt;- function(x, func){ func(x) } my_func() is a very simple function that takes x and func() as arguments and that simply executes func(x). This might not seem very useful (after all, you could simply use func(x)!) but this is just for illustration purposes, in practice, your functions would be more useful than that! Let’s try to use my_func(): my_func(c(1, 8, 1, 0, 8), mean) ## [1] 3.6 As expected, this returns the mean of the given vector. But now suppose the following: my_func(c(1, 8, 1, NA, 8), mean) ## [1] NA Because one element of the list is NA, the whole mean is NA. mean() has a na.rm argument that you can set to TRUE to ignore the NAs in the vector. However, here, there is no way to provide this argument to the function mean()! Let’s see what happens when we try to: my_func(c(1, 8, 1, NA, 8), mean, na.rm = TRUE) Error in my_func(c(1, 8, 1, NA, 8), mean, na.rm = TRUE) : unused argument (na.rm = TRUE) So what you could do is pass the value TRUE to the na.rm argument of mean() from your own function: my_func &lt;- function(x, func, remove_na){ func(x, na.rm = remove_na) } my_func(c(1, 8, 1, NA, 8), mean, remove_na = TRUE) ## [1] 4.5 This is one solution, but mean() also has another argument called trim. What if some other user needs this argument? Should you also add it to your function? Surely there’s a way to avoid this problem? Yes, there is, and it’s the dots. The ... simply mean “any other argument as needed”, and it’s very easy to use: my_func &lt;- function(x, func, ...){ func(x, ...) } my_func(c(1, 8, 1, NA, 8), mean, na.rm = TRUE) ## [1] 4.5 or, now, if you need the trim argument: my_func(c(1, 8, 1, NA, 8), mean, na.rm = TRUE, trim = 0.1) ## [1] 4.5 The ... are very useful when writing wrappers such as my_func(). 8.5 Functions that take columns of data as arguments In many situations, you will want to write functions that look similar to this: my_function(my_data, one_column_inside_data) Such a function would be useful in situation where you have to apply a certain number of operations to columns for different data frames. For example if you need to create tables of descriptive statistics or graphs periodically, it might be very interesting to put these operations inside a function and then call the function whenever you need it, on the fresh batch of data. However, if you try to write something like that, something that might seem unexpected, at first, will happen: data(mtcars) simple_function &lt;- function(dataset, col_name){ dataset %&gt;% group_by(col_name) %&gt;% summarise(mean_speed = mean(speed)) -&gt; dataset return(dataset) } simple_function(cars, &quot;dist&quot;) Error: unknown variable to group by : col_name The variable col_name is passed to simple_function() as a string, but group_by() requires a variable name. So why not try to convert col_name to a name? simple_function &lt;- function(dataset, col_name){ col_name &lt;- as.name(col_name) dataset %&gt;% group_by(col_name) %&gt;% summarise(mean_speed = mean(speed)) -&gt; dataset return(dataset) } simple_function(cars, &quot;dist&quot;) Error: unknown variable to group by : col_name This is because R is literally looking for the variable &quot;dist&quot; somewhere in the global environment, and not as a column of the data. R does not understand that you are refering to the column &quot;dist&quot; that is inside the dataset. So how can we make R understand what you mean? To be able to do that, we need to use a framework that was introduced recently in the tidyverse, called tidyeval. This discussion can get very technical, so I will spare you the details. However, you can read about it here and here. The discussion can get complicated, but using tidyeval is actually quite easy, and you can get a cookbook approach to it. Take a look at the code below: simple_function &lt;- function(dataset, col_name){ col_name &lt;- enquo(col_name) dataset %&gt;% group_by(!!col_name) %&gt;% summarise(mean_mpg = mean(mpg)) -&gt; dataset return(dataset) } simple_function(mtcars, cyl) ## # A tibble: 3 x 2 ## cyl mean_mpg ## &lt;int&gt; &lt;dbl&gt; ## 1 4 26.7 ## 2 6 19.7 ## 3 8 15.1 As you can see, the previous idea we had, which was using as.name() was not very far away from the solution. The solution, with tidyeval, consists in using enquo(), which for our purposes, let’s say that this function does something similar to as.name() (in truth, it doesn’t). Now that col_name is (R programmers call it) quoted, we need to tell group_by() to evaluate the input as is. This is done with !!(), which is another tidyeval function. I say it again; don’t worry if you don’t understand everything. Just remember to use enquo() on your column names and then !!() inside the dplyr function you want to use. Let’s see some other examples: simple_function &lt;- function(dataset, col_name, value){ col_name &lt;- enquo(col_name) dataset %&gt;% filter((!!col_name) == value) %&gt;% summarise(mean_cyl = mean(cyl)) -&gt; dataset return(dataset) } simple_function(mtcars, am, 1) ## mean_cyl ## 1 5.076923 Notice that I’ve written: filter((!!col_name) == value) and not: filter(!!col_name == value) I have enclosed !!col_name inside parentheses. This is because operators such as == have precedence over !!, so you have to be explicit. Also, notice that I didn’t have to quote 1. This is because it’s standard variable, not a column inside the dataset. Let’s make this function a bit more general. I hard-coded the variable cyl inside the body of the function, but maybe you’d like the mean of another variable? simple_function &lt;- function(dataset, filter_col, mean_col, value){ filter_col &lt;- enquo(filter_col) mean_col &lt;- enquo(mean_col) dataset %&gt;% filter((!!filter_col) == value) %&gt;% summarise(mean((!!mean_col))) -&gt; dataset return(dataset) } simple_function(mtcars, am, cyl, 1) ## mean(cyl) ## 1 5.076923 Notice that I had to quote mean_col too. Using the ... that we discovered in the previous section, we can pass more than one column: simple_function &lt;- function(dataset, ...){ col_vars &lt;- quos(...) dataset %&gt;% summarise_at(vars(!!!col_vars), funs(mean, sd)) } Because these dots contain more than one variable, you have to use quos() instead of enquo(). This will put the arguments provided via the dots in a list. Then, because we have a list of columns, we have to use summarise_at(), which you should know if you did the exercices of chapter 5. So if you didn’t do them, go back to them and finish them first. Doing the exercise will also teach you what vars() and funs() are. The last thing you have to pay attention to is to use !!!() if you used quos(). So 3 ! instead of only 2. This allows you to then do things like this: simple_function(mtcars, am, cyl, mpg) ## am_mean cyl_mean mpg_mean am_sd cyl_sd mpg_sd ## 1 0.40625 6.1875 20.09062 0.4989909 1.785922 6.026948 Using ... with !!!() allows you to write very flexible functions. If you need to be even more general, you can also provide the summary functions as arguments of your function, but you have to rewrite your function a little bit: simple_function &lt;- function(dataset, cols, funcs){ dataset %&gt;% summarise_at(vars(!!!cols), funs(!!!funcs)) } You might be wondering where the quos() went? Well because now we are passing two lists of, a list columns that we have to quote, and a list of functions, that we have to quote, we need to use quos() when calling the function: simple_function(mtcars, quos(am, cyl, mpg), quos(mean, sd, sum)) ## am_mean cyl_mean mpg_mean am_sd cyl_sd mpg_sd am_sum cyl_sum ## 1 0.40625 6.1875 20.09062 0.4989909 1.785922 6.026948 13 198 ## mpg_sum ## 1 642.9 This works, but I don’t think you’ll need to have that much flexibility; either the columns are variable, or the functions, but rarely both at the same time. 8.6 Functions that use loops It is entirely possible to put a loop inside a function. For example, consider the following function that return the square root of a number using Newton’s algorithm: sqrt_newton &lt;- function(a, init = 1, eps = 0.01){ stopifnot(a &gt;= 0) while(abs(init**2 - a) &gt; eps){ init &lt;- 1/2 *(init + a/init) } return(init) } This functions contains a while loop inside its body. Let’s see if it works: sqrt_newton(16) ## [1] 4.000001 In the definition of the function, I wrote init = 1 and eps = 0.01 which means that this argument can be omitted and will have the provided value (0.01) as the default. You can then use this function as any other, for example with map(): map(c(16, 7, 8, 9, 12), sqrt_newton) ## [[1]] ## [1] 4.000001 ## ## [[2]] ## [1] 2.645767 ## ## [[3]] ## [1] 2.828469 ## ## [[4]] ## [1] 3.000092 ## ## [[5]] ## [1] 3.464616 This is what I meant before with “your functions are nothing special”. Once the function is defined, you can use it like any other base R function. Notice the use of stopifnot() inside the body of the function. This is a way to return an error in case a condition is not fulfilled. 8.7 Anonymous functions As the name implies, anonymous functions are functions that do not have a name. These are useful inside functions that have functions as arguments, such as purrr::map() or purrr::reduce(): map(c(1,2,3,4), function(x){1/sqrt(x)}) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 0.7071068 ## ## [[3]] ## [1] 0.5773503 ## ## [[4]] ## [1] 0.5 These anonymous functions get defined in a very similar way to regular functions, you just skip the name and that’s it. tidyverse functions also support formulas; these get converted to anonymous functions: map(c(1,2,3,4), ~{1/sqrt(.)}) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 0.7071068 ## ## [[3]] ## [1] 0.5773503 ## ## [[4]] ## [1] 0.5 Using a formula instead of an anonymous function is less verbose; you use ~ instead of function(x) and a single dot . instead of x. What if you need an anonymous function that requires more than one argument? This is not a problem: map2(c(1, 2, 3, 4, 5), c(9, 8, 7, 6, 5), function(x, y){(x**2)/y}) ## [[1]] ## [1] 0.1111111 ## ## [[2]] ## [1] 0.5 ## ## [[3]] ## [1] 1.285714 ## ## [[4]] ## [1] 2.666667 ## ## [[5]] ## [1] 5 or, using a formula: map2(c(1, 2, 3, 4, 5), c(9, 8, 7, 6, 5), ~{(.x**2)/.y}) ## [[1]] ## [1] 0.1111111 ## ## [[2]] ## [1] 0.5 ## ## [[3]] ## [1] 1.285714 ## ## [[4]] ## [1] 2.666667 ## ## [[5]] ## [1] 5 Because you have now two arguments, a single dot could not work, so instead you use .x and .y to avoid confusion. 8.8 Exercises Exercise 1 Create the following vector: \\[a = (1,6,7,8,8,9,2)\\] Using a for loop and a while loop, compute the sum of its elements. To avoid issues, use i as the counter inside the for loop, and j as the counter for the while loop. How would you achieve that with a functional (a function that takes a function as an argument)? Exercise 2 Let’s use a loop to get the matrix product of a matrix A and B. Follow these steps to create the loop: Create matrix A: \\[A = \\left( \\begin{array}{ccc} 9 &amp; 4 &amp; 12 \\\\ 5 &amp; 0 &amp; 7 \\\\ 2 &amp; 6 &amp; 8 \\\\ 9 &amp; 2 &amp; 9 \\end{array} \\right) \\] Create matrix B: \\[B = \\left( \\begin{array}{cccc} 5 &amp; 4 &amp; 2 &amp; 5 \\\\ 2 &amp; 7 &amp; 2 &amp; 1 \\\\ 8 &amp; 3 &amp; 2 &amp; 6 \\\\ \\end{array} \\right) \\] Create a matrix C, with dimension 4x4 that will hold the result. Use this command: `C = matrix(rep(0,16), nrow = 4)} Using a for loop, loop over the rows of A first: `for(i in 1:nrow(A))} Inside this loop, loop over the columns of B: `for(j in 1:ncol(B))} Again, inside this loop, loop over the rows of B: `for(k in 1:nrow(B))} Inside this last loop, compute the result and save it inside C: `C[i,j] = C[i,j] + A[i,k] * B[k,j]} R has a built-in function to compute the dot product of 2 matrices. Which is it? Exercise 3 Fizz Buzz: Print integers from 1 to 100. If a number is divisible by 3, print the word Fizz if it’s divisible by 5, print Buzz. Use a for loop and if statements. Exercise 4 Fizz Buzz 2: Same as above, but now add this third condition: if a number is both divisible by 3 and 5, print &quot;FizzBuzz&quot;. for (i in 1:100){ if (i %% 15 == 0) { print(&quot;FizzBuzz&quot;) } else if (i %% 3 == 0) { print(&quot;Fizz&quot;) } else if (i %% 5 == 0) { print(&quot;Buzz&quot;) } else { print(i) } } ## [1] 1 ## [1] 2 ## [1] &quot;Fizz&quot; ## [1] 4 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 7 ## [1] 8 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; ## [1] 11 ## [1] &quot;Fizz&quot; ## [1] 13 ## [1] 14 ## [1] &quot;FizzBuzz&quot; ## [1] 16 ## [1] 17 ## [1] &quot;Fizz&quot; ## [1] 19 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 22 ## [1] 23 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; ## [1] 26 ## [1] &quot;Fizz&quot; ## [1] 28 ## [1] 29 ## [1] &quot;FizzBuzz&quot; ## [1] 31 ## [1] 32 ## [1] &quot;Fizz&quot; ## [1] 34 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 37 ## [1] 38 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; ## [1] 41 ## [1] &quot;Fizz&quot; ## [1] 43 ## [1] 44 ## [1] &quot;FizzBuzz&quot; ## [1] 46 ## [1] 47 ## [1] &quot;Fizz&quot; ## [1] 49 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 52 ## [1] 53 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; ## [1] 56 ## [1] &quot;Fizz&quot; ## [1] 58 ## [1] 59 ## [1] &quot;FizzBuzz&quot; ## [1] 61 ## [1] 62 ## [1] &quot;Fizz&quot; ## [1] 64 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 67 ## [1] 68 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; ## [1] 71 ## [1] &quot;Fizz&quot; ## [1] 73 ## [1] 74 ## [1] &quot;FizzBuzz&quot; ## [1] 76 ## [1] 77 ## [1] &quot;Fizz&quot; ## [1] 79 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 82 ## [1] 83 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; ## [1] 86 ## [1] &quot;Fizz&quot; ## [1] 88 ## [1] 89 ## [1] &quot;FizzBuzz&quot; ## [1] 91 ## [1] 92 ## [1] &quot;Fizz&quot; ## [1] 94 ## [1] &quot;Buzz&quot; ## [1] &quot;Fizz&quot; ## [1] 97 ## [1] 98 ## [1] &quot;Fizz&quot; ## [1] &quot;Buzz&quot; "],
["functional-programming.html", "Chapter 9 Functional programming 9.1 Functions definition 9.2 Properties of functions 9.3 Functional programming with {purrr} 9.4 Using your functions inside mutate() 9.5 Working with a list of datasets 9.6 Mapping your homebrewed functions to lists of datasets 9.7 Functional programming and plotting 9.8 Functional programming and modeling 9.9 Exercises", " Chapter 9 Functional programming By now, you are pretty familiar with functions in R. Now, let’s introduce the functional programming paradigm, but first, let’s go over some formal definitions. 9.1 Functions definition You should be familiar with function definitions in R. For example, suppose you want to compute the square root of a number and want to do so using Newton’s algorithm: sqrt_newton &lt;- function(a, init, eps = 0.01){ while(abs(init**2 - a) &gt; eps){ init &lt;- 1/2 *(init + a/init) } return(init) } You can then use this function to get the square root of a number: sqrt_newton(16, 2) ## [1] 4.00122 We are using a while loop inside the body. The body of a function are the instructions that define the function. You can get the body of a function with body(some_func) of the function. In pure functional programming languages, like Haskell, you don’t have loops. How can you program without loops, you may ask? In functional programming, loops are replaced by recursion, which we already discussed in the previous chapter. Let’s rewrite our little example above with recursion: sqrt_newton_recur &lt;- function(a, init, eps = 0.01){ if(abs(init**2 - a) &lt; eps){ result &lt;- init } else { init &lt;- 1/2 * (init + a/init) result &lt;- sqrt_newton_recur(a, init, eps) } return(result) } sqrt_newton_recur(16, 2) ## [1] 4.00122 R is not a pure functional programming language though, so we can still use loops (be it while or for loops) in the bodies of our functions. As discussed in the previous chapter, it is actually better, performance-wise, to use loops instead of recursion, because R is not tail-call optimized. I won’t got into the details of what tail-call optimization is but just remember that if performance is important a loop will be faster. However, sometimes, it is easier to write a function using recursion. I personally tend to avoid loops if performance is not important, because I find that code that avoids loops is easier to read and debug. However, knowing that you can use loops is reassuring. In the coming sections I will show you some built-in functions that make it possible to avoid writing loops and that don’t rely on recursion, so performance won’t be penalized. 9.2 Properties of functions Mathematical functions have a nice property: we always get the same output for a given input. This is called referential transparency and we should aim to write our R functions in such a way. For example, the following function: increment &lt;- function(x){ return(x + 1) } Is a referential transparent function. We always get the same result for any x that we give to this function. This: increment(10) ## [1] 11 will always produce 11. However, this one: increment_opaque &lt;- function(x){ return(x + spam) } is not a referential transparent function, because its value depends on the global variable spam. spam &lt;- 1 increment_opaque(10) ## [1] 11 will only produce 11 if spam = 1. But what if spam = 19? spam &lt;- 19 increment_opaque(10) ## [1] 29 To make increment_opaque() a referential transparent function, it is enough to make spam an argument: increment_not_opaque &lt;- function(x, spam){ return(x + spam) } Now even if there is a global variable called spam, this will not influence our function: spam &lt;- 19 increment_not_opaque(10, 34) ## [1] 44 This is because the variable spam defined in the body of the function is a local variable. It could have been called anything else, really. Avoiding opaque functions makes our life easier. Another property that adepts of functional programming value is that functions should have no, or very limited, side-effects. This means that functions should not change the state of your program. For example this function (which is not a referential transparent function): count_iter &lt;- 0 sqrt_newton_side_effect &lt;- function(a, init, eps = 0.01){ while(abs(init**2 - a) &gt; eps){ init &lt;- 1/2 *(init + a/init) count_iter &lt;&lt;- count_iter + 1 # The &quot;&lt;&lt;-&quot; symbol means that we assign the } # RHS value in a variable in the global environment return(init) } If you look in the environment pane, you will see that count_iter equals 0. Now call this function with the following arguments: sqrt_newton_side_effect(16000, 2) ## [1] 126.4911 print(count_iter) ## [1] 9 If you check the value of count_iter now, you will see that it increased! This is a side effect, because the function changed something outside of its scope. It changed a value in the global environment. In general, it is good practice to avoid side-effects. For example, we could make the above function not have any side effects like this: sqrt_newton_count &lt;- function(a, init, count_iter = 0, eps = 0.01){ while(abs(init**2 - a) &gt; eps){ init &lt;- 1/2 *(init + a/init) count_iter &lt;- count_iter + 1 } return(c(init, count_iter)) } Now, this function returns a list with two elements, the result, and the number of iterations it took to get the result: sqrt_newton_count(16000, 2) ## [1] 126.4911 9.0000 Writing to disk is also considered a side effect, because the function changes something (a file) outside its scope. But this cannot be avoided since you want to write to disk. Just remember: try to avoid having functions changing variables in the global environment unless you have a very good reason of doing so. Finally, another property of mathematical functions, is that they do one single thing. Functional programming purists also program their functions to do one single task. This has benefits, but can complicate things. The function we wrote previously does two things: it computes the square root of a number and also returns the number of iterations it took to compute the result. However, this is not a bad thing; the function is doing two tasks, but these tasks are related to each other and it makes sense to have them together. My piece of advice: avoid having functions that do many unrelated things. This makes debugging harder. In conclusion: you should strive for referential transparency, try to avoid side effects unless you have a good reason to have them and try to keep your functions short and do as little tasks as possible. This makes testing and debugging easier, as you will see. 9.3 Functional programming with {purrr} Hadley Wickham developed a package called purrr which contains a lot of very useful functions. 9.3.1 The map*() family of functions In the previous section we saw how to map a function to each element of a list. Each version of an *apply() function has a different purpose, but it is not very easy to remember which one returns a list, which other one returns an atomic vector and so on. If you’re working on data frames you can use apply() to sum (for example) over columns or rows, because you can specify which MARGIN you want to sum over. But you do not get a data frame back. In the purrr package, each of the functions that do mapping have a similar name. The first part of these functions’ names all start with map_ and the second part tells you what this function is going to output. For example, if you want doubles out, you would use map_dbl(). If you are working on data frames want a data frame back, you would use map_df(). These are much more intuitive and easier to remember and we’re going to learn how to use them in the chapter about The Tidyverse. For now, let’s just focus on the basic functions, map() and reduce() (and some variants of reduce()). To map a function to every element of a list, simply use map(): library(&quot;purrr&quot;) numbers &lt;- c(7, 8, 19, 64) map(numbers, sqrt_newton, init = 1) ## [[1]] ## [1] 2.645767 ## ## [[2]] ## [1] 2.828469 ## ## [[3]] ## [1] 4.358902 ## ## [[4]] ## [1] 8.000002 If you want print “hello” using a function from purrr you would need to use rerun(): rerun(10, &quot;hello&quot;) ## [[1]] ## [1] &quot;hello&quot; ## ## [[2]] ## [1] &quot;hello&quot; ## ## [[3]] ## [1] &quot;hello&quot; ## ## [[4]] ## [1] &quot;hello&quot; ## ## [[5]] ## [1] &quot;hello&quot; ## ## [[6]] ## [1] &quot;hello&quot; ## ## [[7]] ## [1] &quot;hello&quot; ## ## [[8]] ## [1] &quot;hello&quot; ## ## [[9]] ## [1] &quot;hello&quot; ## ## [[10]] ## [1] &quot;hello&quot; rerun() simply runs an expression (which can be arbitrarily complex) n times, whereas map() maps a function to a list of inputs, so to achieve the same with map(), you need to map the print() function to a vector of characters: map(rep(&quot;hello&quot;, 10), print) ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [1] &quot;hello&quot; ## [[1]] ## [1] &quot;hello&quot; ## ## [[2]] ## [1] &quot;hello&quot; ## ## [[3]] ## [1] &quot;hello&quot; ## ## [[4]] ## [1] &quot;hello&quot; ## ## [[5]] ## [1] &quot;hello&quot; ## ## [[6]] ## [1] &quot;hello&quot; ## ## [[7]] ## [1] &quot;hello&quot; ## ## [[8]] ## [1] &quot;hello&quot; ## ## [[9]] ## [1] &quot;hello&quot; ## ## [[10]] ## [1] &quot;hello&quot; rep() is a function that creates a vector by repeating something, in this case the string “hello”, as many times as needed, here 10. The output here is a bit different that before though, because first you will see “hello” printed 10 times, but map() always returns a list, this means that you will also get a list where each element is the string “hello”. We know the standard map() function, which returns a list, but there are a number of variants of this function. map_dbl() returns an atomic vector of doubles: map_dbl(numbers, sqrt_newton, init = 1) ## [1] 2.645767 2.828469 4.358902 8.000002 map_chr() returns an atomic vector of strings: map_chr(numbers, sqrt_newton, init = 1) ## [1] &quot;2.645767&quot; &quot;2.828469&quot; &quot;4.358902&quot; &quot;8.000002&quot; map_lgl() returns an atomic vector of TRUE or FALSE: divisible &lt;- function(x, y){ if_else(x %% y == 0, TRUE, FALSE) } map_lgl(seq(1:100), divisible, 3) ## [1] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE ## [12] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE ## [23] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE ## [34] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE ## [45] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE ## [56] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE ## [67] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE ## [78] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE ## [89] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE ## [100] FALSE There are also other interesting variants, such as map_if(): a &lt;- seq(1,10) map_if(a, (function(x) divisible(x, 2)), sqrt) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 1.414214 ## ## [[3]] ## [1] 3 ## ## [[4]] ## [1] 2 ## ## [[5]] ## [1] 5 ## ## [[6]] ## [1] 2.44949 ## ## [[7]] ## [1] 7 ## ## [[8]] ## [1] 2.828427 ## ## [[9]] ## [1] 9 ## ## [[10]] ## [1] 3.162278 I used map_if() to take the square root of only those numbers in vector a that are divisble by 2, by using an anonymous function that checks if a number is divisible by 2 (by wrapping divisible()). map_at() is similar to map_if() but maps the function at a position specified by the user: map_at(numbers, c(1, 3), sqrt) ## [[1]] ## [1] 2.645751 ## ## [[2]] ## [1] 8 ## ## [[3]] ## [1] 4.358899 ## ## [[4]] ## [1] 64 or if you have a named list: recipe &lt;- list(&quot;spam&quot; = 1, &quot;eggs&quot; = 3, &quot;bacon&quot; = 10) map_at(recipe, &quot;bacon&quot;, `*`, 2) ## $spam ## [1] 1 ## ## $eggs ## [1] 3 ## ## $bacon ## [1] 20 I used map_at() to double the quantity of bacon in the recipe (by using the * function, and specifying its second argument, 2. Try the following in the command prompt: `*`(3, 4)). map2() is the equivalent of mapply() and pmap() is the generalisation of map2() for more than 2 arguments: print(a) ## [1] 1 2 3 4 5 6 7 8 9 10 b &lt;- seq(1, 2, length.out = 10) print(b) ## [1] 1.000000 1.111111 1.222222 1.333333 1.444444 1.555556 1.666667 ## [8] 1.777778 1.888889 2.000000 map2(a, b, `*`) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2.222222 ## ## [[3]] ## [1] 3.666667 ## ## [[4]] ## [1] 5.333333 ## ## [[5]] ## [1] 7.222222 ## ## [[6]] ## [1] 9.333333 ## ## [[7]] ## [1] 11.66667 ## ## [[8]] ## [1] 14.22222 ## ## [[9]] ## [1] 17 ## ## [[10]] ## [1] 20 n &lt;- seq(1:10) pmap(list(a, b, n), rnorm) ## [[1]] ## [1] 0.5228073 ## ## [[2]] ## [1] -0.8856618 -0.4413967 ## ## [[3]] ## [1] 1.4155987 4.1007044 0.8913657 ## ## [[4]] ## [1] -0.7107047 -2.3114483 -2.0153534 10.9966740 ## ## [[5]] ## [1] 2.1148855 -1.0089850 -0.7582949 3.7423916 -2.0241568 ## ## [[6]] ## [1] -7.133674 5.004090 -4.586379 1.464726 -4.060136 8.169341 ## ## [[7]] ## [1] -1.662485 -3.299414 -1.842140 -9.736988 -6.506668 -13.593611 ## [7] -7.720286 ## ## [[8]] ## [1] -0.5765731 -1.9494025 13.3737479 -6.7713640 -5.0651393 -0.4672062 ## [7] -6.1769428 -5.9703368 ## ## [[9]] ## [1] -8.0769748 -9.3789841 -2.8255642 -2.5827607 -14.3653924 -3.3497944 ## [7] -8.0911177 -7.2457692 0.4281032 ## ## [[10]] ## [1] 7.630558 18.478175 -5.733534 18.059096 -9.578085 8.565885 27.489911 ## [8] 1.652396 -4.696336 1.923952 9.3.2 Reducing with purrr In the purrr package, you can find two more functions for folding: reduce() and reduce_right(). The difference between reduce() and reduce_right() is pretty obvious: reduce_right() starts from the right! a &lt;- seq(1, 10) reduce(a, `-`) ## [1] -53 reduce_right(a, `-`) ## [1] -35 For operations that are not commutative, this makes a difference. Other interesting folding functions are accumulate() and accumulate_right(): a &lt;- seq(1, 10) accumulate(a, `-`) ## [1] 1 -1 -4 -8 -13 -19 -26 -34 -43 -53 accumulate_right(a, `-`) ## [1] -35 -34 -32 -29 -25 -20 -14 -7 1 10 These two functions keep the intermediary results. In the previous chapter, we wrote a loop to compute the sum of the 100 first integers. We can do the same with purrr::reduce(): result = reduce(seq(1,100), `+`) print(result) ## [1] 5050 You certainly agree with me that is simpler to understand. You can even see what happens in more detail using accumulate: accumulate(seq(1, 100), `+`) ## [1] 1 3 6 10 15 21 28 36 45 55 66 78 91 105 ## [15] 120 136 153 171 190 210 231 253 276 300 325 351 378 406 ## [29] 435 465 496 528 561 595 630 666 703 741 780 820 861 903 ## [43] 946 990 1035 1081 1128 1176 1225 1275 1326 1378 1431 1485 1540 1596 ## [57] 1653 1711 1770 1830 1891 1953 2016 2080 2145 2211 2278 2346 2415 2485 ## [71] 2556 2628 2701 2775 2850 2926 3003 3081 3160 3240 3321 3403 3486 3570 ## [85] 3655 3741 3828 3916 4005 4095 4186 4278 4371 4465 4560 4656 4753 4851 ## [99] 4950 5050 9.3.3 safely() and possibly() safely() and possibly() are very useful functions. Consider the following situation: a &lt;- list(&quot;a&quot;, 4, 5) sqrt(a) Error in sqrt(a) : non-numeric argument to mathematical function Using map() or Map() will result in a similar error. safely() is an higher-order function that takes one function as an argument and executes it… safely, meaning the execution of the function will not stop if there is an error. The error message gets captured alongside valid results. a &lt;- list(&quot;a&quot;, 4, 5) safe_sqrt &lt;- safely(sqrt) map(a, safe_sqrt) ## [[1]] ## [[1]]$result ## NULL ## ## [[1]]$error ## &lt;simpleError in sqrt(x = x): non-numeric argument to mathematical function&gt; ## ## ## [[2]] ## [[2]]$result ## [1] 2 ## ## [[2]]$error ## NULL ## ## ## [[3]] ## [[3]]$result ## [1] 2.236068 ## ## [[3]]$error ## NULL possibly() works similarly, but also allows you to specify a return value in case of an error: possible_sqrt &lt;- possibly(sqrt, otherwise = NA_real_) map(a, possible_sqrt) ## [[1]] ## [1] NA ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 2.236068 Of course, in this particular example, the same effect could be obtained way more easily: sqrt(as.numeric(a)) ## Warning: NAs introduced by coercion ## [1] NA 2.000000 2.236068 However, in some situations, this trick does not work as intended (or at all), so possibly() and safely() are the way to go. 9.3.4 is_*() and as_*() functions Remember in Chapter 3, when I introduced is.*() and as.*() functions? I told you then that we were going to learn about is_*() and as_*() in Chapter 9. This is it! 9.3.5 «Transposing lists» Another interesting function is transpose(). It is not an alternative to the function t() from base but, has a similar effect. transpose() works on lists. Let’s take a look at the example from before: safe_sqrt &lt;- safely(sqrt, otherwise = NA_real_) map(a, safe_sqrt) ## [[1]] ## [[1]]$result ## [1] NA ## ## [[1]]$error ## &lt;simpleError in sqrt(x = x): non-numeric argument to mathematical function&gt; ## ## ## [[2]] ## [[2]]$result ## [1] 2 ## ## [[2]]$error ## NULL ## ## ## [[3]] ## [[3]]$result ## [1] 2.236068 ## ## [[3]]$error ## NULL The output is a list with the first element being a list with a result and an error message. One might want to have all the results in a single list, and all the error messages in another list. This is possible with transpose(): purrr::transpose(map(a, safe_sqrt)) ## $result ## $result[[1]] ## [1] NA ## ## $result[[2]] ## [1] 2 ## ## $result[[3]] ## [1] 2.236068 ## ## ## $error ## $error[[1]] ## &lt;simpleError in sqrt(x = x): non-numeric argument to mathematical function&gt; ## ## $error[[2]] ## NULL ## ## $error[[3]] ## NULL I explicitely call purrr::transpose() because there is also a data.table::transpose(), which is not the same function. You have to be careful about that sort of thing, because it can cause errors in your programs and debuging this type of error is a nightmare. 9.4 Using your functions inside mutate() Once you wrote a function, you can easily use it inside a pipe workflow: double_number &lt;- function(x){ x+x } mtcars %&gt;% mutate(double_mpg = double_number(mpg)) ## mpg cyl disp hp drat wt qsec vs am gear carb double_mpg ## 1 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 42.0 ## 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 42.0 ## 3 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 45.6 ## 4 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 42.8 ## 5 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 37.4 ## 6 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 36.2 ## 7 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 28.6 ## 8 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 48.8 ## 9 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 45.6 ## 10 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 38.4 ## 11 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 35.6 ## 12 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 32.8 ## 13 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 34.6 ## 14 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 30.4 ## 15 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 20.8 ## 16 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 20.8 ## 17 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 29.4 ## 18 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 64.8 ## 19 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 60.8 ## 20 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 67.8 ## 21 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 43.0 ## 22 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 31.0 ## 23 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 30.4 ## 24 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 26.6 ## 25 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 38.4 ## 26 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 54.6 ## 27 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 52.0 ## 28 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 60.8 ## 29 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 31.6 ## 30 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 39.4 ## 31 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 30.0 ## 32 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 42.8 Granted this example is stupid, but it shows you, again, that functions you define are nothing special. You can use them just as any other. You can also avoid to define a function altogether, especially if you need an operation only once, by using the . like this: mtcars %&gt;% mutate(double_mpg = .$mpg + .$mpg) ## mpg cyl disp hp drat wt qsec vs am gear carb double_mpg ## 1 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 42.0 ## 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 42.0 ## 3 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 45.6 ## 4 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 42.8 ## 5 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 37.4 ## 6 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 36.2 ## 7 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 28.6 ## 8 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 48.8 ## 9 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 45.6 ## 10 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 38.4 ## 11 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 35.6 ## 12 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 32.8 ## 13 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 34.6 ## 14 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 30.4 ## 15 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 20.8 ## 16 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 20.8 ## 17 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 29.4 ## 18 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 64.8 ## 19 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 60.8 ## 20 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 67.8 ## 21 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 43.0 ## 22 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 31.0 ## 23 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 30.4 ## 24 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 26.6 ## 25 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 38.4 ## 26 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 54.6 ## 27 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 52.0 ## 28 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 60.8 ## 29 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 31.6 ## 30 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 39.4 ## 31 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 30.0 ## 32 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 42.8 9.5 Working with a list of datasets 9.5.1 Using map() to work on lists of datasets This is our first encouter with a typical functional programming function, map(). Let’s read the list of datasets from the previous chapter: paths &lt;- Sys.glob(&quot;datasets/unemployment/*.csv&quot;) all_datasets &lt;- import_list(paths) str(all_datasets) ## List of 4 ## $ unemp_2013:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of which: Wage-earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of which: Non-wage-earners: int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ Unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ Active population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ Year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ unemp_2014:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of which: Wage-earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of which: Non-wage-earners: int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ Unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ Active population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ Year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ unemp_2015:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of which: Wage-earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of which: Non-wage-earners: int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ Active population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ Year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ unemp_2016:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ Commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ Total employed population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of which: Wage-earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of which: Non-wage-earners: int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ Unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ Active population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ Unemployment rate (in %) : num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ Year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... For working with lists, another package from the tidyverse that is very useful, is called purrr. purrr will be presented in-depth in Chapter 9. The first thing we are going to do is use a function to clean the names of the datasets. These names are not very easy to work with; there are spaces, and it would be better if the names of the columns would be all lowercase. For this we are going to use the function clean_names() from the janitor package. For a single dataset, I would write this: library(janitor) one_dataset = one_dataset %&gt;% clean_names() and I would get a dataset with column names in lowercase and spaces replaced by _ (and other corrections). How can I apply, or map, this function to each dataset in the list? To do this I need to use purrr::map(): library(purrr) all_datasets = all_datasets %&gt;% map(clean_names) all_datasets %&gt;% glimpse() ## List of 4 ## $ unemp_2013:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 223407 17802 1703 844 1431 4094 2146 971 1218 3002 ... ## ..$ of_which_wage_earners : int [1:118] 203535 15993 1535 750 1315 3800 1874 858 1029 2664 ... ## ..$ of_which_non_wage_earners : int [1:118] 19872 1809 168 94 116 294 272 113 189 338 ... ## ..$ unemployed : int [1:118] 19287 1071 114 25 74 261 98 45 66 207 ... ## ..$ active_population : int [1:118] 242694 18873 1817 869 1505 4355 2244 1016 1284 3209 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.95 5.67 6.27 2.88 4.92 ... ## ..$ year : int [1:118] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 ... ## $ unemp_2014:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 228423 18166 1767 845 1505 4129 2172 1007 1268 3124 ... ## ..$ of_which_wage_earners : int [1:118] 208238 16366 1606 757 1390 3840 1897 887 1082 2782 ... ## ..$ of_which_non_wage_earners : int [1:118] 20185 1800 161 88 115 289 275 120 186 342 ... ## ..$ unemployed : int [1:118] 19362 1066 122 19 66 287 91 38 61 202 ... ## ..$ active_population : int [1:118] 247785 19232 1889 864 1571 4416 2263 1045 1329 3326 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.81 5.54 6.46 2.2 4.2 ... ## ..$ year : int [1:118] 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 ... ## $ unemp_2015:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 233130 18310 1780 870 1470 4130 2170 1050 1300 3140 ... ## ..$ of_which_wage_earners : int [1:118] 212530 16430 1620 780 1350 3820 1910 920 1100 2770 ... ## ..$ of_which_non_wage_earners : int [1:118] 20600 1880 160 90 120 310 260 130 200 370 ... ## ..$ unemployed : int [1:118] 18806 988 106 29 73 260 80 41 72 169 ... ## ..$ active_population : int [1:118] 251936 19298 1886 899 1543 4390 2250 1091 1372 3309 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.46 5.12 5.62 3.23 4.73 ... ## ..$ year : int [1:118] 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 ... ## $ unemp_2016:&#39;data.frame&#39;: 118 obs. of 8 variables: ## ..$ commune : chr [1:118] &quot;Grand-Duche de Luxembourg&quot; &quot;Canton Capellen&quot; &quot;Dippach&quot; &quot;Garnich&quot; ... ## ..$ total_employed_population : int [1:118] 236100 18380 1790 870 1470 4160 2160 1030 1330 3150 ... ## ..$ of_which_wage_earners : int [1:118] 215430 16500 1640 780 1350 3840 1900 900 1130 2780 ... ## ..$ of_which_non_wage_earners : int [1:118] 20670 1880 150 90 120 320 260 130 200 370 ... ## ..$ unemployed : int [1:118] 18185 975 91 27 66 246 76 35 70 206 ... ## ..$ active_population : int [1:118] 254285 19355 1881 897 1536 4406 2236 1065 1400 3356 ... ## ..$ unemployment_rate_in_percent: num [1:118] 7.15 5.04 4.84 3.01 4.3 ... ## ..$ year : int [1:118] 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 ... So now, what if I want to know, for each dataset, which communes have an unemployment rate that is less than, say, 3%? For a single dataset I would do something like this: one_dataset %&gt;% filter(unemployment_rate_in_percent &lt; 3) But for a list of datasets, map() is needed (and as you will see, that is not all that is needed): all_datasets %&gt;% map(~filter(., unemployment_rate_in_percent &lt; 3)) ## $unemp_2013 ## commune total_employed_population of_which_wage_earners ## 1 Garnich 844 750 ## 2 Leudelange 1064 937 ## 3 Bech 526 463 ## of_which_non_wage_earners unemployed active_population ## 1 94 25 869 ## 2 127 32 1096 ## 3 63 16 542 ## unemployment_rate_in_percent year ## 1 2.876870 2013 ## 2 2.919708 2013 ## 3 2.952030 2013 ## ## $unemp_2014 ## commune total_employed_population of_which_wage_earners ## 1 Garnich 845 757 ## 2 Leudelange 1102 965 ## 3 Bech 543 476 ## 4 Flaxweiler 879 789 ## of_which_non_wage_earners unemployed active_population ## 1 88 19 864 ## 2 137 34 1136 ## 3 67 15 558 ## 4 90 27 906 ## unemployment_rate_in_percent year ## 1 2.199074 2014 ## 2 2.992958 2014 ## 3 2.688172 2014 ## 4 2.980132 2014 ## ## $unemp_2015 ## commune total_employed_population of_which_wage_earners ## 1 Bech 520 450 ## 2 Bous 750 680 ## of_which_non_wage_earners unemployed active_population ## 1 70 14 534 ## 2 70 22 772 ## unemployment_rate_in_percent year ## 1 2.621723 2015 ## 2 2.849741 2015 ## ## $unemp_2016 ## commune total_employed_population of_which_wage_earners ## 1 Reckange-sur-Mess 980 850 ## 2 Bech 520 450 ## 3 Betzdorf 1500 1350 ## 4 Flaxweiler 910 820 ## of_which_non_wage_earners unemployed active_population ## 1 130 30 1010 ## 2 70 11 531 ## 3 150 45 1545 ## 4 90 24 934 ## unemployment_rate_in_percent year ## 1 2.970297 2016 ## 2 2.071563 2016 ## 3 2.912621 2016 ## 4 2.569593 2016 I know what you’re thinking… what the hell?. Let me explain: map() needs a function to map to each element of the list. all_datasets is the list to which I want to map the function. But what function? filter() is the function I need, so why doesn’t: all_datasets %&gt;% map(filter(unemployment_rate_in_percent &lt; 3)) work? This is a bit complicated, and has to do with what is called environments. If you try to run the code above, you will get this error message: Error in filter(unemployment_rate_in_percent &lt; 3) : object &#39;unemployment_rate_in_percent&#39; not found I won’t go into details, but by writing ~filter(., unemployment_rate_in_percent &lt; 3), which is a formula (~ is the symbol to define formulas, more on this in the later chapters), map() converts it to a function that it can use. If you want to know more about this, you can read it in Advanced R by Hadley Wickham, but it is an advanced topic. 9.6 Mapping your homebrewed functions to lists of datasets Before merging these datasets together, we would need them to have a year column indicating the year. It would also be helpful if gave names to these datasets. For this task, we can use purrr::set_names(): all_datasets = set_names(all_datasets, as.character(seq(2013, 2016))) Let’s take a look at the list now: str(all_datasets) As you can see, each data.frame object contained in the list has been renamed. You can thus access them with the $ operator: 9.6.1 Data frames and reduce Using map() we now know how to apply a function to each dataset of a list. But maybe it would be easier to merge all the datasets first, and then manipulate them? Before that though, I am going to teach you how to use purrr::reduce(), another very powerful function that works on lists. This is a function that you can find in other programming languages, but sometimes it is called fold. I think that the following example illustrates the power of reduce() well: numbers = seq(1, 5) # Create a vector with the numbers 1 to 5 reduce(numbers, `+`, .init = 0) ## [1] 15 reduce() takes a function as an argument, here the function +7 and then does the following computation: 0 + numbers[1] + numbers[2] + numbers[3]... It applies the user supplied function successively but has to start with something, so we give it the argument init also. This argument is actually optional, but I show it here because in some cases it might be useful to start the computations at another value than 0.reduce() generalizes functions that only take two arguments. If you were to write a function that returns the minimum between two numbers: my_min = function(a, b){ if(a &lt; b){ return(a) } else { return(b) } } You could use reduce() to get the minimum of a list of numbers: numbers2 = c(3, 1, -8, 9) reduce(numbers2, my_min) ## [1] -8 As long as you provide a function and a list of elements to reduce(), you will get a single output. So how could reduce() help us with merging all the datasets that are in the list? dplyr comes with a lot of function to merge two datasets. Remember that I said before that reduce() allows you to generalize a function of two arguments? Let’s try it with our list of datasets: unemp_lux = reduce(all_datasets, full_join) ## Joining, by = c(&quot;commune&quot;, &quot;total_employed_population&quot;, &quot;of_which_wage_earners&quot;, &quot;of_which_non_wage_earners&quot;, &quot;unemployed&quot;, &quot;active_population&quot;, &quot;unemployment_rate_in_percent&quot;, &quot;year&quot;) ## Joining, by = c(&quot;commune&quot;, &quot;total_employed_population&quot;, &quot;of_which_wage_earners&quot;, &quot;of_which_non_wage_earners&quot;, &quot;unemployed&quot;, &quot;active_population&quot;, &quot;unemployment_rate_in_percent&quot;, &quot;year&quot;) ## Joining, by = c(&quot;commune&quot;, &quot;total_employed_population&quot;, &quot;of_which_wage_earners&quot;, &quot;of_which_non_wage_earners&quot;, &quot;unemployed&quot;, &quot;active_population&quot;, &quot;unemployment_rate_in_percent&quot;, &quot;year&quot;) glimpse(unemp_lux) ## Observations: 472 ## Variables: 8 ## $ commune &lt;chr&gt; &quot;Grand-Duche de Luxembourg&quot;, &quot;Can... ## $ total_employed_population &lt;int&gt; 223407, 17802, 1703, 844, 1431, 4... ## $ of_which_wage_earners &lt;int&gt; 203535, 15993, 1535, 750, 1315, 3... ## $ of_which_non_wage_earners &lt;int&gt; 19872, 1809, 168, 94, 116, 294, 2... ## $ unemployed &lt;int&gt; 19287, 1071, 114, 25, 74, 261, 98... ## $ active_population &lt;int&gt; 242694, 18873, 1817, 869, 1505, 4... ## $ unemployment_rate_in_percent &lt;dbl&gt; 7.947044, 5.674773, 6.274078, 2.8... ## $ year &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 201... full_join() is one of the dplyr function that merges data. There are others that might be useful depending on the kind of join operation you need. Let’s write this data to disk as we’re going to keep using it for the next chapters: export(unemp_lux, &quot;datasets/unemp_lux.csv&quot;) 9.7 Functional programming and plotting In this section, we are going to learn how to use the possibilities offered by the purrr package and how it can work together with ggplot2 to generate many plots. This is a more advanced topic, but what comes next is also what makes R, and the functional programming paradigm so powerful. For example, suppose that instead of wanting a single plot with the unemployment rate of each commune, you need one unemployment plot, per commune: unemp_lux_data %&gt;% filter(division == &quot;Luxembourg&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division)) + theme_minimal() + labs(title = &quot;Unemployment in Luxembourg&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() and then you would write the same for “Esch-sur-Alzette” and also for “Wiltz”. If you only have to make to make these 3 plots, copy and pasting the above lines is no big deal: unemp_lux_data %&gt;% filter(division == &quot;Esch-sur-Alzette&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division)) + theme_minimal() + labs(title = &quot;Unemployment in Esch-sur-Alzette&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() unemp_lux_data %&gt;% filter(division == &quot;Wiltz&quot;) %&gt;% ggplot(aes(year, unemployment_rate_in_percent, group = division)) + theme_minimal() + labs(title = &quot;Unemployment in Esch-sur-Alzette&quot;, x = &quot;Year&quot;, y = &quot;Rate&quot;) + geom_line() Put copy and pasting is error prone. Can you spot the copy-paste mistake I made? And what if you have to create the above plots for all 108 Luxembourguish communes? That’s a lot of copy pasting. What if, once you are done copy pasting, you have to change something, for example, the theme? You could use the search and replace function of RStudio, true, but sometimes search and replace can also introduce bugs and typos. You can avoid all these issues by using purrr::map(). What do you need to map over? The commune names. So let’s create a vector of commune names: communes = list(&quot;Luxembourg&quot;, &quot;Esch-sur-Alzette&quot;, &quot;Wiltz&quot;) Now we can create the graphs using map(), or map2() to be exact: plots_tibble = unemp_lux_data %&gt;% filter(division %in% communes) %&gt;% group_by(division) %&gt;% nest() %&gt;% mutate(plot = map2(.x = data, .y = division, ~ggplot(data = .x) + theme_minimal() + geom_line(aes(year, unemployment_rate_in_percent, group = 1)) + labs(title = paste(&quot;Unemployment in&quot;, .y)))) Let’s study this line by line: the first line is easy, we simply use filter() to keep only the communes we are interested in. Then we group by division and use tidyr::nest(). As a refresher, let’s take a look at what this does: unemp_lux_data %&gt;% filter(division %in% communes) %&gt;% group_by(division) %&gt;% nest() ## # A tibble: 3 x 2 ## division data ## &lt;chr&gt; &lt;list&gt; ## 1 Esch-sur-Alzette &lt;tibble [15 × 7]&gt; ## 2 Luxembourg &lt;tibble [15 × 7]&gt; ## 3 Wiltz &lt;tibble [15 × 7]&gt; This creates a tibble with two columns, division and data, where each individual (or commune in this case) is another tibble with all the original variables. This is very useful, because now we can pass these tibbles to map2(), to generate the plots. But why map2() and what’s the difference with map()? map2() works the same way as map(), but maps over two inputs: numbers1 = list(1, 2, 3, 4, 5) numbers2 = list(9, 8, 7, 6, 5) map2(numbers1, numbers2, `*`) ## [[1]] ## [1] 9 ## ## [[2]] ## [1] 16 ## ## [[3]] ## [1] 21 ## ## [[4]] ## [1] 24 ## ## [[5]] ## [1] 25 In our example with the graphs, the two inputs are the data, and the names of the communes. This is useful to create the title with labs(title = paste(&quot;Unemployment in&quot;, .y)))) where .y is the second input of map2(), the commune names contained in variable division. So what happened? We now have a tibble called plots_tibble that looks like this: print(plots_tibble) ## # A tibble: 3 x 3 ## division data plot ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Esch-sur-Alzette &lt;tibble [15 × 7]&gt; &lt;S3: gg&gt; ## 2 Luxembourg &lt;tibble [15 × 7]&gt; &lt;S3: gg&gt; ## 3 Wiltz &lt;tibble [15 × 7]&gt; &lt;S3: gg&gt; This tibble contains three columns, division, data and now a new one called plot, that we created before using the last line mutate(plot = ...) (remember that mutate() adds columns to tibbles). plot is a list-column, with elements… being plots! Yes you read that right, the elements of the column plot are literally plots. This is what I meant with list columns. Let’s see what is inside the data and the plot columns exactly: plots_tibble %&gt;% pull(data) ## [[1]] ## # A tibble: 15 x 7 ## year active_populati… of_which_non_wa… of_which_wage_e… ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 11.3 665 10.1 ## 2 2002 11.7 677 10.3 ## 3 2003 11.7 674 10.2 ## 4 2004 12.2 659 10.6 ## 5 2005 11.9 654 10.3 ## 6 2006 12.2 657 10.5 ## 7 2007 12.6 634 10.9 ## 8 2008 12.9 638 11.0 ## 9 2009 13.2 652 11.0 ## 10 2010 13.6 638 11.2 ## 11 2011 13.9 630 11.5 ## 12 2012 14.3 684 11.8 ## 13 2013 14.8 694 12.0 ## 14 2014 15.2 703 12.5 ## 15 2015 15.3 710 12.6 ## # ... with 3 more variables: total_employed_population &lt;dbl&gt;, ## # unemployed &lt;dbl&gt;, unemployment_rate_in_percent &lt;dbl&gt; ## ## [[2]] ## # A tibble: 15 x 7 ## year active_populati… of_which_non_wa… of_which_wage_e… ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 34.4 2.89 30.4 ## 2 2002 34.8 2.94 30.3 ## 3 2003 35.2 3.03 30.1 ## 4 2004 35.6 3.06 30.1 ## 5 2005 35.6 3.13 29.8 ## 6 2006 35.5 3.12 30.3 ## 7 2007 36.1 3.25 31.1 ## 8 2008 37.5 3.39 31.9 ## 9 2009 37.9 3.49 31.6 ## 10 2010 38.6 3.54 32.1 ## 11 2011 40.3 3.66 33.6 ## 12 2012 41.8 3.81 34.6 ## 13 2013 43.4 3.98 35.5 ## 14 2014 44.6 4.11 36.7 ## 15 2015 45.2 4.14 37.5 ## # ... with 3 more variables: total_employed_population &lt;dbl&gt;, ## # unemployed &lt;dbl&gt;, unemployment_rate_in_percent &lt;dbl&gt; ## ## [[3]] ## # A tibble: 15 x 7 ## year active_populati… of_which_non_wa… of_which_wage_e… ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2001 2.13 223 1.79 ## 2 2002 2.14 220 1.78 ## 3 2003 2.18 223 1.79 ## 4 2004 2.24 227 1.85 ## 5 2005 2.26 229 1.85 ## 6 2006 2.20 206 1.82 ## 7 2007 2.27 198 1.88 ## 8 2008 2.30 200 1.90 ## 9 2009 2.36 201 1.94 ## 10 2010 2.42 195 1.97 ## 11 2011 2.48 190 2.02 ## 12 2012 2.59 188 2.10 ## 13 2013 2.66 195 2.15 ## 14 2014 2.69 185 2.19 ## 15 2015 2.77 180 2.27 ## # ... with 3 more variables: total_employed_population &lt;dbl&gt;, ## # unemployed &lt;dbl&gt;, unemployment_rate_in_percent &lt;dbl&gt; each element of data is a tibble for the specific country with columns year, active_population, etc, the original columns. But obviously, there is no division column. So to plot the data, and join all the dots together, we need to add group = 1 in the call to ggplot2() (whereas if you plot multiple lines in the same graph, you need to write group = division). But more interestingly, how can you actually see the plots? If you want to simply look at them, it is enough to use pull(): plots_tibble %&gt;% pull(plot) ## [[1]] ## ## [[2]] ## ## [[3]] And if we want to save these plots, we can do so using map2(): map2(paste0(plots_tibble$division, &quot;.pdf&quot;), plots_tibble$plot, ggsave) Saving 7 x 5 in image Saving 6.01 x 3.94 in image Saving 6.01 x 3.94 in image This was probably the most advanced topic we have studied yet; but you probably agree with me that it is among the most useful ones. This section is a perfect illustration of the power of functional programming; you can mix and match functions as long as you give them the correct arguments. You can pass data to functions that use data and then pass these functions to other functions that use functions as arguments, such as map().8 map() does not care if the functions you pass to it produces tables, graphs or even another function. map() will simply map this function to a list of inputs, and as long as these inputs are correct arguments to the function, map() will do its magic. If you combine this with list-columns, you can even use map() alongside dplyr functions and map your function by first grouping, filtering, etc… 9.8 Functional programming and modeling 9.8.1 Bootstrapping The broom package includes a bootstrap() function that allows you to resample your data with replacement and estimate your model on each sample. A worked example is available in one of the package’s Vignette. R also includes a more general boot() function, but we are going to learn about this one later, as it involves some programming. Let’s go back to model_log, and try to get bootstrapped confidence intervals (as shown in the Vignette I linked above): boot_result &lt;- Housing %&gt;% bootstrap(50) %&gt;% do(tidy(lm(log(price) ~ bedrooms + driveway, data = .))) I just use 2 variables to make the output smaller. Let’s take a look at boot_result: print(boot_result) ## # A tibble: 150 x 6 ## # Groups: replicate [50] ## replicate term estimate std.error statistic p.value ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 (Intercept) 10.2 0.0691 148. 0. ## 2 1 bedrooms 0.185 0.0191 9.72 1.07e-20 ## 3 1 drivewayyes 0.366 0.0404 9.07 2.23e-18 ## 4 2 (Intercept) 10.1 0.0640 158. 0. ## 5 2 bedrooms 0.218 0.0181 12.0 1.12e-29 ## 6 2 drivewayyes 0.319 0.0381 8.37 4.93e-16 ## 7 3 (Intercept) 10.2 0.0706 144. 0. ## 8 3 bedrooms 0.192 0.0200 9.58 3.51e-20 ## 9 3 drivewayyes 0.341 0.0402 8.48 2.15e-16 ## 10 4 (Intercept) 10.2 0.0703 146. 0. ## # ... with 140 more rows boot_result is a tibble grouped by the new variable replicate. Now it is easy to compute confidence intervals for the parameters: boot_result %&gt;% group_by(term) %&gt;% summarize(low = quantile(estimate, .05/2), high = quantile(estimate, 1 - .05/2)) ## # A tibble: 3 x 3 ## term low high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 10.1 10.3 ## 2 bedrooms 0.152 0.223 ## 3 drivewayyes 0.314 0.412 quantile() is a built-in function that returns the quantile at the \\(alpha\\) level for a given vector (in this case the vector of estimates). Of course, we had to group by term first, as we need to compute the confidence intervals, for each terms (or estimated parameters) separately. Plotting the densities of the bootstrapped parameters might also prove interesting: ggplot(boot_result, aes(estimate)) + geom_density() + facet_wrap(~term, scales = &quot;free&quot;) 9.8.2 Cross-validation To do cross-validation, we are going to use the modelr package, which is also part of the tidyverse.9 library(modelr) modelr includes two functions for cross-validation, crossv_kfold and crossv_mc, which do K-fold Cross-Validation and Monte Carlo Cross-Validation respectively. First, let’s see what cross_mc() (cross_kfold()) returns when applied to data: cv_Housing = Housing %&gt;% crossv_mc(n = 50) print(cv_Housing) ## # A tibble: 50 x 3 ## train test .id ## &lt;list&gt; &lt;list&gt; &lt;chr&gt; ## 1 &lt;S3: resample&gt; &lt;S3: resample&gt; 01 ## 2 &lt;S3: resample&gt; &lt;S3: resample&gt; 02 ## 3 &lt;S3: resample&gt; &lt;S3: resample&gt; 03 ## 4 &lt;S3: resample&gt; &lt;S3: resample&gt; 04 ## 5 &lt;S3: resample&gt; &lt;S3: resample&gt; 05 ## 6 &lt;S3: resample&gt; &lt;S3: resample&gt; 06 ## 7 &lt;S3: resample&gt; &lt;S3: resample&gt; 07 ## 8 &lt;S3: resample&gt; &lt;S3: resample&gt; 08 ## 9 &lt;S3: resample&gt; &lt;S3: resample&gt; 09 ## 10 &lt;S3: resample&gt; &lt;S3: resample&gt; 10 ## # ... with 40 more rows This is a tibble with 3 colmuns, two of them being list-columns; train and test. Each element of train and test is a resampled tibble of the original data. This means that we can now estimate our first model (the simple linear one) on each resampled data using map(): Now if we want to estimate all these models: cv_models = cv_Housing %&gt;% mutate(model = map(train, ~lm(price ~ ., data = .))) print(cv_models) ## # A tibble: 50 x 4 ## train test .id model ## &lt;list&gt; &lt;list&gt; &lt;chr&gt; &lt;list&gt; ## 1 &lt;S3: resample&gt; &lt;S3: resample&gt; 01 &lt;S3: lm&gt; ## 2 &lt;S3: resample&gt; &lt;S3: resample&gt; 02 &lt;S3: lm&gt; ## 3 &lt;S3: resample&gt; &lt;S3: resample&gt; 03 &lt;S3: lm&gt; ## 4 &lt;S3: resample&gt; &lt;S3: resample&gt; 04 &lt;S3: lm&gt; ## 5 &lt;S3: resample&gt; &lt;S3: resample&gt; 05 &lt;S3: lm&gt; ## 6 &lt;S3: resample&gt; &lt;S3: resample&gt; 06 &lt;S3: lm&gt; ## 7 &lt;S3: resample&gt; &lt;S3: resample&gt; 07 &lt;S3: lm&gt; ## 8 &lt;S3: resample&gt; &lt;S3: resample&gt; 08 &lt;S3: lm&gt; ## 9 &lt;S3: resample&gt; &lt;S3: resample&gt; 09 &lt;S3: lm&gt; ## 10 &lt;S3: resample&gt; &lt;S3: resample&gt; 10 &lt;S3: lm&gt; ## # ... with 40 more rows We added a list-column with the 50 models estimated (or trained) on the train data. Now we can compute, say, the RMSE from before on each one. modelr includes a rmse() function, so unlike in the previous section where we computed the RMSE manually we are simply going to use this function: rmse_cv = cv_models %&gt;% mutate(rmse_all_models = map2_dbl(model, test, ~rmse(.x, .y))) %&gt;% pull(rmse_all_models) print(rmse_cv) ## [1] 15951.99 16342.37 15942.59 13547.26 14220.94 13558.39 12336.18 ## [8] 13905.72 14659.48 16195.46 17102.41 14071.76 16190.94 17183.69 ## [15] 15604.58 15008.10 17874.27 13993.60 15377.16 18582.74 17557.52 ## [22] 16666.49 17355.66 18119.38 17788.71 15631.23 14969.67 19183.09 ## [29] 14250.48 15560.58 15389.80 16337.59 13726.18 15567.40 14204.88 ## [36] 18432.65 15793.34 17213.26 16693.29 15047.21 13187.58 17593.13 ## [43] 13984.53 13562.76 15935.71 15669.48 15501.22 14357.58 15069.67 ## [50] 13746.53 We can now compute the mean of this rmse_cv variable: cv_rmse_lin_lin = mean(rmse_cv) which is equal to 1.563492410^{4}. For the log-lin model, this is a bit more complicated, because we need to exponentiate the predictions. However, if we use rmse() as before, there is no way to do that. I show you how you can do that, but it involves a few more steps than simply using rmse(). Try to understand the code below that computes the bootstrapped rmse for the log-lin model. You can see this as an advanced exercise; if you understand these next lines of code, you should understand anything that has to do with the tidyverse. cv_rmse_log_lin = cv_Housing %&gt;% mutate(model = map(train, ~lm(log(price) ~ ., data = .))) %&gt;% mutate(log_pred = map2(model, test, ~exp(predict(.x, .y)))) %&gt;% mutate(prices = map(test, ~as.data.frame(.x)$price)) %&gt;% mutate( rmse_all = map2_dbl(log_pred, prices, ~sqrt(mean((.x - .y)**2, na.rm = TRUE)))) %&gt;% pull(rmse_all) %&gt;% mean() cv_rmse_log_lin is equal to 1.530599610^{4}, which is lower than in the lin-lin model. 9.9 Exercises Suppose you have an Excel workbook that contains data on three sheets. Create a function that reads entire workbooks, and that returns a list of tibbles, where each tibble is the data of one sheet (download the example Excel workbook, example_workbook.xlsx, from the assets folder on the books github). Use one of the map() functions to combine two lists into one. Consider the following two lists: mediterranean &lt;- list(&quot;starters&quot; = list(&quot;humous&quot;, &quot;lasagna&quot;), &quot;dishes&quot; = list(&quot;sardines&quot;, &quot;olives&quot;)) continental &lt;- list(&quot;starters&quot; = list(&quot;pea soup&quot;, &quot;terrine&quot;), &quot;dishes&quot; = list(&quot;frikadelle&quot;, &quot;sauerkraut&quot;)) The result we’d like to have would look like this: $starters $starters[[1]] [1] &quot;humous&quot; $starters[[2]] [1] &quot;olives&quot; $starters[[3]] [1] &quot;pea soup&quot; $starters[[4]] [1] &quot;terrine&quot; $dishes $dishes[[1]] [1] &quot;sardines&quot; $dishes[[2]] [1] &quot;lasagna&quot; $dishes[[3]] [1] &quot;frikadelle&quot; $dishes[[4]] [1] &quot;sauerkraut&quot; This is simply the + operator you’re used to. Try this out: `+`(1, 5) and you’ll see + is a function like any other. You just have to write backticks around the plus symbol to make it work.↩ Functions that have other functions as input are called higher order functions↩ This package is still somewhat young and experimental and might get replaced by two others in the future. At some point in the future you might get a warning message telling you that the package is deprecated. When this happens, you would need to switch to the new packages, but transition should be fairly easy.↩ "],
["package-development.html", "Chapter 10 Package development 10.1 Why you need to write your own package 10.2 Unit testing your package", " Chapter 10 Package development 10.1 Why you need to write your own package 10.2 Unit testing your package "],
["further-topics.html", "Chapter 11 Further topics 11.1 Generating Pdf or Word reports with R 11.2 Scraping the internet 11.3 Regular expressions 11.4 Setting up a blog with {blogdown}", " Chapter 11 Further topics 11.1 Generating Pdf or Word reports with R 11.2 Scraping the internet 11.3 Regular expressions 11.4 Setting up a blog with {blogdown} "],
["references.html", "References", " References "]
]
